# Phase 1: Setup (é¡¹ç›®åˆå§‹åŒ–)

**çŠ¶æ€**: âšª æœªå¼€å§‹
**å¼€å§‹æ—¥æœŸ**: å¾…å®š
**é¢„è®¡å®Œæˆ**: å¾…å®š
**è´Ÿè´£äºº**: å¾…å®š
**ä»»åŠ¡æ€»æ•°**: 8

---

## ğŸ“‹ éªŒæ”¶æ ‡å‡†

- [ ] æ‰€æœ‰ä¾èµ–åº“å·²å®‰è£…ï¼ˆkafka-python, redis-py, pymongo, clickhouse-driver, fastapi, uvicornï¼‰
- [ ] Kafkaé›†ç¾¤å¯ä»¥è¿æ¥å¹¶åˆ›å»ºtopic
- [ ] MySQL/ClickHouse/Redis/MongoDBæ•°æ®åº“å¯ä»¥è¿æ¥
- [ ] é¡¹ç›®ç»“æ„å·²åˆ›å»ºï¼ˆworkers/execution_node/, livecore/ï¼‰

---

## ğŸ¯ æ´»è·ƒä»»åŠ¡ (æœ€å¤š5ä¸ª)

> æ ¹æ®Constitutionä»»åŠ¡ç®¡ç†åŸåˆ™ï¼Œä»ä¸‹é¢çš„ä»»åŠ¡æ± ä¸­é€‰æ‹©æœ€å¤š5ä¸ªä»»åŠ¡ä½œä¸ºå½“å‰æ´»è·ƒä»»åŠ¡

**å½“å‰æ´»è·ƒä»»åŠ¡**: (æš‚æ— ï¼Œè¯·ä»å¾…åŠä»»åŠ¡æ± ä¸­é€‰æ‹©)

```markdown
ç¤ºä¾‹ï¼š
- [ ] T001 å®‰è£…Pythonä¾èµ–åº“
- [ ] T002 [P] åˆ›å»ºå®ç›˜äº¤æ˜“æ¨¡å—ç›®å½•ç»“æ„
- [ ] T003 [P] åˆ›å»ºKafka topicé…ç½®è„šæœ¬
- [ ] T004 [P] ç¼–å†™Kafkaè¿æ¥æµ‹è¯•è„šæœ¬
- [ ] T005 [P] åˆ›å»ºæ•°æ®åº“é…ç½®æ¨¡æ¿
```

---

## ğŸ“¥ å¾…åŠä»»åŠ¡æ±  (8ä¸ª)

### T001 å®‰è£…Pythonä¾èµ–åº“
- **æ–‡ä»¶**: `requirements.txt`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: å¦
- **æè¿°**: å®‰è£…kafka-python, redis-py, pymongo, clickhouse-driver, fastapi, uvicornåˆ°requirements.txt
- **è¯¦ç»†æ­¥éª¤**:
  1. ç¼–è¾‘requirements.txtï¼Œæ·»åŠ ä»¥ä¸‹ä¾èµ–ï¼š
     ```text
     kafka-python>=2.0.2
     redis-py>=5.0.0
     pymongo>=4.6.0
     clickhouse-driver>=0.2.6
     fastapi>=0.109.0
     uvicorn>=0.27.0
     ```
  2. è¿è¡Œ `pip install -r requirements.txt` éªŒè¯å®‰è£…
- **éªŒæ”¶**: pip install -r requirements.txt æˆåŠŸæ— é”™è¯¯

---

### T002 [P] åˆ›å»ºå®ç›˜äº¤æ˜“æ¨¡å—ç›®å½•ç»“æ„
- **æ–‡ä»¶**:
  - æ–°å¢: `src/ginkgo/workers/execution_node/`
  - æ–°å¢: `src/ginkgo/livecore/`
  - å¤ç”¨: `src/ginkgo/trading/engines/` (engine_live.py)
  - å¤ç”¨: `src/ginkgo/trading/gateway/` (trade_gateway.py)
  - å¤ç”¨: `src/ginkgo/trading/events/`
  - å¤ç”¨: `api/`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**:
  - åˆ›å»ºworkers/execution_node/ç›®å½•ï¼Œç”¨äºExecutionNode Workerï¼ˆç‹¬ç«‹è¿›ç¨‹ï¼‰
  - åˆ›å»ºlivecore/ç›®å½•ï¼Œç”¨äºLiveCoreå®¹å™¨ï¼ˆå¤šçº¿ç¨‹ï¼‰
  - å¤ç”¨ç°æœ‰trading/engines/ç›®å½•ä¸­çš„engine_live.py
  - å¤ç”¨ç°æœ‰trading/gateway/ç›®å½•ä¸­çš„trade_gateway.py
  - å¤ç”¨ç°æœ‰trading/events/ç›®å½•ä¸­çš„äº‹ä»¶ç±»ï¼ˆEventPriceUpdate, EventOrderPartiallyFilledç­‰ï¼‰
  - å¤ç”¨ç°æœ‰api/ç›®å½•ç”¨äºAPI Gateway
  - ä¸ºæ‰€æœ‰æ–°ç›®å½•åˆ›å»º__init__.pyæ–‡ä»¶
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºç›®å½•ç»“æ„ï¼š
     ```bash
     mkdir -p src/ginkgo/workers/execution_node
     mkdir -p src/ginkgo/livecore
     ```
  2. åˆ›å»ºæ‰€æœ‰å¿…è¦çš„__init__.pyæ–‡ä»¶ï¼ˆä½¿ç›®å½•æˆä¸ºPythonåŒ…ï¼‰ï¼š
     ```bash
     touch src/ginkgo/workers/__init__.py
     touch src/ginkgo/workers/execution_node/__init__.py
     touch src/ginkgo/livecore/__init__.py
     ```
  3. éªŒè¯å¤ç”¨ç›®å½•å­˜åœ¨ï¼š
     - `src/ginkgo/trading/engines/engine_live.py`
     - `src/ginkgo/trading/gateway/trade_gateway.py`
     - `src/ginkgo/trading/events/`
     - `api/`
- **éªŒæ”¶**: æ‰€æœ‰ç›®å½•å­˜åœ¨ä¸”åŒ…å«__init__.pyï¼Œå¤ç”¨ç›®å½•å·²ç¡®è®¤å­˜åœ¨

---

### T003 [P] åˆ›å»ºKafka topicé…ç½®è„šæœ¬
- **æ–‡ä»¶**: `scripts/setup_kafka_topics.sh`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: åˆ›å»ºKafka topicé…ç½®è„šæœ¬ï¼Œåˆ›å»º7ä¸ªtopicç”¨äºå®ç›˜äº¤æ˜“
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºè„šæœ¬æ–‡ä»¶ `scripts/setup_kafka_topics.sh`
  2. å®ç°ä»¥ä¸‹topicåˆ›å»ºé€»è¾‘ï¼š
     ```bash
     #!/bin/bash
     # Kafka Topics for Live Trading Architecture

     KAFKA_BROKER=localhost:9092

     # Market Data Topics
     kafka-topics.sh --create --topic ginkgo.live.market.data --bootstrap-server $KAFKA_BROKER --partitions 3 --replication-factor 1
     kafka-topics.sh --create --topic ginkgo.live.market.data.hk --bootstrap-server $KAFKA_BROKER --partitions 1 --replication-factor 1
     kafka-topics.sh --create --topic ginkgo.live.market.data.us --bootstrap-server $KAFKA_BROKER --partitions 1 --replication-factor 1
     kafka-topics.sh --create --topic ginkgo.live.market.data.futures --bootstrap-server $KAFKA_BROKER --partitions 1 --replication-factor 1

     # Order Topics
     kafka-topics.sh --create --topic ginkgo.live.orders.submission --bootstrap-server $KAFKA_BROKER --partitions 3 --replication-factor 1
     kafka-topics.sh --create --topic ginkgo.live.orders.feedback --bootstrap-server $KAFKA_BROKER --partitions 3 --replication-factor 1

     # Control Topics
     kafka-topics.sh --create --topic ginkgo.live.control.commands --bootstrap-server $KAFKA_BROKER --partitions 1 --replication-factor 1
     kafka-topics.sh --create --topic ginkgo.live.schedule.updates --bootstrap-server $KAFKA_BROKER --partitions 1 --replication-factor 1
     kafka-topics.sh --create --topic ginkgo.live.system.events --bootstrap-server $KAFKA_BROKER --partitions 1 --replication-factor 1

     # Alert Topic (Global)
     kafka-topics.sh --create --topic ginkgo.alerts --bootstrap-server $KAFKA_BROKER --partitions 1 --replication-factor 1

     echo "Kafka topics created successfully!"
     ```
  3. æ·»åŠ æ‰§è¡Œæƒé™ï¼š`chmod +x scripts/setup_kafka_topics.sh`
- **éªŒæ”¶**: è„šæœ¬å¯æ‰§è¡Œï¼ŒæˆåŠŸåˆ›å»ºæ‰€æœ‰topic

---

### T004 [P] ç¼–å†™Kafkaè¿æ¥æµ‹è¯•è„šæœ¬
- **æ–‡ä»¶**: `tests/network/live/test_kafka_connection.py`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: ç¼–å†™æµ‹è¯•è„šæœ¬éªŒè¯Kafkaè¿æ¥å’Œtopicåˆ›å»º
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºæµ‹è¯•æ–‡ä»¶ `tests/network/live/test_kafka_connection.py`
  2. å®ç°ä»¥ä¸‹æµ‹è¯•é€»è¾‘ï¼š
     ```python
     import pytest
     from kafka import KafkaProducer, KafkaConsumer
     from kafka.errors import KafkaError

     @pytest.mark.network
     def test_kafka_producer_connection():
         """æµ‹è¯•Kafka Producerè¿æ¥"""
         try:
             producer = KafkaProducer(
                 bootstrap_servers=['localhost:9092'],
                 acks='all',
                 value_serializer=lambda v: v.encode('utf-8')
             )
             # å‘é€æµ‹è¯•æ¶ˆæ¯
             future = producer.send('ginkgo.live.market.data', key=b'test', value=b'connection_test')
             record_metadata = future.get(timeout=10)
             producer.close()
             assert record_metadata.topic == 'ginkgo.live.market.data'
         except KafkaError as e:
             pytest.fail(f"Kafka producer connection failed: {e}")

     @pytest.mark.network
     def test_kafka_consumer_connection():
         """æµ‹è¯•Kafka Consumerè¿æ¥"""
         try:
             consumer = KafkaConsumer(
                 'ginkgo.live.market.data',
                 bootstrap_servers=['localhost:9092'],
                 auto_offset_reset='earliest',
                 enable_auto_commit=True
             )
             consumer.close()
         except KafkaError as e:
             pytest.fail(f"Kafka consumer connection failed: {e}")

     @pytest.mark.network
     def test_kafka_topics_exist():
         """æµ‹è¯•æ‰€æœ‰å¿…éœ€çš„topicæ˜¯å¦å·²åˆ›å»º"""
         from kafka.admin import KafkaAdminClient, NewTopic

         admin_client = KafkaAdminClient(
             bootstrap_servers="localhost:9092"
         )

         required_topics = [
             'ginkgo.live.market.data',
             'ginkgo.live.market.data.hk',
             'ginkgo.live.market.data.us',
             'ginkgo.live.market.data.futures',
             'ginkgo.live.orders.submission',
             'ginkgo.live.orders.feedback',
             'ginkgo.live.control.commands',
             'ginkgo.live.schedule.updates',
             'ginkgo.live.system.events',
             'ginkgo.alerts'
         ]

         existing_topics = admin_client.list_topics()
         for topic in required_topics:
             assert topic in existing_topics, f"Topic {topic} not found"

         admin_client.close()
     ```
  3. æ·»åŠ pytestæ ‡è®°ï¼šåœ¨`tests/network/live/__init__.py`ä¸­é…ç½®
- **éªŒæ”¶**: è¿è¡Œpytestæµ‹è¯•é€šè¿‡ï¼ŒKafkaè¿æ¥æ­£å¸¸ï¼Œæ‰€æœ‰topicå­˜åœ¨

---

### T005 [P] åˆ›å»ºæ•°æ®åº“é…ç½®æ¨¡æ¿
- **æ–‡ä»¶**: `~/.ginkgo/config.yaml`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: åœ¨~/.ginkgo/config.yamlæ·»åŠ kafkaã€redisã€mysqlã€clickhouseã€mongodbé…ç½®
- **è¯¦ç»†æ­¥éª¤**:
  1. ç¼–è¾‘æˆ–åˆ›å»º `~/.ginkgo/config.yaml`
  2. æ·»åŠ ä»¥ä¸‹é…ç½®èŠ‚ï¼š
     ```yaml
     # Kafka Configuration
     kafka:
       bootstrap_servers: "localhost:9092"
       consumer_group: "ginkgo_live_trading"
       auto_offset_reset: "earliest"
       enable_auto_commit: false

     # Redis Configuration
     redis:
       host: "localhost"
       port: 6379
       db: 0
       password: null
       socket_timeout: 5
       socket_connect_timeout: 5

     # MySQL Configuration
     mysql:
       host: "localhost"
       port: 3306
       user: "ginkgo"
       password: "your_password"
       database: "ginkgo"
       charset: "utf8mb4"

     # ClickHouse Configuration
     clickhouse:
       host: "localhost"
       port: 9000
       user: "default"
       password: ""
       database: "ginkgo"
       settings:
         use_numpy: true

     # MongoDB Configuration
     mongodb:
       host: "localhost"
       port: 27017
       username: ""
       password: ""
       database: "ginkgo"
       auth_source: "admin"
     ```
  3. ç¡®ä¿æ–‡ä»¶æƒé™æ­£ç¡®ï¼š`chmod 600 ~/.ginkgo/config.yaml`
- **éªŒæ”¶**: é…ç½®æ–‡ä»¶å­˜åœ¨ï¼ŒåŒ…å«æ‰€æœ‰å¿…éœ€çš„é…ç½®èŠ‚

---

### T006 [P] ç¼–å†™æ•°æ®åº“è¿æ¥æµ‹è¯•è„šæœ¬
- **æ–‡ä»¶**: `tests/network/live/test_database_connection.py`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: ç¼–å†™æµ‹è¯•è„šæœ¬éªŒè¯MySQL/ClickHouse/Redis/MongoDBè¿æ¥
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºæµ‹è¯•æ–‡ä»¶ `tests/network/live/test_database_connection.py`
  2. å®ç°ä»¥ä¸‹æµ‹è¯•é€»è¾‘ï¼š
     ```python
     import pytest
     import redis
     from clickhouse_driver import Client as ClickHouseClient
     import pymysql
     from pymongo import MongoClient

     @pytest.mark.network
     def test_redis_connection():
         """æµ‹è¯•Redisè¿æ¥"""
         try:
             r = redis.Redis(host='localhost', port=6379, db=0)
             r.ping()
             r.close()
         except redis.ConnectionError as e:
             pytest.fail(f"Redis connection failed: {e}")

     @pytest.mark.network
     def test_mysql_connection():
         """æµ‹è¯•MySQLè¿æ¥"""
         try:
             conn = pymysql.connect(
                 host='localhost',
                 user='ginkgo',
                 password='your_password',
                 database='ginkgo'
             )
             cursor = conn.cursor()
             cursor.execute("SELECT 1")
             cursor.close()
             conn.close()
         except pymysql.Error as e:
             pytest.fail(f"MySQL connection failed: {e}")

     @pytest.mark.network
     def test_clickhouse_connection():
         """æµ‹è¯•ClickHouseè¿æ¥"""
         try:
             client = ClickHouseClient(host='localhost', port=9000)
             result = client.execute('SELECT 1')
             assert result[0][0] == 1
             client.disconnect()
         except Exception as e:
             pytest.fail(f"ClickHouse connection failed: {e}")

     @pytest.mark.network
     def test_mongodb_connection():
         """æµ‹è¯•MongoDBè¿æ¥"""
         try:
             client = MongoClient('localhost', 27017, serverSelectionTimeoutMS=2000)
             client.server_info()
             client.close()
         except Exception as e:
             pytest.fail(f"MongoDB connection failed: {e}")
     ```
  3. æ·»åŠ pytestæ ‡è®°
- **éªŒæ”¶**: è¿è¡Œpytestæµ‹è¯•é€šè¿‡ï¼Œæ‰€æœ‰æ•°æ®åº“è¿æ¥æ­£å¸¸

---

### T007 åˆ›å»º.env.exampleæ¨¡æ¿æ–‡ä»¶
- **æ–‡ä»¶**: `.env.example`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: å¦
- **æè¿°**: åˆ›å»º.env.exampleæ¨¡æ¿æ–‡ä»¶ï¼ŒåŒ…å«Kafkaã€Redisã€æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»º `.env.example` æ–‡ä»¶
  2. æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š
     ```bash
     # Kafka
     KAFKA_BOOTSTRAP_SERVERS=localhost:9092
     KAFKA_CONSUMER_GROUP=ginkgo_live_trading

     # Redis
     REDIS_HOST=localhost
     REDIS_PORT=6379
     REDIS_DB=0

     # MySQL
     MYSQL_HOST=localhost
     MYSQL_PORT=3306
     MYSQL_USER=ginkgo
     MYSQL_PASSWORD=your_password
     MYSQL_DATABASE=ginkgo

     # ClickHouse
     CLICKHOUSE_HOST=localhost
     CLICKHOUSE_PORT=9000
     CLICKHOUSE_USER=default
     CLICKHOUSE_DATABASE=ginkgo

     # MongoDB
     MONGODB_HOST=localhost
     MONGODB_PORT=27017
     MONGODB_DATABASE=ginkgo
     ```
- **éªŒæ”¶**: .env.exampleæ–‡ä»¶å­˜åœ¨ï¼ŒåŒ…å«æ‰€æœ‰ç¯å¢ƒå˜é‡ç¤ºä¾‹

---

### T008 ç¼–å†™Docker Composeé…ç½®æ–‡ä»¶
- **æ–‡ä»¶**: `docker-compose.yml`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: å¦
- **æè¿°**: ç¼–å†™Docker Composeé…ç½®æ–‡ä»¶ç”¨äºæœ¬åœ°å¼€å‘ç¯å¢ƒ
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºæˆ–ç¼–è¾‘ `docker-compose.yml`
  2. æ·»åŠ ä»¥ä¸‹æœåŠ¡ï¼š
     ```yaml
     version: '3.8'

     services:
       # Kafka
       zookeeper:
         image: confluentinc/cp-zookeeper:7.4.0
         environment:
           ZOOKEEPER_CLIENT_PORT: 2181
         ports:
           - "2181:2181"

       kafka:
         image: confluentinc/cp-kafka:7.4.0
         depends_on:
           - zookeeper
         ports:
           - "9092:9092"
         environment:
           KAFKA_BROKER_ID: 1
           KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
           KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
           KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
           KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
           KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

       # Redis
       redis:
         image: redis:7-alpine
         ports:
           - "6379:6379"
         command: redis-server --appendonly yes

       # MySQL
       mysql:
         image: mysql:8.0
         ports:
           - "3306:3306"
         environment:
           MYSQL_ROOT_PASSWORD: root_password
           MYSQL_DATABASE: ginkgo
           MYSQL_USER: ginkgo
           MYSQL_PASSWORD: ginkgo_password
         volumes:
           - mysql_data:/var/lib/mysql

       # ClickHouse
       clickhouse:
         image: clickhouse/clickhouse-server:23
         ports:
           - "8123:8123"
           - "9000:9000"
         volumes:
           - clickhouse_data:/var/lib/clickhouse

       # MongoDB
       mongodb:
         image: mongo:7
         ports:
           - "27017:27017"
         environment:
           MONGO_INITDB_DATABASE: ginkgo
         volumes:
           - mongodb_data:/data/db

     volumes:
       mysql_data:
       clickhouse_data:
       mongodb_data:
     ```
  3. éªŒè¯é…ç½®ï¼š`docker-compose config`
- **éªŒæ”¶**: docker-compose up -d å¯ä»¥å¯åŠ¨æ‰€æœ‰æœåŠ¡

---

## âœ… å·²å®Œæˆä»»åŠ¡ (0ä¸ª)

*(æš‚æ— )*

---

## ğŸ“Š è¿›åº¦è·Ÿè¸ª

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»ä»»åŠ¡æ•° | 8 |
| å·²å®Œæˆ | 0 |
| è¿›è¡Œä¸­ | 0 |
| å¾…åŠ | 8 |
| å®Œæˆè¿›åº¦ | 0% |

---

## ğŸ”— ä¾èµ–å…³ç³»

```
Phase 1: Setup (æœ¬é˜¶æ®µ)
    â†“
Phase 2: Foundational
```

---

## ğŸ“ å¤‡æ³¨

- æœ¬é˜¶æ®µæ‰€æœ‰ä»»åŠ¡éƒ½æ˜¯åŸºç¡€è®¾æ–½æ­å»ºï¼Œå®Œæˆåå³å¯å¼€å§‹Phase 2
- å»ºè®®ä¼˜å…ˆå®ŒæˆT001-T006ï¼ŒT007-T008å¯ä»¥ç¨åè¡¥å……
- æ‰€æœ‰å¹¶è¡Œä»»åŠ¡ï¼ˆæ ‡è®°[P]ï¼‰å¯ä»¥åŒæ—¶è¿›è¡Œï¼Œæé«˜æ•ˆç‡

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0
**æœ€åæ›´æ–°**: 2026-01-04
