# Phase 3: User Story 1 - å•Portfolioå®ç›˜è¿è¡Œ (P1)

**çŠ¶æ€**: âšª æœªå¼€å§‹
**å¼€å§‹æ—¥æœŸ**: å¾…å®š
**é¢„è®¡å®Œæˆ**: å¾…å®š
**ä¾èµ–**: Phase 1-2å®Œæˆ
**ä»»åŠ¡æ€»æ•°**: 14
**User Story**: ä½œä¸ºäº¤æ˜“è€…ï¼Œæˆ‘å¸Œæœ›åœ¨å®ç›˜ç¯å¢ƒä¸­è¿è¡Œå•ä¸ªæŠ•èµ„ç»„åˆï¼Œç­–ç•¥èƒ½å¤Ÿæ¥æ”¶å®æ—¶è¡Œæƒ…ã€ç”Ÿæˆä¿¡å·å¹¶è‡ªåŠ¨æ‰§è¡Œäº¤æ˜“

---

## ğŸ“‹ éªŒæ”¶æ ‡å‡†

- [ ] ExecutionNodeå¯ä»¥å¯åŠ¨å¹¶åŠ è½½Portfolioé…ç½®
- [ ] ExecutionNodeè®¢é˜…Kafka market.data topicå¹¶æ¥æ”¶EventPriceUpdate
- [ ] Portfolio.on_price_update()æ–¹æ³•å¯ä»¥å¤„ç†äº‹ä»¶å¹¶ç”ŸæˆSignal
- [ ] Signalé€šè¿‡Sizerè®¡ç®—ç”ŸæˆOrder
- [ ] Orderé€šè¿‡ExecutionNode.submit_order()æäº¤åˆ°Kafka orders.submission topic
- [ ] LiveEngineè®¢é˜…orders.submission topicå¹¶å¤„ç†è®¢å•
- [ ] TradeGatewayæ¨¡æ‹Ÿæ‰§è¡Œè®¢å•å¹¶è¿”å›EventOrderFilled
- [ ] Portfolio.on_order_filled()æ›´æ–°æŒä»“å’Œç°é‡‘
- [ ] æŒä»“å’Œç°é‡‘åŒæ­¥å†™å…¥ClickHouseå’ŒMySQL
- [ ] ç«¯åˆ°ç«¯å»¶è¿Ÿ < 200ms

---

## ğŸ¯ æ´»è·ƒä»»åŠ¡ (æœ€å¤š5ä¸ª)

> æ ¹æ®Constitutionä»»åŠ¡ç®¡ç†åŸåˆ™ï¼Œä»ä¸‹é¢çš„ä»»åŠ¡æ± ä¸­é€‰æ‹©æœ€å¤š5ä¸ªä»»åŠ¡ä½œä¸ºå½“å‰æ´»è·ƒä»»åŠ¡

**å½“å‰æ´»è·ƒä»»åŠ¡**: (æš‚æ— ï¼Œè¯·ä»å¾…åŠä»»åŠ¡æ± ä¸­é€‰æ‹©)

---

## ğŸ“¥ å¾…åŠä»»åŠ¡æ±  (14ä¸ª)

### 3.1 ExecutionNodeåŸºç¡€ (5ä¸ªä»»åŠ¡)

### T017 [P] åˆ›å»ºExecutionNodeä¸»ç±»
- **æ–‡ä»¶**: `src/ginkgo/workers/execution_node/node.py`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: åˆ›å»ºExecutionNodeä¸»ç±»ï¼ŒåŒ…å«__init__, start, stopæ–¹æ³•ï¼Œæ”¯æŒåŠ è½½Portfolioé…ç½®
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºæ–‡ä»¶ `src/ginkgo/workers/execution_node/node.py`
  2. å®ç°ExecutionNodeç±»ï¼š
     ```python
     from typing import Dict, List, Optional
     from threading import Thread, Lock
     from queue import Queue
     import redis
     from kafka import KafkaConsumer

     from ginkgo.workers.execution_node.portfolio_processor import PortfolioProcessor
     from ginkgo.workers.execution_node.interest_map import InterestMap
     from ginkgo.workers.execution_node.backpressure import BackpressureChecker
     from ginkgo.data.cruds.portfolio_crud import PortfolioCRUD

     class ExecutionNode:
         """ExecutionNodeæ‰§è¡ŒèŠ‚ç‚¹ï¼Œè¿è¡Œå¤šä¸ªPortfolioå®ä¾‹"""

         def __init__(self, node_id: str, max_portfolios: int = 5):
             self.node_id = node_id
             self.max_portfolios = max_portfolios
             self.portfolios: Dict[str, PortfolioProcessor] = {}
             self.interest_map = InterestMap()
             self.backpressure_checker = BackpressureChecker(max_size=1000)
             self.kafka_consumer: Optional[KafkaConsumer] = None
             self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
             self.is_running = False
             self.lock = Lock()

         def start(self):
             """å¯åŠ¨ExecutionNode"""
             self.is_running = True
             # å¯åŠ¨Kafkaæ¶ˆè´¹è€…çº¿ç¨‹
             # å¯åŠ¨å¿ƒè·³ä¸ŠæŠ¥çº¿ç¨‹

         def stop(self):
             """åœæ­¢ExecutionNode"""
             self.is_running = False
             # åœæ­¢æ‰€æœ‰Portfolio
             # å…³é—­Kafkaæ¶ˆè´¹è€…
             # å…³é—­Redisè¿æ¥

         def load_portfolio(self, portfolio_id: str):
             """ä»æ•°æ®åº“åŠ è½½Portfolioé…ç½®"""
             portfolio_crud = PortfolioCRUD()
             portfolio = portfolio_crud.get_portfolio_by_id(portfolio_id)
             # åˆ›å»ºPortfolioProcessorå®ä¾‹
             processor = PortfolioProcessor(portfolio_id, portfolio)
             with self.lock:
                 self.portfolios[portfolio_id] = processor
                 self.interest_map.add_portfolio(portfolio_id, portfolio.interest_set)

         def subscribe_market_data(self):
             """è®¢é˜…Kafka market.data topic"""
             self.kafka_consumer = KafkaConsumer(
                 'ginkgo.live.market.data',
                 bootstrap_servers=['localhost:9092'],
                 group_id=f'execution_node_{self.node_id}',
                 auto_offset_reset='latest',
                 enable_auto_commit=False
             )
     ```
  3. æ·»åŠ å¤´éƒ¨æ³¨é‡Šï¼ˆUpstream/Downstream/Roleï¼‰
- **éªŒæ”¶**: ExecutionNodeç±»åˆ›å»ºæˆåŠŸï¼Œå¯ä»¥å®ä¾‹åŒ–

---

### T018 [P] åˆ›å»ºPortfolioProcessorçº¿ç¨‹ç±»
- **æ–‡ä»¶**: `src/ginkgo/workers/execution_node/portfolio_processor.py`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: åˆ›å»ºPortfolioProcessorçº¿ç¨‹ç±»ï¼ŒåŒ…å«queueå’Œportfolioå®ä¾‹
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºæ–‡ä»¶ `src/ginkgo/workers/execution_node/portfolio_processor.py`
  2. å®ç°PortfolioProcessorç±»ï¼š
     ```python
     from threading import Thread
     from queue import Queue
     from typing import Optional
     from ginkgo.core.portfolios.portfolio import Portfolio

     class PortfolioProcessor(Thread):
         """Portfolioå¤„ç†å™¨çº¿ç¨‹ï¼Œæ¯ä¸ªPortfolioä¸€ä¸ªç‹¬ç«‹çº¿ç¨‹"""

         def __init__(self, portfolio_id: str, portfolio: Portfolio, max_queue_size: int = 1000):
             super().__init__(daemon=True)
             self.portfolio_id = portfolio_id
             self.portfolio = portfolio
             self.queue = Queue(maxsize=max_queue_size)
             self.is_running = False

         def run(self):
             """ä¸»å¾ªç¯ï¼šä»queueè·å–äº‹ä»¶å¹¶è°ƒç”¨portfolio.on_event()"""
             self.is_running = True
             while self.is_running:
                 try:
                     event = self.queue.get(timeout=1)
                     self.portfolio.on_event(event)
                     self.queue.task_done()
                 except:
                     continue

         def stop(self):
             """åœæ­¢å¤„ç†å™¨"""
             self.is_running = False
             self.join()

         def put_event(self, event):
             """å‘é˜Ÿåˆ—æ”¾å…¥äº‹ä»¶ï¼ˆéé˜»å¡ï¼‰"""
             try:
                 self.queue.put(event, block=False)
                 return True
             except:
                 return False  # Queueå·²æ»¡

         def get_queue_size(self) -> int:
             """è·å–å½“å‰é˜Ÿåˆ—å¤§å°"""
             return self.queue.qsize()
     ```
  3. æ·»åŠ å¤´éƒ¨æ³¨é‡Š
- **éªŒæ”¶**: PortfolioProcessorç±»åˆ›å»ºæˆåŠŸï¼Œç»§æ‰¿Thread

---

### T019 å®ç°ExecutionNode.load_portfolio()æ–¹æ³•
- **æ–‡ä»¶**: `src/ginkgo/workers/execution_node/node.py`
- **ä¾èµ–**: T017
- **å¹¶è¡Œ**: å¦
- **æè¿°**: å®ç°ä»æ•°æ®åº“åŠ è½½Portfolioé…ç½®çš„å®Œæ•´é€»è¾‘
- **è¯¦ç»†æ­¥éª¤**:
  1. æ‰©å±•ExecutionNode.load_portfolio()æ–¹æ³•
  2. å®ç°æ•°æ®åº“æŸ¥è¯¢é€»è¾‘ï¼š
     ```python
     def load_portfolio(self, portfolio_id: str):
         """ä»æ•°æ®åº“åŠ è½½Portfolioé…ç½®"""
         from ginkgo.data.cruds.portfolio_crud import PortfolioCRUD
         from ginkgo import services

         # ä»æ•°æ®åº“æŸ¥è¯¢Portfolioé…ç½®
         portfolio_crud = services.data.cruds.portfolio()
         portfolio_model = portfolio_crud.get_portfolio_by_id(portfolio_id)

         # éªŒè¯is_live=True
         if not portfolio_model.is_live:
             raise ValueError(f"Portfolio {portfolio_id} is not a live portfolio")

         # åˆ›å»ºPortfolioå®ä¾‹ï¼ˆéœ€æ‰©å±•PortfolioåŸºç±»æ”¯æŒå®ç›˜äº¤æ˜“ï¼‰
         portfolio = Portfolio(
             portfolio_id=portfolio_model.uuid,
             name=portfolio_model.name,
             initial_cash=portfolio_model.initial_cash
         )

         # åŠ è½½ç­–ç•¥ã€Sizerã€é£æ§é…ç½®ï¼ˆé€šè¿‡MPortfolioFileMappingï¼‰
         # ... (é…ç½®åŠ è½½é€»è¾‘)

         # åˆ›å»ºPortfolioProcessorå®ä¾‹
         processor = PortfolioProcessor(portfolio_id, portfolio, max_queue_size=1000)
         processor.start()

         # æ³¨å†Œåˆ°ExecutionNode
         with self.lock:
             self.portfolios[portfolio_id] = processor
             self.interest_map.add_portfolio(portfolio_id, portfolio.get_interest_set())

         # æ›´æ–°RedisçŠ¶æ€
         self.redis_client.hset(
             f"portfolio:{portfolio_id}:status",
             mapping={
                 "status": "running",
                 "node": self.node_id,
                 "started_at": datetime.now().isoformat()
             }
         )

         return processor
     ```
  3. æ·»åŠ é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
- **éªŒæ”¶**: load_portfolio()æ–¹æ³•å¯ä»¥ä»æ•°æ®åº“åŠ è½½é…ç½®å¹¶åˆ›å»ºPortfolioProcessor

---

### T020 å®ç°ExecutionNode.subscribe_market_data()æ–¹æ³•
- **æ–‡ä»¶**: `src/ginkgo/workers/execution_node/node.py`
- **ä¾èµ–**: T017
- **å¹¶è¡Œ**: å¦
- **æè¿°**: å®ç°è®¢é˜…Kafka market.data topicçš„å®Œæ•´é€»è¾‘
- **è¯¦ç»†æ­¥éª¤**:
  1. æ‰©å±•ExecutionNode.subscribe_market_data()æ–¹æ³•
  2. å®ç°Kafkaæ¶ˆæ¯æ¶ˆè´¹å’Œè·¯ç”±ï¼š
     ```python
     def subscribe_market_data(self):
         """è®¢é˜…Kafka market.data topicå¹¶è·¯ç”±æ¶ˆæ¯åˆ°Portfolio"""
         import json
         from ginkgo.trading.events.price_update import EventPriceUpdate

         self.kafka_consumer = KafkaConsumer(
             'ginkgo.live.market.data',
             bootstrap_servers=['localhost:9092'],
             group_id=f'execution_node_{self.node_id}',
             auto_offset_reset='latest',
             enable_auto_commit=False,
             value_deserializer=lambda m: json.loads(m.decode('utf-8'))
         )

         def consume_loop():
             while self.is_running:
                 for message in self.kafka_consumer:
                     # è§£æEventPriceUpdate
                     event_data = message.value
                     event = EventPriceUpdate(
                         code=event_data['code'],
                         timestamp=datetime.fromisoformat(event_data['timestamp']),
                         price=event_data['price'],
                         volume=event_data.get('volume', 0)
                     )

                     # ä½¿ç”¨interest_mapè·¯ç”±åˆ°å¯¹åº”çš„Portfolio
                     portfolio_ids = self.interest_map.get_portfolios(event.code)
                     for portfolio_id in portfolio_ids:
                         if portfolio_id in self.portfolios:
                             processor = self.portfolios[portfolio_id]
                             # æ£€æŸ¥backpressure
                             if self.backpressure_checker.check_and_alert(processor):
                                 processor.put_event(event)

                     # æ‰‹åŠ¨æäº¤offset
                     self.kafka_consumer.commit()

         # å¯åŠ¨æ¶ˆè´¹çº¿ç¨‹
         self.consumer_thread = Thread(target=consume_loop, daemon=True)
         self.consumer_thread.start()
     ```
  3. æ·»åŠ å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—
- **éªŒæ”¶**: subscribe_market_data()æ–¹æ³•å¯ä»¥è®¢é˜…Kafkaå¹¶æ­£ç¡®è·¯ç”±æ¶ˆæ¯

---

### T021 å®ç°PortfolioProcessor.run()ä¸»å¾ªç¯
- **æ–‡ä»¶**: `src/ginkgo/workers/execution_node/portfolio_processor.py`
- **ä¾èµ–**: T018
- **å¹¶è¡Œ**: å¦
- **æè¿°**: å®Œå–„PortfolioProcessor.run()ä¸»å¾ªç¯ï¼Œå®ç°äº‹ä»¶åˆ†å‘é€»è¾‘
- **è¯¦ç»†æ­¥éª¤**:
  1. æ‰©å±•PortfolioProcessor.run()æ–¹æ³•
  2. å®ç°å®Œæ•´çš„äº‹ä»¶å¤„ç†å¾ªç¯ï¼š
     ```python
     def run(self):
         """ä¸»å¾ªç¯ï¼šä»queueè·å–äº‹ä»¶å¹¶è°ƒç”¨portfolio.on_event()"""
         self.is_running = True
         from ginkgo import GLOG

         GLOG.info(f"PortfolioProcessor {self.portfolio_id} started")

         while self.is_running:
             try:
                 # ä»Queueè·å–äº‹ä»¶ï¼ˆè¶…æ—¶1ç§’ï¼‰
                 event = self.queue.get(timeout=1)

                 # æ ¹æ®äº‹ä»¶ç±»å‹åˆ†å‘
                 if isinstance(event, EventPriceUpdate):
                     self.portfolio.on_price_update(event)
                 elif isinstance(event, EventOrderPartiallyFilled):
                     self.portfolio.on_order_filled(event)
                 else:
                     self.portfolio.on_event(event)

                 self.queue.task_done()

             except Exception as e:
                 GLOG.error(f"PortfolioProcessor {self.portfolio_id} error: {e}")
                 continue

         GLOG.info(f"PortfolioProcessor {self.portfolio_id} stopped")
     ```
  3. æ·»åŠ å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—
- **éªŒæ”¶**: run()ä¸»å¾ªç¯å¯ä»¥æ­£ç¡®å¤„ç†å„ç±»äº‹ä»¶

---

### 3.2 Portfolioäº‹ä»¶å¤„ç† (4ä¸ªä»»åŠ¡)

### T022 [P] æ‰©å±•Portfolioæ·»åŠ on_price_update()æ–¹æ³•
- **æ–‡ä»¶**: `src/ginkgo/core/portfolios/portfolio.py`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: æ‰©å±•PortfolioåŸºç±»ï¼Œæ·»åŠ on_price_update()æ–¹æ³•å¤„ç†å®æ—¶è¡Œæƒ…å¹¶ç”ŸæˆSignal
- **è¯¦ç»†æ­¥éª¤**:
  1. è¯»å– `src/ginkgo/core/portfolios/portfolio.py`
  2. æ·»åŠ on_price_update()æ–¹æ³•ï¼š
     ```python
     def on_price_update(self, event: EventPriceUpdate):
         """å¤„ç†å®æ—¶è¡Œæƒ…äº‹ä»¶ï¼Œç”Ÿæˆäº¤æ˜“ä¿¡å·"""
         from ginkgo import GLOG

         # æ›´æ–°æœ€æ–°ä»·æ ¼æ•°æ®
         self._update_price_data(event.code, event.price, event.timestamp)

         # è°ƒç”¨ç­–ç•¥ç”Ÿæˆä¿¡å·
         signals = self.strategy.cal(
             portfolio_info=self.get_portfolio_info(),
             event=event
         )

         # å¤„ç†ç”Ÿæˆçš„ä¿¡å·
         for signal in signals:
             self._on_signal(signal)

         GLOG.debug(f"Portfolio {self.portfolio_id} processed price update for {event.code}")
     ```
  3. æ·»åŠ è¾…åŠ©æ–¹æ³•ï¼š_update_price_data(), _on_signal()
- **éªŒæ”¶**: on_price_update()æ–¹æ³•å¯ä»¥å¤„ç†EventPriceUpdateå¹¶ç”ŸæˆSignal

---

### T023 [P] æ‰©å±•Portfolioæ·»åŠ on_order_filled()æ–¹æ³•
- **æ–‡ä»¶**: `src/ginkgo/core/portfolios/portfolio.py`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: æ‰©å±•PortfolioåŸºç±»ï¼Œæ·»åŠ on_order_filled()æ–¹æ³•å¤„ç†è®¢å•æˆäº¤å¹¶æ›´æ–°æŒä»“å’Œç°é‡‘
- **è¯¦ç»†æ­¥éª¤**:
  1. åœ¨Portfolioç±»ä¸­æ·»åŠ on_order_filled()æ–¹æ³•ï¼š
     ```python
     def on_order_filled(self, event: EventOrderPartiallyFilled):
         """å¤„ç†è®¢å•æˆäº¤äº‹ä»¶ï¼Œæ›´æ–°æŒä»“å’Œç°é‡‘"""
         from ginkgo import GLOG

         # æ›´æ–°æŒä»“
         if event.direction == DIRECTION_TYPES.LONG:
             self._add_position(
                 code=event.code,
                 volume=event.filled_volume,
                 price=event.filled_price
             )
         else:  # SHORT
             self._reduce_position(
                 code=event.code,
                 volume=event.filled_volume,
                 price=event.filled_price
             )

         # æ›´æ–°ç°é‡‘
         self._update_cash(event.filled_volume, event.filled_price, event.direction)

         # åŒæ­¥åˆ°æ•°æ®åº“
         self.sync_state_to_db()

         GLOG.info(f"Portfolio {self.portfolio_id} order filled: {event.order_id}")
     ```
  3. æ·»åŠ è¾…åŠ©æ–¹æ³•ï¼š_add_position(), _reduce_position(), _update_cash()
- **éªŒæ”¶**: on_order_filled()æ–¹æ³•å¯ä»¥å¤„ç†EventOrderPartiallyFilledå¹¶æ›´æ–°çŠ¶æ€

---

### T024 å®ç°Portfolio.sync_state_to_db()æ–¹æ³•
- **æ–‡ä»¶**: `src/ginkgo/core/portfolios/portfolio.py`
- **ä¾èµ–**: T022, T023
- **å¹¶è¡Œ**: å¦
- **æè¿°**: å®ç°åŒæ­¥å†™å…¥æŒä»“å’Œç°é‡‘åˆ°æ•°æ®åº“çš„æ–¹æ³•
- **è¯¦ç»†æ­¥éª¤**:
  1. åœ¨Portfolioç±»ä¸­å®ç°sync_state_to_db()æ–¹æ³•ï¼š
     ```python
     def sync_state_to_db(self):
         """åŒæ­¥æŒä»“å’Œç°é‡‘åˆ°æ•°æ®åº“"""
         from ginkgo import services, GLOG

         # å†™å…¥æŒä»“åˆ°ClickHouse
         position_crud = services.data.cruds.position()
         for code, position in self.positions.items():
             position_crud.add_position(position)

         # å†™å…¥èµ„é‡‘çŠ¶æ€åˆ°MySQL
         # ... (éœ€è¦å®ç°èµ„é‡‘çŠ¶æ€çš„CRUDæ“ä½œ)

         GLOG.debug(f"Portfolio {self.portfolio_id} state synced to database")
     ```
  2. ä½¿ç”¨@time_loggerå’Œ@retryè£…é¥°å™¨
  3. æ·»åŠ é”™è¯¯å¤„ç†
- **éªŒæ”¶**: sync_state_to_db()æ–¹æ³•å¯ä»¥æ­£ç¡®åŒæ­¥çŠ¶æ€åˆ°æ•°æ®åº“

---

### T025 [P] ç¼–å†™Portfolioäº‹ä»¶å¤„ç†å•å…ƒæµ‹è¯•
- **æ–‡ä»¶**: `tests/unit/live/test_portfolio_events.py`
- **ä¾èµ–**: T022, T023, T024
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: ç¼–å†™Portfolioäº‹ä»¶å¤„ç†çš„å•å…ƒæµ‹è¯•
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºæµ‹è¯•æ–‡ä»¶ `tests/unit/live/test_portfolio_events.py`
  2. å®ç°æµ‹è¯•ç”¨ä¾‹ï¼š
     ```python
     import pytest
     from ginkgo.core.portfolios.portfolio import Portfolio
     from ginkgo.trading.events.price_update import EventPriceUpdate
     from ginkgo.trading.events.order_lifecycle_events import EventOrderPartiallyFilled
     from ginkgo.trading.enums import DIRECTION_TYPES

     @pytest.mark.unit
     def test_portfolio_on_price_update():
         """æµ‹è¯•Portfolioå¤„ç†ä»·æ ¼æ›´æ–°äº‹ä»¶"""
         portfolio = Portfolio(portfolio_id="test", initial_cash=100000)
         event = EventPriceUpdate(
             code="000001.SZ",
             timestamp=datetime.now(),
             price=10.5,
             volume=1000
         )

         # Mockç­–ç•¥
         portfolio.strategy = MockStrategy()

         # å¤„ç†äº‹ä»¶
         portfolio.on_price_update(event)

         # éªŒè¯ä¿¡å·ç”Ÿæˆ
         assert len(portfolio.signals) > 0

     @pytest.mark.unit
     def test_portfolio_on_order_filled():
         """æµ‹è¯•Portfolioå¤„ç†è®¢å•æˆäº¤äº‹ä»¶"""
         portfolio = Portfolio(portfolio_id="test", initial_cash=100000)
         event = EventOrderPartiallyFilled(
             order_id="test_order",
             code="000001.SZ",
             direction=DIRECTION_TYPES.LONG,
             filled_volume=100,
             filled_price=10.5,
             timestamp=datetime.now()
         )

         # å¤„ç†äº‹ä»¶
         portfolio.on_order_filled(event)

         # éªŒè¯æŒä»“æ›´æ–°
         assert "000001.SZ" in portfolio.positions
         assert portfolio.positions["000001.SZ"].volume == 100
     ```
  3. æ·»åŠ æ›´å¤šæµ‹è¯•ç”¨ä¾‹
- **éªŒæ”¶**: æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡

---

### 3.3 LiveCoreå®¹å™¨ä¸è®¢å•æäº¤æµç¨‹ (5ä¸ªä»»åŠ¡)

### T026 å®ç°ExecutionNode.submit_order()æ–¹æ³•
- **æ–‡ä»¶**: `src/ginkgo/workers/execution_node/node.py`
- **ä¾èµ–**: T019
- **å¹¶è¡Œ**: å¦
- **æè¿°**: å®ç°å°†Orderå‘å¸ƒåˆ°Kafka orders.submission topicçš„æ–¹æ³•
- **è¯¦ç»†æ­¥éª¤**:
  1. åœ¨ExecutionNodeç±»ä¸­å®ç°submit_order()æ–¹æ³•ï¼š
     ```python
     def submit_order(self, order: Order):
         """å°†Orderæäº¤åˆ°Kafka orders.submission topic"""
         from ginkgo.data.drivers.ginkgo_kafka import GinkgoProducer
         import json

         producer = GinkgoProducer(bootstrap_servers="localhost:9092")

         # åºåˆ—åŒ–Order
         order_data = {
             "order_id": order.uuid,
             "portfolio_id": order.portfolio_id,
             "code": order.code,
             "direction": order.direction.value,
             "volume": order.volume,
             "price": order.price,
             "timestamp": order.timestamp.isoformat()
         }

         # å‘é€åˆ°Kafka
         producer.produce("ginkgo.live.orders.submission", json.dumps(order_data))
         producer.flush()

         from ginkgo import GLOG
         GLOG.info(f"Order {order.uuid} submitted to Kafka")
     ```
  2. æ·»åŠ å¼‚å¸¸å¤„ç†
- **éªŒæ”¶**: submit_order()æ–¹æ³•å¯ä»¥å°†Orderå‘å¸ƒåˆ°Kafka

---

### T027 [P] åˆ›å»ºLiveCoreä¸»å…¥å£ï¼ˆå¤šçº¿ç¨‹å®¹å™¨ï¼‰
- **æ–‡ä»¶**: `src/ginkgo/livecore/main.py`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: åˆ›å»ºLiveCoreä¸»å…¥å£ï¼Œå¯åŠ¨DataManager/LiveEngine/Schedulerçº¿ç¨‹
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºæ–‡ä»¶ `src/ginkgo/livecore/main.py`
  2. å®ç°LiveCoreå®¹å™¨ï¼š
     ```python
     from threading import Thread
     import signal
     import sys

     class LiveCore:
         """LiveCoreä¸šåŠ¡é€»è¾‘å±‚å®¹å™¨ï¼ˆå¤šçº¿ç¨‹ï¼‰"""

         def __init__(self):
             self.threads = []
             self.is_running = False

         def start(self):
             """å¯åŠ¨æ‰€æœ‰ç»„ä»¶çº¿ç¨‹"""
             self.is_running = True

             # å¯åŠ¨DataManagerçº¿ç¨‹
             from ginkgo.livecore.data_manager import DataManager
             data_manager = DataManager()
             data_thread = Thread(target=data_manager.run, daemon=True)
             data_thread.start()
             self.threads.append(data_thread)

             # å¯åŠ¨LiveEngineçº¿ç¨‹
             from ginkgo.livecore.live_engine import LiveEngine
             live_engine = LiveEngine()
             engine_thread = Thread(target=live_engine.run, daemon=True)
             engine_thread.start()
             self.threads.append(engine_thread)

             # å¯åŠ¨Schedulerçº¿ç¨‹
             from ginkgo.livecore.scheduler import Scheduler
             scheduler = Scheduler()
             scheduler_thread = Thread(target=scheduler.run, daemon=True)
             scheduler_thread.start()
             self.threads.append(scheduler_thread)

             # æ³¨å†Œä¿¡å·å¤„ç†
             signal.signal(signal.SIGINT, self._signal_handler)
             signal.signal(signal.SIGTERM, self._signal_handler)

         def _signal_handler(self, signum, frame):
             """å¤„ç†åœæ­¢ä¿¡å·"""
             from ginkgo import GLOG
             GLOG.info(f"Received signal {signum}, shutting down...")
             self.stop()

         def stop(self):
             """åœæ­¢æ‰€æœ‰ç»„ä»¶"""
             self.is_running = False
             for thread in self.threads:
                 thread.join(timeout=5)

         def wait(self):
             """ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ"""
             for thread in self.threads:
                 thread.join()

     if __name__ == "__main__":
         livecore = LiveCore()
         livecore.start()
         livecore.wait()
     ```
  3. æ·»åŠ å¤´éƒ¨æ³¨é‡Š
- **éªŒæ”¶**: LiveCoreå¯ä»¥å¯åŠ¨æ‰€æœ‰ç»„ä»¶çº¿ç¨‹

---

### T028 [P] åˆ›å»ºLiveEngineå®¹å™¨çº¿ç¨‹
- **æ–‡ä»¶**: `src/ginkgo/livecore/live_engine.py`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: åˆ›å»ºLiveEngineå®¹å™¨çº¿ç¨‹ï¼Œè®¢é˜…orders.submission topic
- **å°è£…ç­–ç•¥**: å°è£…ç°æœ‰`trading/engines/engine_live.py`ä¸­çš„EngineLiveç±»ï¼Œåˆ›å»ºå®¹å™¨ç±»è°ƒç”¨å…¶æ–¹æ³•ï¼Œè€Œä¸æ˜¯åˆ›å»ºæ–°ç±»
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºæ–‡ä»¶ `src/ginkgo/livecore/live_engine.py`
  2. å®ç°LiveEngineå®¹å™¨ç±»ï¼ˆå°è£…EngineLiveï¼‰ï¼š
     ```python
     from threading import Thread
     import json
     from ginkgo.trading.engines.engine_live import EngineLive
     from ginkgo.livecore.trade_gateway_adapter import TradeGatewayAdapter

     class LiveEngine:
         """LiveEngineå®ç›˜å¼•æ“å®¹å™¨çº¿ç¨‹ï¼ˆå°è£…EngineLiveï¼‰"""

         def __init__(self):
             # å°è£…ç°æœ‰çš„EngineLiveå®ä¾‹
             self.engine = EngineLive()
             self.gateway = TradeGatewayAdapter()
             self.kafka_consumer = None

         def run(self):
             """è¿è¡ŒLiveEngineï¼šè®¢é˜…Kafka orders.submission topic"""
             from kafka import KafkaConsumer
             from ginkgo import GLOG

             self.kafka_consumer = KafkaConsumer(
                 'ginkgo.live.orders.submission',
                 bootstrap_servers=['localhost:9092'],
                 group_id='live_engine',
                 auto_offset_reset='latest',
                 enable_auto_commit=False,
                 value_deserializer=lambda m: json.loads(m.decode('utf-8'))
             )

             GLOG.info("LiveEngine started, consuming orders...")

             while True:
                 for message in self.kafka_consumer:
                     order_data = message.value
                     # è°ƒç”¨å°è£…çš„EngineLiveå¤„ç†è®¢å•
                     self._process_order(order_data)
                     self.kafka_consumer.commit()

         def _process_order(self, order_data: dict):
             """å¤„ç†è®¢å•ï¼šè°ƒç”¨EngineLiveå’ŒTradeGatewayæ‰§è¡Œ"""
             from ginkgo import GLOG

             # è°ƒç”¨EngineLiveå¤„ç†è®¢å•ï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰
             fill_event = self.engine.process_order(order_data)

             # å¦‚æœEngineLiveè¿”å›äº†æˆäº¤äº‹ä»¶ï¼Œå‘å¸ƒåˆ°Kafka
             if fill_event:
                 self._publish_order_feedback(fill_event)

             GLOG.info(f"Order {order_data['order_id']} processed")

         def _publish_order_feedback(self, fill_event):
             """å‘å¸ƒè®¢å•å›æŠ¥åˆ°Kafka orders.feedback topic"""
             from ginkgo.data.drivers.ginkgo_kafka import GinkgoProducer

             producer = GinkgoProducer(bootstrap_servers="localhost:9092")
             producer.produce("ginkgo.live.orders.feedback", fill_event.to_json())
             producer.flush()
     ```
  3. æ·»åŠ å¤´éƒ¨æ³¨é‡Šï¼ˆUpstream: DataManager, Scheduler; Downstream: TradeGatewayAdapter; Role: å®¹å™¨çº¿ç¨‹ï¼Œå°è£…EngineLiveå¤„ç†Kafkaè®¢å•ï¼‰
- **éªŒæ”¶**: LiveEngineå¯ä»¥è®¢é˜…Kafkaå¹¶æ­£ç¡®å°è£…EngineLiveå¤„ç†è®¢å•

---

### T029 [P] åˆ›å»ºTradeGatewayé€‚é…å™¨
- **æ–‡ä»¶**: `src/ginkgo/livecore/trade_gateway_adapter.py`
- **ä¾èµ–**: æ— 
- **å¹¶è¡Œ**: æ˜¯
- **æè¿°**: åˆ›å»ºTradeGatewayé€‚é…å™¨ï¼Œå°è£…trading/gateway/trade_gateway.py
- **è¯¦ç»†æ­¥éª¤**:
  1. åˆ›å»ºæ–‡ä»¶ `src/ginkgo/livecore/trade_gateway_adapter.py`
  2. å®ç°TradeGatewayé€‚é…å™¨ï¼š
     ```python
     from ginkgo.trading.gateway.trade_gateway import TradeGateway

     class TradeGatewayAdapter:
         """äº¤æ˜“ç½‘å…³é€‚é…å™¨ï¼Œå°è£…TradeGatewayç”¨äºå®ç›˜äº¤æ˜“"""

         def __init__(self):
             self.gateway = TradeGateway()

         def submit_order(self, order_data: dict):
             """æäº¤è®¢å•åˆ°åˆ¸å•†"""
             from ginkgo.trading.entities.order import Order
             from ginkgo.trading.enums import DIRECTION_TYPES, ORDER_TYPES

             # æ„é€ Orderå¯¹è±¡
             order = Order(
                 portfolio_id=order_data['portfolio_id'],
                 code=order_data['code'],
                 direction=DIRECTION_TYPES(order_data['direction']),
                 volume=order_data['volume'],
                 price=order_data['price'],
                 order_type=ORDER_TYPES.LIMIT
             )

             # è°ƒç”¨TradeGatewayæ‰§è¡Œ
             fill_event = self.gateway.submit_order(order)

             return fill_event
     ```
  3. æ·»åŠ å¤´éƒ¨æ³¨é‡Š
- **éªŒæ”¶**: TradeGatewayAdapterå¯ä»¥æ­£ç¡®å°è£…TradeGateway

---

### T030 æ”¹é€ GinkgoProducerçš„acks=1ä¸ºacks=all
- **æ–‡ä»¶**: `src/ginkgo/data/drivers/ginkgo_kafka.py`
- **ä¾èµ–**: T014
- **å¹¶è¡Œ**: å¦
- **æè¿°**: æ”¹é€ GinkgoProducerçš„acksé…ç½®ï¼Œä»acks=1æ”¹ä¸ºacks=allç¡®ä¿æ¶ˆæ¯å¯é æ€§
- **è¯¦ç»†æ­¥éª¤**:
  1. è¯»å– `src/ginkgo/data/drivers/ginkgo_kafka.py`
  2. æ‰¾åˆ°GinkgoProducerç±»çš„__init__æ–¹æ³•
  3. ä¿®æ”¹acksé…ç½®ï¼š
     ```python
     # æ”¹é€ å‰
     self.producer = KafkaProducer(
         bootstrap_servers=bootstrap_servers,
         acks=1,  # âŒ ç­‰å¾…leaderç¡®è®¤
         ...
     )

     # æ”¹é€ å
     self.producer = KafkaProducer(
         bootstrap_servers=bootstrap_servers,
         acks="all",  # âœ… ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
         enable_idempotence=True,  # âœ… å¯ç”¨å¹‚ç­‰æ€§
         ...
     )
     ```
  4. æ›´æ–°ç›¸å…³æ–‡æ¡£æ³¨é‡Š
- **éªŒæ”¶**: GinkgoProducerä½¿ç”¨acks=allå’Œenable_idempotence=True

---

## âœ… å·²å®Œæˆä»»åŠ¡ (0ä¸ª)

*(æš‚æ— )*

---

## ğŸ“Š è¿›åº¦è·Ÿè¸ª

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»ä»»åŠ¡æ•° | 14 |
| å·²å®Œæˆ | 0 |
| è¿›è¡Œä¸­ | 0 |
| å¾…åŠ | 14 |
| å®Œæˆè¿›åº¦ | 0% |

---

## ğŸ”— ä¾èµ–å…³ç³»

```
Phase 2: Foundational
    â†“
Phase 3: User Story 1 (æœ¬é˜¶æ®µ) â† MVP
    â†“
Phase 4: User Story 2
Phase 6: User Story 4
```

---

## ğŸ“ å¤‡æ³¨

- **æœ¬é˜¶æ®µæ˜¯MVPæ ¸å¿ƒ**ï¼Œå®Œæˆå³å¯éªŒè¯å®ç›˜äº¤æ˜“æ¶æ„çš„åŸºç¡€åŠŸèƒ½
- T017-T021å¯ä»¥å¹¶è¡Œï¼ˆ4ä¸ªä»»åŠ¡ï¼‰
- T022-T023å¯ä»¥å¹¶è¡Œ
- T027-T029å¯ä»¥å¹¶è¡Œï¼ˆ3ä¸ªä»»åŠ¡ï¼‰
- æœ¬é˜¶æ®µå®Œæˆåï¼Œå³å¯è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•ï¼ŒéªŒè¯å»¶è¿Ÿ<200ms

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0
**æœ€åæ›´æ–°**: 2026-01-04
