# Upstream: FileService (æ–‡ä»¶ç®¡ç†ä¸šåŠ¡æœåŠ¡)ã€PortfolioService (æ–‡ä»¶ç»‘å®šç®¡ç†)
# Downstream: BaseCRUD (ç»§æ‰¿æä¾›æ ‡å‡†CRUDèƒ½åŠ›å’Œè£…é¥°å™¨@time_logger/@retry/@cache)ã€MFile (MySQLæ–‡ä»¶æ¨¡å‹)ã€FileInfoå®ä½“(ä¸šåŠ¡æ–‡ä»¶ä¿¡æ¯å®ä½“)ã€FILE_TYPES (æ–‡ä»¶ç±»å‹æšä¸¾STRATEGY/ANALYZER/SELECTOR/SIZER/RISKMANAGER/DATA/OTHER)
# Role: FileCRUDæ–‡ä»¶CRUDæ“ä½œç»§æ‰¿BaseCRUDæä¾›æ–‡ä»¶ç®¡ç†å’Œä¸šåŠ¡æŸ¥è¯¢æ–¹æ³•æ”¯æŒäº¤æ˜“ç³»ç»ŸåŠŸèƒ½å’Œç»„ä»¶é›†æˆæä¾›å®Œæ•´ä¸šåŠ¡æ”¯æŒ






from typing import List, Optional, Union, Any, Dict
import pandas as pd
from datetime import datetime

from ginkgo.data.crud.base_crud import BaseCRUD
from ginkgo.data.models import MFile
from ginkgo.enums import SOURCE_TYPES, FILE_TYPES
from ginkgo.libs import GLOG
from ginkgo.trading.core.file_info import FileInfo
from ginkgo.data.access_control import restrict_crud_access


@restrict_crud_access
class FileCRUD(BaseCRUD[MFile]):
    """
    File CRUD operations.
    """

    # ç±»çº§åˆ«å£°æ˜ï¼Œæ”¯æŒè‡ªåŠ¨æ³¨å†Œ

    _model_class = MFile

    def __init__(self):
        super().__init__(MFile)

    def _get_enum_mappings(self) -> Dict[str, Any]:
        """
        ğŸ¯ Define field-to-enum mappings for FileCRUD.

        Returns:
            Dictionary mapping field names to enum classes
        """
        return {
            'type': FILE_TYPES,
        }

    def _get_field_config(self) -> dict:
        """
        å®šä¹‰ File æ•°æ®çš„å­—æ®µé…ç½® - å¿…å¡«å­—æ®µéªŒè¯

        Returns:
            dict: å­—æ®µé…ç½®å­—å…¸
        """
        return {
            # æ–‡ä»¶ç±»å‹ - æšä¸¾å€¼
            'type': {
                'type': 'enum',
                'choices': [f for f in FILE_TYPES]
            },

            # æ–‡ä»¶å - éç©ºå­—ç¬¦ä¸²ï¼Œæœ€å¤§40å­—ç¬¦ï¼ˆä¸æ¨¡å‹String(40)ä¸€è‡´ï¼‰
            'name': {
                'type': 'string',
                'min': 1,
                'max': 40
            },

            # æ–‡ä»¶æ•°æ® - äºŒè¿›åˆ¶æ•°æ®
            'data': {
                'type': 'bytes'
            },

            # version, parent_uuid, is_latest å­—æ®µæœ‰é»˜è®¤å€¼ï¼Œä¸éœ€è¦éªŒè¯ä¸ºå¿…å¡«
            # sourceå­—æ®µç§»é™¤éªŒè¯é…ç½®ï¼Œä½¿ç”¨æ¨¡å‹é»˜è®¤å€¼ SOURCE_TYPES.OTHER
        }

    def _create_from_params(self, **kwargs) -> MFile:
        """
        Hook method: Create MFile from parameters.
        """
        # Convert string file_type to enum if needed
        file_type = kwargs.get("file_type", kwargs.get("type", FILE_TYPES.OTHER))
        if isinstance(file_type, str):
            # Map common string types to enum values
            type_mapping = {
                "TEXT": FILE_TYPES.OTHER,
                "PYTHON": FILE_TYPES.STRATEGY,
                "JSON": FILE_TYPES.OTHER,
                "ANALYZER": FILE_TYPES.ANALYZER,
                "INDEX": FILE_TYPES.INDEX,
                "STRATEGY": FILE_TYPES.STRATEGY,
                "ENGINE": FILE_TYPES.ENGINE,
                "HANDLER": FILE_TYPES.HANDLER,
            }
            file_type = type_mapping.get(file_type.upper(), FILE_TYPES.OTHER)
        
        return MFile(
            type=FILE_TYPES.validate_input(file_type),
            name=kwargs.get("filename", kwargs.get("name", "ginkgo_file")),
            data=kwargs.get("data", b""),
            source=SOURCE_TYPES.validate_input(kwargs.get("source", SOURCE_TYPES.SIM)),
            desc=kwargs.get("desc"),  # æ·»åŠ descå‚æ•°
        )

    def _convert_input_item(self, item: Any) -> Optional[MFile]:
        """
        Hook method: Convert file objects to MFile.
        """
        if isinstance(item, FileInfo):
            # Convert string type to enum if needed
            file_type = item.type
            if isinstance(file_type, str):
                type_mapping = {
                    "TEXT": FILE_TYPES.OTHER,
                    "PYTHON": FILE_TYPES.STRATEGY,
                    "JSON": FILE_TYPES.OTHER,
                    "ANALYZER": FILE_TYPES.ANALYZER,
                    "INDEX": FILE_TYPES.INDEX,
                    "STRATEGY": FILE_TYPES.STRATEGY,
                    "ENGINE": FILE_TYPES.ENGINE,
                    "HANDLER": FILE_TYPES.HANDLER,
                }
                file_type = type_mapping.get(file_type.upper(), FILE_TYPES.OTHER)
            
            return MFile(
                type=FILE_TYPES.validate_input(file_type),
                name=item.name,
                data=getattr(item, 'data', b""),
                source=SOURCE_TYPES.validate_input(item.source),
            )
        return None


    def _convert_models_to_business_objects(self, models: List) -> List:
        """
        ğŸ¯ Convert models to business objects.

        Args:
            models: List of models with enum fields already fixed

        Returns:
            List of models (business object doesn't exist yet)
        """
        # For now, return models as-is since business object doesn't exist yet
        return models

    def _convert_output_items(self, items: List, output_type: str = "model") -> List[Any]:
        """
        Hook method: Convert objects for business layer.
        """
        return items

    def _convert_output_items(self, items: List[MFile], output_type: str = "model") -> List[Any]:
        """
        Hook method: Convert MFile objects for business layer.
        """
        if output_type == "file_info":
            return [FileInfo(item) for item in items]
        return items

    # Business Helper Methods
    def find_by_file_id(self, file_id: str, as_dataframe: bool = False) -> Union[List[MFile], pd.DataFrame]:
        """
        Business helper: Find file by ID.
        """
        return self.find(filters={"uuid": file_id}, page_size=1,
                        as_dataframe=as_dataframe)

    def find_by_filename(self, filename: str, as_dataframe: bool = False) -> Union[List[MFile], pd.DataFrame]:
        """
        Business helper: Find files by filename pattern.
        """
        return self.find(filters={"name__like": filename}, order_by="update_at", desc_order=True,
                        as_dataframe=as_dataframe)

    def find_by_type(self, file_type: str, as_dataframe: bool = False) -> Union[List[MFile], pd.DataFrame]:
        """
        Business helper: Find files by type.
        """
        # Convert string type to enum if needed
        if isinstance(file_type, str):
            type_mapping = {
                "TEXT": FILE_TYPES.OTHER,
                "PYTHON": FILE_TYPES.STRATEGY,
                "JSON": FILE_TYPES.OTHER,
                "ANALYZER": FILE_TYPES.ANALYZER,
                "INDEX": FILE_TYPES.INDEX,
                "STRATEGY": FILE_TYPES.STRATEGY,
                "ENGINE": FILE_TYPES.ENGINE,
                "HANDLER": FILE_TYPES.HANDLER,
            }
            file_type = type_mapping.get(file_type.upper(), FILE_TYPES.OTHER)
        
        return self.find(filters={"type": file_type}, order_by="update_at", desc_order=True,
                        as_dataframe=as_dataframe)

    def find_by_size_range(self, min_size: int, max_size: int,
                          as_dataframe: bool = False) -> Union[List[MFile], pd.DataFrame]:
        """
        Business helper: Find files by size range (not supported by MFile model).
        """
        GLOG.DEBUG("File size range search not supported by MFile model")
        return self.find(filters={}, as_dataframe=as_dataframe)

    def get_total_size_by_type(self, file_type: str) -> int:
        """
        Business helper: Get total size of files by type (not supported by MFile model).
        """
        GLOG.DEBUG("File size calculation not supported by MFile model")
        files = self.find_by_type(file_type, as_dataframe=False)
        return len(files)

    def delete_by_file_id(self, file_id: str) -> None:
        """
        Business helper: Delete file by ID.
        """
        GLOG.DEBUG(f"åˆ é™¤æ–‡ä»¶è®°å½•: {file_id}")
        return self.remove({"uuid": file_id})

    # ç‰ˆæœ¬ç®¡ç†æ–¹æ³•
    def get_latest_by_name(self, name: str, file_type: FILE_TYPES = None) -> Optional[MFile]:
        """
        è·å–æŒ‡å®šåç§°çš„æœ€æ–°ç‰ˆæœ¬æ–‡ä»¶

        Args:
            name: æ–‡ä»¶åç§°
            file_type: æ–‡ä»¶ç±»å‹ï¼ˆå¯é€‰ï¼‰

        Returns:
            æœ€æ–°ç‰ˆæœ¬çš„MFileå¯¹è±¡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        filters = {"name": name, "is_latest": True}
        if file_type is not None:
            filters["type"] = file_type
        result = self.find(filters=filters, page_size=1)
        return result[0] if result else None

    def get_version_history(self, name: str, file_type: FILE_TYPES = None) -> List[MFile]:
        """
        è·å–æŒ‡å®šæ–‡ä»¶çš„æ‰€æœ‰ç‰ˆæœ¬

        Args:
            name: æ–‡ä»¶åç§°
            file_type: æ–‡ä»¶ç±»å‹ï¼ˆå¯é€‰ï¼‰

        Returns:
            æŒ‰åˆ›å»ºæ—¶é—´æ’åºçš„ç‰ˆæœ¬åˆ—è¡¨
        """
        filters = {"name": name}
        if file_type is not None:
            filters["type"] = file_type
        return self.find(filters=filters, order_by="create_at", desc_order=False)

    def create_new_version(self, file_uuid: str, new_data: bytes = None, new_name: str = None) -> MFile:
        """
        åŸºäºç°æœ‰æ–‡ä»¶åˆ›å»ºæ–°ç‰ˆæœ¬

        Args:
            file_uuid: å½“å‰æ–‡ä»¶çš„UUIDï¼ˆå¯ä»¥æ˜¯ä»»æ„ç‰ˆæœ¬ï¼‰
            new_data: æ–°çš„ä»£ç å†…å®¹ï¼ˆå¯é€‰ï¼‰
            new_name: æ–°çš„åç§°ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ–°åˆ›å»ºçš„MFileå¯¹è±¡
        """
        old_files = self.find(filters={"uuid": file_uuid}, page_size=1)
        if not old_files:
            raise ValueError(f"File not found: {file_uuid}")
        old_file = old_files[0]

        # è·å–è¯¥æ–‡ä»¶åçš„æœ€æ–°ç‰ˆæœ¬ï¼Œç”¨äºè®¡ç®—æ–°ç‰ˆæœ¬å·
        latest_file = self.get_latest_by_name(old_file.name, old_file.type)
        if not latest_file:
            raise ValueError(f"No latest version found for: {old_file.name}")

        # å°†æ‰€æœ‰ç‰ˆæœ¬æ ‡è®°ä¸ºéæœ€æ–°
        self.modify(filters={"name": old_file.name, "type": old_file.type}, updates={"is_latest": False})

        # ä»æœ€æ–°ç‰ˆæœ¬å·é€’å¢
        new_version = self._increment_version(latest_file.version)

        # åˆ›å»ºæ–°ç‰ˆæœ¬
        return MFile(
            name=new_name or old_file.name,
            type=old_file.type,
            version=new_version,
            parent_uuid=latest_file.uuid,  # æŒ‡å‘ä¹‹å‰çš„æœ€æ–°ç‰ˆæœ¬
            is_latest=True,
            data=new_data if new_data is not None else old_file.data,
            source=old_file.source,
            desc=old_file.desc,
        )

    def _increment_version(self, version: str) -> str:
        """
        ç‰ˆæœ¬å·é€’å¢: 1.0.0 -> 1.0.1 -> 1.0.2...

        Args:
            version: å½“å‰ç‰ˆæœ¬å·

        Returns:
            é€’å¢åçš„ç‰ˆæœ¬å·
        """
        try:
            parts = version.split('.')
            if len(parts) == 3:
                major, minor, patch = int(parts[0]), int(parts[1]), int(parts[2])
                return f"{major}.{minor}.{patch + 1}"
        except (ValueError, AttributeError):
            pass
        return "1.0.1"  # é»˜è®¤æ–°ç‰ˆæœ¬
