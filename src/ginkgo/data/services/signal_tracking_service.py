# Upstream: Strategy Signal Tracking (ä¿¡å·æ‰§è¡Œè¿½è¸ª)ã€EventExecutionConfirmed (æ‰§è¡Œç¡®è®¤äº‹ä»¶)
# Downstream: BaseService (ç»§æ‰¿æä¾›æœåŠ¡åŸºç¡€èƒ½åŠ›)ã€SignalTrackerCRUD (ä¿¡å·è¿½è¸ªCRUDæ“ä½œ)ã€MSignalTracker (ä¿¡å·è¿½è¸ªæ¨¡å‹)ã€EXECUTION_MODE/TRACKINGSTATUS_TYPES/ACCOUNT_TYPE (æ‰§è¡Œæ¨¡å¼/è¿½è¸ªçŠ¶æ€/è´¦æˆ·ç±»å‹æšä¸¾)
# Role: SignalTrackingServiceä¿¡å·è¿½è¸ªæœåŠ¡æä¾›ä¿¡å·æ‰§è¡Œè¿½è¸ªå’Œç»Ÿè®¡åŠŸèƒ½æ”¯æŒäº¤æ˜“ç³»ç»ŸåŠŸèƒ½å’Œç»„ä»¶é›†æˆæä¾›å®Œæ•´ä¸šåŠ¡æ”¯æŒ






from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
from decimal import Decimal

from ginkgo.data.crud.signal_tracker_crud import SignalTrackerCRUD
from ginkgo.data.models.model_signal_tracker import MSignalTracker
from ginkgo.trading.entities.signal import Signal
from ginkgo.enums import EXECUTION_MODE, TRACKINGSTATUS_TYPES, ACCOUNT_TYPE
from ginkgo.libs import GLOG, time_logger, retry, to_decimal, datetime_normalize
from ginkgo.data.services.base_service import ServiceResult, BaseService


class SignalTrackingService(BaseService):
    """
    Signal Tracking Service Layer

    Provides complete business logic for signal execution tracking, including creating tracking records,
    confirming execution, statistical analysis, etc., following flat architecture design
    """

    def __init__(self, tracker_crud: SignalTrackerCRUD):
        """
        Initialize signal tracking service

        Args:
            tracker_crud: Signal tracking data access object
        """
        # Call parent constructor, following flat architecture pattern
        super().__init__(crud_repo=tracker_crud)
        self._crud_repo = tracker_crud

    @time_logger
    @retry(max_try=3)
    def create(
        self,
        signal: Signal,
        execution_mode: EXECUTION_MODE,
        account_type: ACCOUNT_TYPE,
        engine_id: Optional[str] = None
    ) -> ServiceResult:
        """
        Create tracking record for signal

        Args:
            signal: Trading signal
            execution_mode: Execution mode
            account_type: Account type
            engine_id: Engine ID

        Returns:
            ServiceResult[MSignalTracker]: Service result
        """
        try:
            # Get signal business time (key field)
            signal_business_time = signal.business_timestamp or signal.timestamp

            # Create MSignalTracker object directly
            from ginkgo.data.models.model_signal_tracker import MSignalTracker

            tracker = MSignalTracker(
                signal_id=signal.uuid,
                strategy_id=getattr(signal, 'strategy_id', ''),
                portfolio_id=signal.portfolio_id,
                engine_id=engine_id or "",
                execution_mode=execution_mode,
                account_type=account_type,
                expected_code=signal.code,
                expected_direction=signal.direction,
                expected_price=float(getattr(signal, 'price', 0)),
                expected_volume=getattr(signal, 'volume', 0),

                # Time fields - simplified approach
                timestamp=datetime.now(),                    # System creation time
                business_timestamp=signal_business_time,     # Signal business time
                expected_timestamp=signal_business_time,     # Expected execution time (simplified)
                notification_sent_at=datetime.now(),         # Notification sent time
                tracking_status=TRACKINGSTATUS_TYPES.NOTIFIED,
                time_delay_seconds=None,                     # Calculated when execution is confirmed
            )

            tracker = self._crud_repo.add(tracker)

            if tracker is None:
                return ServiceResult.error("Failed to create signal tracking: database insertion returned None")

            GLOG.INFO(f"Created signal tracking for signal_id: {signal.uuid}")
            return ServiceResult.success(tracker)
            
        except Exception as e:
            GLOG.ERROR(f"Failed to create signal tracking: {e}")
            return ServiceResult.error(f"Failed to create signal tracking: {e}")

    @time_logger
    @retry(max_try=3)
    def set_confirmed(
        self,
        signal_id: str,
        actual_price: float,
        actual_volume: int,
        execution_timestamp: Optional[datetime] = None
    ) -> ServiceResult:
        """
        Confirm signal execution

        Args:
            signal_id: Signal ID
            actual_price: Actual price
            actual_volume: Actual volume
            execution_timestamp: Execution time

        Returns:
            ServiceResult[MSignalTracker]: Service result
        """
        try:
            tracker = self._crud_repo.find_by_signal_id(signal_id)
            if not tracker:
                return ServiceResult.error(f"Signal tracking record not found: {signal_id}")
            
            if tracker.is_executed():
                return ServiceResult.error(f"Signal already confirmed execution: {signal_id}")
            
            # ğŸ¯ Actual execution time: prefer passed business time, otherwise use signal business time
            actual_execution_time = execution_timestamp or tracker.business_timestamp

            # ğŸ¯ Calculate execution delay (based on business time)
            time_delay_seconds = None
            if tracker.expected_timestamp and actual_execution_time:
                time_delay_seconds = (actual_execution_time - tracker.expected_timestamp).total_seconds()

            # Update tracking record
            update_data = {
                "actual_price": actual_price,
                "actual_volume": actual_volume,
                "actual_timestamp": actual_execution_time,          # Actual execution time (business time)
                "tracking_status": TRACKINGSTATUS_TYPES.EXECUTED,
                "execution_confirmed_at": datetime.now(),           # Execution confirmation system time
                "time_delay_seconds": time_delay_seconds
            }
            
            result = self._crud_repo.modify(filters={"uuid": tracker.uuid}, updates=update_data)

            if result.is_success():
                updated_tracker = self._crud_repo.get_by_uuid(tracker.uuid)
                GLOG.INFO(f"Confirmed execution for signal_id: {signal_id}")
                return ServiceResult.success(updated_tracker)
            else:
                return ServiceResult.error("Failed to update tracking record")

        except Exception as e:
            GLOG.ERROR(f"Failed to confirm execution: {e}")
            return ServiceResult.error(f"Failed to confirm execution: {e}")

    @time_logger
    @retry(max_try=3)
    def set_timeout(
        self,
        signal_id: str,
        reason: str = "Execution timeout"
    ) -> ServiceResult:
        """
        Mark signal as timeout status

        Args:
            signal_id: Signal ID
            reason: Timeout reason

        Returns:
            ServiceResult[bool]: Service result
        """
        try:
            self._crud_repo.modify(
                filters={"signal_id": signal_id},
                updates={
                    "tracking_status": TRACKINGSTATUS_TYPES.TIMEOUT,
                    "reject_reason": reason
                }
            )

            GLOG.INFO(f"Marked signal as timeout: {signal_id}")
            return ServiceResult.success(True)

        except Exception as e:
            GLOG.ERROR(f"Failed to mark timeout: {e}")
            return ServiceResult.error(f"Timeout marking failed: {e}")

    @time_logger
    @retry(max_try=3)
    def get_pending(
        self,
        engine_id: Optional[str] = None,
        portfolio_id: Optional[str] = None,
        strategy_id: Optional[str] = None,
        timeout_minutes: int = 30
    ) -> ServiceResult:
        """
        Get pending signals for confirmation

        Args:
            engine_id: Engine ID filter
            portfolio_id: Portfolio ID filter
            strategy_id: Strategy ID filter
            timeout_minutes: Timeout period (minutes)

        Returns:
            ServiceResult[List[MSignalTracker]]: Service result
        """
        try:
            # ä½¿ç”¨SignalTrackerCRUDçš„ç‰¹å®šæ–¹æ³•
            pending_signals = self._crud_repo.find_by_tracking_status(
                tracking_status=TRACKINGSTATUS_TYPES.NOTIFIED.value
            )

            return ServiceResult.success(pending_signals)

        except Exception as e:
            GLOG.ERROR(f"Failed to get pending signals: {e}")
            return ServiceResult.error(f"è·å–å¾…ç¡®è®¤ä¿¡å·å¤±è´¥: {e}")

    @time_logger
    @retry(max_try=3)
    def get_timeouts(
        self,
        engine_id: Optional[str] = None,
        timeout_minutes: int = 30
    ) -> ServiceResult:
        """
        è·å–è¶…æ—¶çš„ä¿¡å·
        
        Args:
            engine_id: å¼•æ“IDç­›é€‰
            timeout_minutes: è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
            
        Returns:
            ServiceResult[List[MSignalTracker]]: æœåŠ¡ç»“æœ
        """
        try:
            timeout_threshold = datetime.now() - timedelta(minutes=timeout_minutes)
            
            filters = {
                "tracking_status": TRACKINGSTATUS_TYPES.NOTIFIED,
                "notification_sent_at__lt": timeout_threshold
            }
            
            if engine_id:
                filters["engine_id"] = engine_id
            
            timeout_signals = self._crud_repo.get_items_filtered(**filters)
            
            return ServiceResult.success(timeout_signals)
            
        except Exception as e:
            GLOG.ERROR(f"Failed to get timeout signals: {e}")
            return ServiceResult.error(f"è·å–è¶…æ—¶ä¿¡å·å¤±è´¥: {e}")
    
        
    @time_logger
    @retry(max_try=3)
    def set_status(
        self,
        tracking_uuid: str,
        new_status: TRACKINGSTATUS_TYPES,
        notes: Optional[str] = None
    ) -> ServiceResult:
        """
        æ›´æ–°è¿½è¸ªè®°å½•çŠ¶æ€
        
        Args:
            tracking_uuid: è¿½è¸ªè®°å½•UUID
            new_status: æ–°çŠ¶æ€
            notes: å¤‡æ³¨ä¿¡æ¯
            
        Returns:
            ServiceResult[MSignalTracker]: æœåŠ¡ç»“æœ
        """
        try:
            # è·å–ç°æœ‰è®°å½• (tracking_uuidå®é™…ä¸Šæ˜¯signal_id)
            tracking_records = self._crud_repo.find(filters={"signal_id": tracking_uuid})
            if not tracking_records or len(tracking_records) == 0:
                return ServiceResult.error(f"æœªæ‰¾åˆ°è¿½è¸ªè®°å½•: {tracking_uuid}")

            tracking_record = tracking_records[0]
            
            # æ›´æ–°çŠ¶æ€
            update_data = {
                "tracking_status": new_status,
                "update_at": datetime.now()
            }
            
            if notes:
                update_data["notes"] = notes
            
            # æ ¹æ®çŠ¶æ€è®¾ç½®ç›¸åº”çš„æ—¶é—´æˆ³
            if new_status == TRACKINGSTATUS_TYPES.EXECUTED:
                update_data["executed_at"] = datetime.now()
            elif new_status == TRACKINGSTATUS_TYPES.TIMEOUT:
                update_data["timeout_at"] = datetime.now()
            elif new_status == TRACKINGSTATUS_TYPES.CANCELED:
                update_data["canceled_at"] = datetime.now()
            
            # æ‰§è¡Œæ›´æ–°
            self._crud_repo.modify(filters={"signal_id": tracking_uuid}, updates=update_data)
            updated_record = tracking_record  # modifyæ–¹æ³•ä¸è¿”å›å€¼ï¼Œä½¿ç”¨åŸæ¥çš„è®°å½•
            
            GLOG.INFO(f"Updated tracking status for {tracking_uuid}: {new_status}")
            return ServiceResult.success(updated_record)
            
        except Exception as e:
            GLOG.ERROR(f"Failed to update tracking status: {e}")
            return ServiceResult.error(f"æ›´æ–°è¿½è¸ªçŠ¶æ€å¤±è´¥: {e}")

    @time_logger
    @retry(max_try=3)
    def batch_mark_timeout(
        self,
        engine_id: Optional[str] = None,
        timeout_minutes: int = 30
    ) -> ServiceResult:
        """
        æ‰¹é‡æ ‡è®°è¶…æ—¶ä¿¡å·
        
        Args:
            engine_id: å¼•æ“IDç­›é€‰
            timeout_minutes: è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
            
        Returns:
            ServiceResult[int]: æ ‡è®°ä¸ºè¶…æ—¶çš„ä¿¡å·æ•°é‡
        """
        try:
            timeout_signals_result = self.get_timeout_signals(engine_id, timeout_minutes)
            
            if not timeout_signals_result.is_success():
                return ServiceResult.error("è·å–è¶…æ—¶ä¿¡å·å¤±è´¥")
            
            timeout_signals = timeout_signals_result.data
            count = 0
            
            for signal in timeout_signals:
                result = self.mark_timeout(signal.signal_id, "Batch timeout")
                if result.is_success():
                    count += 1
            
            GLOG.INFO(f"Batch marked {count} timeout signals")
            return ServiceResult.success(count)
            
        except Exception as e:
            GLOG.ERROR(f"Failed to batch mark timeout: {e}")
            return ServiceResult.error(f"æ‰¹é‡æ ‡è®°è¶…æ—¶å¤±è´¥: {e}")

    @time_logger
    @retry(max_try=3)
    def get_statistics_summary(
        self,
        engine_id: Optional[str] = None,
        portfolio_id: Optional[str] = None,
        strategy_id: Optional[str] = None,
        account_type: Optional[ACCOUNT_TYPE] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> ServiceResult:
        """
        è·å–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯
        
        Args:
            engine_id: å¼•æ“IDç­›é€‰
            portfolio_id: æŠ•èµ„ç»„åˆIDç­›é€‰
            strategy_id: ç­–ç•¥IDç­›é€‰
            account_type: è´¦æˆ·ç±»å‹ç­›é€‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            ServiceResult[Dict[str, Any]]: ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            filters = {}
            
            if engine_id:
                filters["engine_id"] = engine_id
            if portfolio_id:
                filters["portfolio_id"] = portfolio_id
            if strategy_id:
                filters["strategy_id"] = strategy_id
            if account_type is not None:
                filters["account_type"] = account_type
            if start_date:
                filters["expected_timestamp__gte"] = start_date
            if end_date:
                filters["expected_timestamp__lte"] = end_date
            
            records = self._crud_repo.get_items_filtered(**filters)
            
            total_count = len(records)
            executed_count = len([r for r in records if r.is_executed()])
            pending_count = len([r for r in records if r.is_pending()])
            timeout_count = len([r for r in records if r.is_timeout()])
            
            # è®¡ç®—å¹³å‡å»¶è¿Ÿ
            executed_records = [r for r in records if r.is_executed()]
            avg_time_delay = 0

            if executed_records:
                time_delays = [r.time_delay_seconds for r in executed_records if r.time_delay_seconds]
                if time_delays:
                    avg_time_delay = sum(time_delays) / len(time_delays)
            
            statistics = {
                "total_signals": total_count,
                "executed_signals": executed_count,
                "pending_signals": pending_count,
                "timeout_signals": timeout_count,
                "execution_rate": executed_count / total_count if total_count > 0 else 0,
                "timeout_rate": timeout_count / total_count if total_count > 0 else 0,
                "avg_time_delay_seconds": avg_time_delay
            }
            
            return ServiceResult.success(statistics)
            
        except Exception as e:
            GLOG.ERROR(f"Failed to get execution statistics: {e}")
            return ServiceResult.error(f"è·å–æ‰§è¡Œç»Ÿè®¡å¤±è´¥: {e}")

    
    @time_logger
    @retry(max_try=3)
    def cleanup(self, days_to_keep: int = 30) -> ServiceResult:
        """
        æ¸…ç†æ—§çš„è¿½è¸ªè®°å½•

        Args:
            days_to_keep: ä¿ç•™å¤©æ•°

        Returns:
            ServiceResult[int]: åˆ é™¤çš„è®°å½•æ•°
        """
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)

            # æŸ¥è¯¢éœ€è¦åˆ é™¤çš„æ—§è®°å½•
            old_records = self._crud_repo.find(page_size=10000)

            # ç­›é€‰å‡ºéœ€è¦åˆ é™¤çš„è®°å½•
            to_delete = []
            for record in old_records:
                if record.create_at and record.create_at < cutoff_date:
                    to_delete.append(record)

            # é€æ¡åˆ é™¤
            deleted_count = 0
            for record in to_delete:
                try:
                    self._crud_repo.delete_by_uuid(record.uuid)
                    deleted_count += 1
                except Exception as e:
                    GLOG.WARN(f"Failed to delete signal tracking record {record.uuid}: {e}")

            if deleted_count > 0:
                GLOG.INFO(f"Cleaned up {deleted_count} old signal tracking records")
            else:
                GLOG.DEBUG("No old signal tracking records to clean up")

            return ServiceResult.success(deleted_count)

        except Exception as e:
            GLOG.ERROR(f"Failed to cleanup old records: {e}")
            return ServiceResult.error(f"æ¸…ç†æ—§è®°å½•å¤±è´¥: {e}")

    # ==================== æ ‡å‡†æ¥å£æ–¹æ³• ====================

    @time_logger
    @retry(max_try=3)
    def get(self, **filters) -> ServiceResult:
        """
        æ ‡å‡†è·å–æ–¹æ³• - æ ¹æ®è¿‡æ»¤æ¡ä»¶è·å–ä¿¡å·è¿½è¸ªè®°å½•

        Args:
            **filters: è¿‡æ»¤æ¡ä»¶ï¼Œæ”¯æŒï¼š
                - uuid: è®°å½•UUID
                - signal_id: ä¿¡å·ID
                - portfolio_id: æŠ•èµ„ç»„åˆID
                - engine_id: å¼•æ“ID
                - strategy_id: ç­–ç•¥ID
                - tracking_status: è¿½è¸ªçŠ¶æ€
                - account_type: è´¦æˆ·ç±»å‹
                - limit: é™åˆ¶æ•°é‡
                - offset: åç§»é‡

        Returns:
            ServiceResult[List[MSignalTracker]]: æœåŠ¡ç»“æœ
        """
        try:
            if not filters:
                return ServiceResult.error("è·å–è®°å½•æ—¶å¿…é¡»æä¾›è¿‡æ»¤æ¡ä»¶")

            # ä½¿ç”¨CRUDçš„è·å–æ–¹æ³•
            records = self._crud_repo.find(filters=filters)

            GLOG.DEBUG(f"Retrieved {len(records)} signal tracking records")
            return ServiceResult.success(records)

        except Exception as e:
            GLOG.ERROR(f"Failed to get signal tracking records: {e}")
            return ServiceResult.error(f"è·å–ä¿¡å·è¿½è¸ªè®°å½•å¤±è´¥: {str(e)}")

    @time_logger
    @retry(max_try=3)
    def count(self, **filters) -> ServiceResult:
        """
        æ ‡å‡†è®¡æ•°æ–¹æ³• - æ ¹æ®è¿‡æ»¤æ¡ä»¶ç»Ÿè®¡è®°å½•æ•°é‡

        Args:
            **filters: è¿‡æ»¤æ¡ä»¶ï¼Œæ”¯æŒï¼š
                - signal_id: ä¿¡å·ID
                - portfolio_id: æŠ•èµ„ç»„åˆID
                - engine_id: å¼•æ“ID
                - strategy_id: ç­–ç•¥ID
                - tracking_status: è¿½è¸ªçŠ¶æ€
                - account_type: è´¦æˆ·ç±»å‹

        Returns:
            ServiceResult[int]: è®°å½•æ•°é‡
        """
        try:
            # ä½¿ç”¨CRUDçš„è®¡æ•°æ–¹æ³•
            count = self._crud_repo.count(**filters)

            GLOG.DEBUG(f"Counted {count} signal tracking records")
            return ServiceResult.success({"count": count})

        except Exception as e:
            GLOG.ERROR(f"Failed to count signal tracking records: {e}")
            return ServiceResult.error(f"ç»Ÿè®¡ä¿¡å·è¿½è¸ªè®°å½•å¤±è´¥: {str(e)}")

    @time_logger
    @retry(max_try=3)
    def validate(self, data: Dict[str, Any]) -> ServiceResult:
        """
        æ ‡å‡†éªŒè¯æ–¹æ³• - éªŒè¯ä¿¡å·è¿½è¸ªæ•°æ®çš„æœ‰æ•ˆæ€§

        Args:
            data: å¾…éªŒè¯çš„æ•°æ®å­—å…¸

        Returns:
            ServiceResult[bool]: éªŒè¯ç»“æœ
        """
        try:
            if not isinstance(data, dict):
                return ServiceResult.error("æ•°æ®å¿…é¡»æ˜¯å­—å…¸æ ¼å¼")

            # å¿…å¡«å­—æ®µéªŒè¯
            required_fields = [
                'signal_id', 'portfolio_id', 'execution_mode',
                'account_type', 'expected_code', 'expected_direction'
            ]

            missing_fields = []
            for field in required_fields:
                if field not in data or data[field] is None or data[field] == '':
                    missing_fields.append(field)

            if missing_fields:
                return ServiceResult.error(
                    data={
                        "valid": False,
                        "missing_fields": missing_fields,
                        "message": f"ç¼ºå°‘å¿…å¡«å­—æ®µ: {', '.join(missing_fields)}"
                    },
                    error=f"ç¼ºå°‘å¿…å¡«å­—æ®µ: {', '.join(missing_fields)}"
                )

            # æ•°æ®ç±»å‹éªŒè¯
            if 'expected_price' in data and not isinstance(data['expected_price'], (int, float, Decimal)):
                try:
                    data['expected_price'] = float(data['expected_price'])
                except (ValueError, TypeError):
                    return ServiceResult.error("expected_priceå¿…é¡»æ˜¯æ•°å€¼ç±»å‹")

            if 'expected_volume' in data and not isinstance(data['expected_volume'], int):
                try:
                    data['expected_volume'] = int(data['expected_volume'])
                except (ValueError, TypeError):
                    return ServiceResult.error("expected_volumeå¿…é¡»æ˜¯æ•´æ•°ç±»å‹")

            # æšä¸¾å€¼éªŒè¯
            valid_execution_modes = [mode.value for mode in EXECUTION_MODE]
            if 'execution_mode' in data and data['execution_mode'] not in valid_execution_modes:
                return ServiceResult.error(f"æ— æ•ˆçš„æ‰§è¡Œæ¨¡å¼: {data['execution_mode']}")

            valid_account_types = [atype.value for atype in ACCOUNT_TYPE]
            if 'account_type' in data and data['account_type'] not in valid_account_types:
                return ServiceResult.error(f"æ— æ•ˆçš„è´¦æˆ·ç±»å‹: {data['account_type']}")

            GLOG.DEBUG("Signal tracking data validation passed")
            return ServiceResult.success(
                data={
                    "valid": True,
                    "message": "æ•°æ®éªŒè¯é€šè¿‡"
                }
            )

        except Exception as e:
            GLOG.ERROR(f"Failed to validate signal tracking data: {e}")
            return ServiceResult.error(f"æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")

    @time_logger
    @retry(max_try=3)
    def check_integrity(self, **filters) -> ServiceResult:
        """
        æ ‡å‡†å®Œæ•´æ€§æ£€æŸ¥æ–¹æ³• - æ£€æŸ¥ä¿¡å·è¿½è¸ªæ•°æ®çš„å®Œæ•´æ€§

        Args:
            **filters: æ£€æŸ¥èŒƒå›´è¿‡æ»¤æ¡ä»¶

        Returns:
            ServiceResult[Dict[str, Any]]: å®Œæ•´æ€§æ£€æŸ¥ç»“æœ
        """
        try:
            # è·å–æ£€æŸ¥èŒƒå›´å†…çš„è®°å½•
            records = self._crud_repo.get_items_filtered(**filters)

            total_records = len(records)
            issues = []
            warnings = []

            # æ£€æŸ¥é¡¹ç›®
            for record in records:
                record_issues = []

                # æ£€æŸ¥å…³é”®å­—æ®µå®Œæ•´æ€§
                if not record.signal_id:
                    record_issues.append("ç¼ºå°‘signal_id")
                if not record.portfolio_id:
                    record_issues.append("ç¼ºå°‘portfolio_id")
                if not record.expected_code:
                    record_issues.append("ç¼ºå°‘expected_code")
                if not record.expected_direction:
                    record_issues.append("ç¼ºå°‘expected_direction")

                # æ£€æŸ¥å·²æ‰§è¡Œè®°å½•çš„å­—æ®µå®Œæ•´æ€§
                if record.is_executed():
                    if not record.actual_price:
                        record_issues.append("å·²æ‰§è¡Œè®°å½•ç¼ºå°‘actual_price")
                    if not record.actual_timestamp:
                        record_issues.append("å·²æ‰§è¡Œè®°å½•ç¼ºå°‘actual_timestamp")

                # æ£€æŸ¥æ—¶é—´æˆ³åˆç†æ€§
                if record.expected_timestamp and record.actual_timestamp:
                    time_diff = (record.actual_timestamp - record.expected_timestamp).total_seconds()
                    if time_diff < 0:
                        warnings.append(f"è®°å½•{record.uuid}: å®é™…æ—¶é—´æ—©äºé¢„æœŸæ—¶é—´")
                    elif time_diff > 3600:  # è¶…è¿‡1å°æ—¶
                        warnings.append(f"è®°å½•{record.uuid}: æ‰§è¡Œå»¶è¿Ÿè¶…è¿‡1å°æ—¶")

                if record_issues:
                    issues.append({
                        "record_uuid": record.uuid,
                        "signal_id": record.signal_id,
                        "issues": record_issues
                    })

            # è®¡ç®—å®Œæ•´æ€§æŒ‡æ ‡
            integrity_score = 1.0
            if total_records > 0:
                integrity_score = (total_records - len(issues)) / total_records

            result = {
                "total_records": total_records,
                "records_with_issues": len(issues),
                "integrity_score": integrity_score,
                "issues": issues,
                "warnings": warnings,
                "recommendations": []
            }

            # ç”Ÿæˆå»ºè®®
            if len(issues) > total_records * 0.1:  # è¶…è¿‡10%çš„è®°å½•æœ‰é—®é¢˜
                result["recommendations"].append("å»ºè®®æ£€æŸ¥æ•°æ®è¾“å…¥æµç¨‹ï¼Œæé«˜æ•°æ®è´¨é‡")

            if len(warnings) > total_records * 0.05:  # è¶…è¿‡5%çš„è®°å½•æœ‰è­¦å‘Š
                result["recommendations"].append("å»ºè®®ä¼˜åŒ–æ‰§è¡Œæ—¶é—´ï¼Œå‡å°‘æ‰§è¡Œå»¶è¿Ÿ")

            GLOG.DEBUG(f"Integrity check completed: {len(issues)} issues found")
            return ServiceResult.success(result)

        except Exception as e:
            GLOG.ERROR(f"Failed to check signal tracking integrity: {e}")
            return ServiceResult.error(f"å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")

    # ä»CRUDå±‚ç§»åŠ¨è¿‡æ¥çš„ä¸šåŠ¡é€»è¾‘æ–¹æ³•

    @time_logger
    @retry(max_try=3)
    def find_pending(
        self,
        account_type: Optional[ACCOUNT_TYPE] = None,
        execution_mode: Optional[EXECUTION_MODE] = None
    ) -> ServiceResult:
        """
        æŸ¥æ‰¾å¾…æ‰§è¡Œçš„ä¿¡å·è¿½è¸ªè®°å½•

        Args:
            account_type: è´¦æˆ·ç±»å‹ç­›é€‰
            execution_mode: æ‰§è¡Œæ¨¡å¼ç­›é€‰

        Returns:
            ServiceResult: å¾…æ‰§è¡Œè®°å½•åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨CRUDåŸºç¡€æ–¹æ³•æŸ¥æ‰¾å¾…æ‰§è¡Œä¿¡å·
            filters = {"tracking_status": TRACKINGSTATUS_TYPES.NOTIFIED}
            if account_type is not None:
                filters["account_type"] = account_type
            if execution_mode is not None:
                filters["execution_mode"] = execution_mode

            trackers = self._crud_repo.find(filters=filters, limit=1000)
            return ServiceResult.success(trackers)
        except Exception as e:
            return ServiceResult.error(f"æŸ¥æ‰¾å¾…æ‰§è¡Œä¿¡å·å¤±è´¥: {str(e)}")

    @time_logger
    @retry(max_try=3)
    def get_timeouts_by_account(
        self,
        timeout_hours: int = 24,
        account_type: Optional[ACCOUNT_TYPE] = None
    ) -> ServiceResult:
        """
        æŸ¥æ‰¾è¶…æ—¶çš„ä¿¡å·è¿½è¸ªè®°å½•

        Args:
            timeout_hours: è¶…æ—¶å°æ—¶æ•°
            account_type: è´¦æˆ·ç±»å‹ç­›é€‰

        Returns:
            ServiceResult: è¶…æ—¶è®°å½•åˆ—è¡¨
        """
        try:
            # è®¡ç®—è¶…æ—¶æ—¶é—´ç‚¹
            timeout_time = datetime.now() - timedelta(hours=timeout_hours)

            filters = {
                "tracking_status": TRACKINGSTATUS_TYPES.NOTIFIED,
                "notification_sent_at__lt": timeout_time
            }
            if account_type is not None:
                filters["account_type"] = account_type

            trackers = self._crud_repo.find(filters=filters, limit=1000)
            return ServiceResult.success(trackers)
        except Exception as e:
            return ServiceResult.error(f"æŸ¥æ‰¾è¶…æ—¶ä¿¡å·å¤±è´¥: {str(e)}")

    @time_logger
    @retry(max_try=3)
    def get_statistics(
        self,
        portfolio_id: Optional[str] = None,
        engine_id: Optional[str] = None,
        run_id: Optional[str] = None,
        account_type: Optional[ACCOUNT_TYPE] = None,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None
    ) -> ServiceResult:
        """
        è·å–ä¿¡å·æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯

        Args:
            portfolio_id: æŠ•èµ„ç»„åˆIDç­›é€‰
            engine_id: å¼•æ“IDç­›é€‰
            run_id: è¿è¡Œä¼šè¯IDç­›é€‰
            account_type: è´¦æˆ·ç±»å‹ç­›é€‰
            start_time: å¼€å§‹æ—¶é—´ç­›é€‰
            end_time: ç»“æŸæ—¶é—´ç­›é€‰

        Returns:
            ServiceResult: ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # æ„å»ºè¿‡æ»¤æ¡ä»¶
            filters = {}
            if portfolio_id is not None:
                filters["portfolio_id"] = portfolio_id
            if engine_id is not None:
                filters["engine_id"] = engine_id
            if run_id is not None:
                filters["run_id"] = run_id
            if account_type is not None:
                filters["account_type"] = account_type
            if start_time is not None:
                filters["business_timestamp__gte"] = start_time
            if end_time is not None:
                filters["business_timestamp__lte"] = end_time

            # æŸ¥è¯¢æ‰€æœ‰ç›¸å…³è®°å½•
            all_records = self._crud_repo.find(filters=filters, limit=10000)

            if not all_records:
                stats = {
                    "total_count": 0,
                    "executed_count": 0,
                    "pending_count": 0,
                    "timeout_count": 0,
                    "rejected_count": 0,
                    "execution_rate": 0.0
                }
            else:
                total_count = len(all_records)
                executed_count = len([r for r in all_records if r.tracking_status == TRACKINGSTATUS_TYPES.EXECUTED.value])
                pending_count = len([r for r in all_records if r.tracking_status == TRACKINGSTATUS_TYPES.NOTIFIED.value])
                timeout_count = len([r for r in all_records if r.tracking_status == TRACKINGSTATUS_TYPES.TIMEOUT.value])
                rejected_count = len([r for r in all_records if r.tracking_status == TRACKINGSTATUS_TYPES.REJECTED.value])

                execution_rate = (executed_count / total_count) if total_count > 0 else 0.0

                stats = {
                    "total_count": total_count,
                    "executed_count": executed_count,
                    "pending_count": pending_count,
                    "timeout_count": timeout_count,
                    "rejected_count": rejected_count,
                    "execution_rate": execution_rate
                }

            return ServiceResult.success(stats)
        except Exception as e:
            return ServiceResult.error(f"è·å–æ‰§è¡Œç»Ÿè®¡å¤±è´¥: {str(e)}")

    @time_logger
    @retry(max_try=3)
    def batch_update_execution_status(
        self,
        signal_ids: List[str],
        tracking_status: TRACKINGSTATUS_TYPES,
        actual_price: Optional[float] = None,
        actual_volume: Optional[int] = None,
        actual_timestamp: Optional[datetime] = None,
        notes: Optional[str] = None
    ) -> ServiceResult:
        """
        æ‰¹é‡æ›´æ–°ä¿¡å·æ‰§è¡ŒçŠ¶æ€

        Args:
            signal_ids: ä¿¡å·IDåˆ—è¡¨ (å»ºè®® < 100æ¡)
            tracking_status: æ–°çš„è¿½è¸ªçŠ¶æ€
            actual_price: å®é™…ä»·æ ¼
            actual_volume: å®é™…æ•°é‡
            actual_timestamp: å®é™…æ‰§è¡Œæ—¶é—´
            notes: å¤‡æ³¨ä¿¡æ¯

        Returns:
            ServiceResult: æ›´æ–°æˆåŠŸçš„è®°å½•æ•°é‡
        """
        try:
            updated_count = 0

            for signal_id in signal_ids:
                tracker = self._crud_repo.find_by_signal_id(signal_id)
                if tracker:
                    # æ›´æ–°çŠ¶æ€ä¿¡æ¯
                    tracker.tracking_status = tracking_status.value
                    tracker.execution_confirmed_at = datetime.now()

                    if actual_price is not None:
                        tracker.actual_price = to_decimal(actual_price)
                    if actual_volume is not None:
                        tracker.actual_volume = actual_volume
                    if actual_timestamp is not None:
                        tracker.actual_timestamp = datetime_normalize(actual_timestamp)
                    if notes is not None:
                        tracker.notes = notes

                    # ä¿å­˜æ›´æ–°
                    success = self._crud_repo.update(tracker)
                    if success:
                        updated_count += 1

            return ServiceResult.success({"updated_count": updated_count})
        except Exception as e:
            return ServiceResult.error(f"æ‰¹é‡æ›´æ–°æ‰§è¡ŒçŠ¶æ€å¤±è´¥: {str(e)}")

    
    @time_logger
    @retry(max_try=3)
    def batch_update_paper_trade_execution(
        self,
        executions: List[dict]
    ) -> ServiceResult:
        """
        æ‰¹é‡æ›´æ–°PaperTradeæ‰§è¡Œç»“æœ

        Args:
            executions: æ‰§è¡Œç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªdictåŒ…å«:
                - signal_id: ä¿¡å·ID
                - actual_price: å®é™…ä»·æ ¼
                - actual_volume: å®é™…æ•°é‡
                - actual_timestamp: æ‰§è¡Œæ—¶é—´
                - notes: å¯é€‰å¤‡æ³¨

        Returns:
            ServiceResult: å¤„ç†ç»“æœç»Ÿè®¡
        """
        try:
            if not executions:
                return ServiceResult.success({"total": 0, "success": 0, "failed": 0})

            signal_ids = [exec_data["signal_id"] for exec_data in executions]

            # æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰ç›¸å…³ä¿¡å·
            trackers = self._crud_repo.find(filters={"signal_id__in": signal_ids})
            tracker_map = {tracker.signal_id: tracker for tracker in trackers}

            success_count = 0
            failed_count = 0

            for exec_data in executions:
                signal_id = exec_data["signal_id"]
                tracker = tracker_map.get(signal_id)

                if not tracker:
                    GLOG.WARN(f"æœªæ‰¾åˆ°ä¿¡å·è®°å½•: {signal_id}")
                    failed_count += 1
                    continue

                try:
                    # æ›´æ–°æ‰§è¡Œä¿¡æ¯
                    tracker.tracking_status = TRACKINGSTATUS_TYPES.EXECUTED.value
                    tracker.execution_confirmed_at = datetime.now()
                    tracker.actual_price = to_decimal(exec_data["actual_price"])
                    tracker.actual_volume = exec_data["actual_volume"]
                    tracker.actual_timestamp = datetime_normalize(exec_data.get("actual_timestamp"))
                    tracker.notes = exec_data.get("notes", "PaperTradeæ¨¡æ‹Ÿæˆäº¤")

                    success = self._crud_repo.update(tracker)
                    if success:
                        success_count += 1
                    else:
                        failed_count += 1

                except Exception as e:
                    GLOG.ERROR(f"æ›´æ–°PaperTradeæ‰§è¡Œç»“æœå¤±è´¥ {signal_id}: {e}")
                    failed_count += 1

            result = {
                "total": len(executions),
                "success": success_count,
                "failed": failed_count
            }

            GLOG.INFO(f"PaperTradeæ‰¹é‡æ›´æ–°å®Œæˆ: {result}")
            return ServiceResult.success(result)
        except Exception as e:
            return ServiceResult.error(f"æ‰¹é‡æ›´æ–°PaperTradeæ‰§è¡Œç»“æœå¤±è´¥: {str(e)}")

    @time_logger
    @retry(max_try=3)
    def get_all_signal_ids(self) -> ServiceResult:
        """
        è·å–æ‰€æœ‰ä¿¡å·ID

        Returns:
            ServiceResult: ä¿¡å·IDåˆ—è¡¨
        """
        try:
            all_records = self._crud_repo.find(limit=10000)
            signal_ids = list(set(item.signal_id for item in all_records if item.signal_id))
            return ServiceResult.success(signal_ids)
        except Exception as e:
            return ServiceResult.error(f"è·å–ä¿¡å·IDåˆ—è¡¨å¤±è´¥: {str(e)}")

    @time_logger
    @retry(max_try=3)
    def get_portfolio_ids(self) -> ServiceResult:
        """
        è·å–æ‰€æœ‰æŠ•èµ„ç»„åˆID

        Returns:
            ServiceResult: æŠ•èµ„ç»„åˆIDåˆ—è¡¨
        """
        try:
            all_records = self._crud_repo.find(limit=10000)
            portfolio_ids = list(set(item.portfolio_id for item in all_records if item.portfolio_id))
            return ServiceResult.success(portfolio_ids)
        except Exception as e:
            return ServiceResult.error(f"è·å–æŠ•èµ„ç»„åˆIDåˆ—è¡¨å¤±è´¥: {str(e)}")

    @time_logger
    @retry(max_try=3)
    def find_by_business_time(
        self,
        portfolio_id: str,
        start_business_time: Optional[Any] = None,
        end_business_time: Optional[Any] = None,
        account_type: Optional[ACCOUNT_TYPE] = None,
        tracking_status: Optional[TRACKINGSTATUS_TYPES] = None
    ) -> ServiceResult:
        """
        æ ¹æ®ä¸šåŠ¡æ—¶é—´èŒƒå›´æŸ¥æ‰¾ä¿¡å·è¿½è¸ªè®°å½•

        Args:
            portfolio_id: æŠ•èµ„ç»„åˆID
            start_business_time: å¼€å§‹ä¸šåŠ¡æ—¶é—´
            end_business_time: ç»“æŸä¸šåŠ¡æ—¶é—´
            account_type: è´¦æˆ·ç±»å‹ç­›é€‰
            tracking_status: è¿½è¸ªçŠ¶æ€ç­›é€‰

        Returns:
            ServiceResult: è¿½è¸ªè®°å½•åˆ—è¡¨
        """
        try:
            filters = {"portfolio_id": portfolio_id}

            if start_business_time:
                filters["business_timestamp__gte"] = datetime_normalize(start_business_time)
            if end_business_time:
                filters["business_timestamp__lte"] = datetime_normalize(end_business_time)
            if account_type is not None:
                filters["account_type"] = account_type
            if tracking_status is not None:
                filters["tracking_status"] = tracking_status

            trackers = self._crud_repo.find(filters=filters, limit=1000)
            return ServiceResult.success(trackers)
        except Exception as e:
            return ServiceResult.error(f"æ ¹æ®ä¸šåŠ¡æ—¶é—´æŸ¥æ‰¾ä¿¡å·å¤±è´¥: {str(e)}")

    
    @time_logger
    @retry(max_try=3)
    def exists(self, **filters) -> ServiceResult:
        """
        æ ‡å‡†å­˜åœ¨æ€§æ£€æŸ¥æ–¹æ³• - æ£€æŸ¥ä¿¡å·è¿½è¸ªè®°å½•æ˜¯å¦å­˜åœ¨

        Args:
            **filters: æ£€æŸ¥æ¡ä»¶ï¼Œæ”¯æŒï¼š
                - signal_id: ä¿¡å·ID
                - uuid: è®°å½•UUID
                - portfolio_id: æŠ•èµ„ç»„åˆID
                - engine_id: å¼•æ“ID
                - tracking_status: è¿½è¸ªçŠ¶æ€

        Returns:
            ServiceResult[bool]: å­˜åœ¨æ€§æ£€æŸ¥ç»“æœ
        """
        try:
            if not filters:
                return ServiceResult.error("å­˜åœ¨æ€§æ£€æŸ¥æ—¶å¿…é¡»æä¾›è¿‡æ»¤æ¡ä»¶")

            # ä½¿ç”¨countæ–¹æ³•è¿›è¡Œå­˜åœ¨æ€§æ£€æŸ¥
            count_result = self.count(**filters)
            if not count_result.is_success():
                return ServiceResult.error("å­˜åœ¨æ€§æ£€æŸ¥æ—¶æŸ¥è¯¢å¤±è´¥")

            count = count_result.data.get("count", 0)
            exists = count > 0

            GLOG.DEBUG(f"Existence check result: {exists}")
            return ServiceResult.success({"exists": exists})

        except Exception as e:
            GLOG.ERROR(f"Failed to check signal tracking existence: {e}")
            return ServiceResult.error(f"å­˜åœ¨æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")

    @time_logger
    @retry(max_try=3)
    def health_check(self) -> ServiceResult:
        """
        æœåŠ¡å¥åº·æ£€æŸ¥æ–¹æ³• - æ£€æŸ¥SignalTrackingServiceè¿è¡ŒçŠ¶æ€

        Returns:
            ServiceResult[Dict[str, Any]]: å¥åº·æ£€æŸ¥ç»“æœ
        """
        try:
            health_info = {
                "service_name": "SignalTrackingService",
                "status": "healthy",
                "checks": {}
            }

            # æ£€æŸ¥CRUDä¾èµ–
            if self._crud_repo is None:
                health_info["status"] = "unhealthy"
                health_info["checks"]["crud_dependency"] = {
                    "status": "failed",
                    "error": "SignalTrackerCRUDä¾èµ–æœªåˆå§‹åŒ–"
                }
                return ServiceResult.success(health_info)

            health_info["checks"]["crud_dependency"] = {
                "status": "passed",
                "message": "SignalTrackerCRUDä¾èµ–æ­£å¸¸"
            }

            # æ£€æŸ¥æ•°æ®åº“è¿æ¥ - å°è¯•æ‰§è¡Œä¸€ä¸ªç®€å•æŸ¥è¯¢
            try:
                self._crud_repo.find(limit=1)
                health_info["checks"]["database_connection"] = {
                    "status": "passed",
                    "message": "æ•°æ®åº“è¿æ¥æ­£å¸¸"
                }
            except Exception as db_error:
                health_info["status"] = "unhealthy"
                health_info["checks"]["database_connection"] = {
                    "status": "failed",
                    "error": f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(db_error)}"
                }
                return ServiceResult.success(health_info)

            # æ£€æŸ¥æœåŠ¡åŠŸèƒ½ - å°è¯•ç»Ÿè®¡è®°å½•æ•°é‡
            try:
                count_result = self.count()
                if count_result.is_success():
                    total_count = count_result.data.get("count", 0)
                    health_info["checks"]["service_functionality"] = {
                        "status": "passed",
                        "message": f"æœåŠ¡åŠŸèƒ½æ­£å¸¸ï¼Œå…±{total_count}æ¡è®°å½•"
                    }
                    health_info["total_records"] = total_count
                else:
                    health_info["status"] = "degraded"
                    health_info["checks"]["service_functionality"] = {
                        "status": "warning",
                        "error": count_result.error
                    }
            except Exception as func_error:
                health_info["status"] = "unhealthy"
                health_info["checks"]["service_functionality"] = {
                    "status": "failed",
                    "error": f"æœåŠ¡åŠŸèƒ½æ£€æŸ¥å¤±è´¥: {str(func_error)}"
                }

            # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
            try:
                import psutil
                process = psutil.Process()
                memory_info = process.memory_info()
                health_info["checks"]["memory_usage"] = {
                    "status": "passed",
                    "memory_mb": round(memory_info.rss / 1024 / 1024, 2),
                    "message": f"å†…å­˜ä½¿ç”¨æ­£å¸¸: {round(memory_info.rss / 1024 / 1024, 2)}MB"
                }
            except ImportError:
                health_info["checks"]["memory_usage"] = {
                    "status": "skipped",
                    "message": "psutilæœªå®‰è£…ï¼Œè·³è¿‡å†…å­˜æ£€æŸ¥"
                }
            except Exception as mem_error:
                health_info["checks"]["memory_usage"] = {
                    "status": "warning",
                    "error": f"å†…å­˜æ£€æŸ¥å¤±è´¥: {str(mem_error)}"
                }

            # ç”Ÿæˆæœ€ç»ˆå¥åº·çŠ¶æ€æ¶ˆæ¯
            if health_info["status"] == "healthy":
                message = f"SignalTrackingServiceè¿è¡Œæ­£å¸¸ï¼Œå…±{health_info.get('total_records', 0)}æ¡ä¿¡å·è¿½è¸ªè®°å½•"
            elif health_info["status"] == "degraded":
                message = "SignalTrackingServiceéƒ¨åˆ†åŠŸèƒ½å¼‚å¸¸ï¼Œä½†åŸºæœ¬å¯ç”¨"
            else:
                message = "SignalTrackingServiceè¿è¡Œå¼‚å¸¸ï¼Œéœ€è¦ç«‹å³å¤„ç†"

            GLOG.DEBUG(f"Health check completed: {health_info['status']}")
            return ServiceResult.success(health_info, message)

        except Exception as e:
            GLOG.ERROR(f"Failed to perform health check: {e}")
            return ServiceResult.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")