# Upstream: LiveCoreï¼ˆé€šè¿‡Kafkaæ¥æ”¶å¸‚åœºæ•°æ®å’Œè®¢å•å›æŠ¥ï¼‰
# Downstream: Portfolioï¼ˆè°ƒç”¨äº‹ä»¶å¤„ç†æ–¹æ³•ï¼‰ã€Kafkaï¼ˆå‘å¸ƒè®¢å•æäº¤ï¼‰
# Role: ExecutionNodeæ‰§è¡ŒèŠ‚ç‚¹ï¼Œè¿è¡Œå¤šä¸ªPortfolioå®ä¾‹ï¼Œä»Kafkaæ¥æ”¶äº‹ä»¶å¹¶è·¯ç”±åˆ°Portfolio


"""
ExecutionNodeæ‰§è¡ŒèŠ‚ç‚¹

ExecutionNodeæ˜¯Portfolioçš„è¿è¡Œå®¹å™¨ï¼Œè´Ÿè´£ï¼š
- è¿è¡Œå¤šä¸ªPortfolioå®ä¾‹ï¼ˆæ— æ•°é‡é™åˆ¶ï¼‰
- ä»æ•°æ®åº“åŠ è½½Portfolioé…ç½®å¹¶åˆ›å»ºå®ä¾‹
- ä»Kafkaè®¢é˜…market.dataå’Œorders.feedback topic
- ä½¿ç”¨InterestMapè·¯ç”±äº‹ä»¶åˆ°å¯¹åº”çš„PortfolioProcessor
- æ”¶é›†Portfolioç”Ÿæˆçš„è®¢å•å¹¶æäº¤åˆ°Kafka orders.submission topic
- ä¸ŠæŠ¥å¿ƒè·³å’ŒçŠ¶æ€åˆ°Redis

æ ¸å¿ƒæ¶æ„ï¼šå•Kafkaæ¶ˆè´¹çº¿ç¨‹ + å¤šPortfolioProcessorå¤„ç†çº¿ç¨‹
- Kafkaæ¶ˆè´¹çº¿ç¨‹ï¼šå¿«é€Ÿæ¶ˆè´¹æ¶ˆæ¯ï¼Œæ ¹æ®InterestMapè·¯ç”±åˆ°Portfolio Queue
- PortfolioProcessorçº¿ç¨‹ï¼šæ¯ä¸ªPortfolioç‹¬ç«‹çº¿ç¨‹ï¼Œä»Queueå–æ¶ˆæ¯å¹¶å¤„ç†
- InterestMapï¼šæ˜ å°„è‚¡ç¥¨ä»£ç åˆ°è®¢é˜…çš„Portfolio IDåˆ—è¡¨

MVPé˜¶æ®µï¼ˆPhase 3ï¼‰ï¼š
- å•Portfolioè¿è¡Œ
- åŸºç¡€Kafkaè®¢é˜…å’Œæ¶ˆæ¯è·¯ç”±
- ç®€å•çš„è®¢å•æäº¤æµç¨‹
- ä»æ•°æ®åº“åŠ è½½Portfolioé…ç½®

Phase 4æ‰©å±•ï¼š
- InterestMapè·¯ç”±æœºåˆ¶ï¼ˆO(1)æŸ¥è¯¢ï¼‰
- å¤šPortfolioå¹¶è¡Œè¿è¡Œ
- Backpressureåå‹æœºåˆ¶

äº‘åŸç”Ÿè®¾è®¡ï¼ˆPhase 5ï¼‰ï¼š
- âœ… çŠ¶æ€åœ¨å†…å­˜ï¼ˆé‡å¯åæ¸…ç©ºï¼‰
- âœ… Scheduler è‡ªåŠ¨æ£€æµ‹ç¦»çº¿ï¼ˆå¿ƒè·³ TTL=30sï¼‰
- âœ… Scheduler è‡ªåŠ¨é‡æ–°åˆ†é… Portfolio
- âœ… ExecutionNode é‡æ–°ä¸Šçº¿åç­‰å¾…æ–°ä»»åŠ¡
"""

from typing import Dict, Optional, TYPE_CHECKING, List
from threading import Thread, Lock, Event
from queue import Queue
from datetime import datetime
import time
import logging

from ginkgo.workers.execution_node.portfolio_processor import PortfolioProcessor
from ginkgo.workers.execution_node.interest_map import InterestMap
from ginkgo.data.drivers.ginkgo_kafka import GinkgoConsumer, GinkgoProducer
from ginkgo import services
from ginkgo.enums import PORTFOLIO_RUNSTATE_TYPES
from ginkgo.interfaces.kafka_topics import KafkaTopics

# è·å–æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)


class ExecutionNode:
    """ExecutionNodeæ‰§è¡ŒèŠ‚ç‚¹ï¼Œè¿è¡Œå¤šä¸ªPortfolioå®ä¾‹"""

    def __init__(self, node_id: str):
        """
        åˆå§‹åŒ–ExecutionNodeï¼ˆäº‘åŸç”Ÿæ— çŠ¶æ€è®¾è®¡ï¼‰

        Args:
            node_id: èŠ‚ç‚¹å”¯ä¸€æ ‡è¯†

        äº‘åŸç”Ÿè®¾è®¡åŸåˆ™ï¼š
        - çŠ¶æ€åœ¨å†…å­˜ï¼ˆé‡å¯åæ¸…ç©ºï¼‰
        - Scheduler è‡ªåŠ¨æ£€æµ‹ç¦»çº¿ï¼ˆå¿ƒè·³ TTL=30sï¼‰
        - Scheduler è‡ªåŠ¨é‡æ–°åˆ†é… Portfolio
        - ExecutionNode é‡æ–°ä¸Šçº¿åç­‰å¾…æ–°ä»»åŠ¡
        """
        self.node_id = node_id

        # Portfolioç®¡ç†ï¼š{portfolio_id: PortfolioProcessor}
        # æ³¨æ„ï¼šè¿™äº›å¯¹è±¡åªåœ¨è¿è¡Œæ—¶å­˜åœ¨ï¼Œä¸æŒä¹…åŒ–
        self.portfolios: Dict[str, PortfolioProcessor] = {}
        self.portfolio_lock = Lock()

        # Portfolioå®ä¾‹æŒæœ‰ï¼š{portfolio_id: PortfolioLive}
        # ExecutionNodeæŒæœ‰å”¯ä¸€å®ä¾‹ï¼ŒPortfolioProcessoræŒæœ‰å¼•ç”¨
        self._portfolio_instances: Dict[str, "PortfolioLive"] = {}

        # InterestMapï¼šè‚¡ç¥¨ä»£ç åˆ°Portfolio IDåˆ—è¡¨çš„æ˜ å°„
        # O(1)æŸ¥è¯¢è®¢é˜…æŸè‚¡ç¥¨çš„Portfolioåˆ—è¡¨
        self.interest_map: InterestMap = InterestMap()

        # Kafkaæ¶ˆè´¹è€…
        self.market_data_consumer: Optional[GinkgoConsumer] = None
        self.order_feedback_consumer: Optional[GinkgoConsumer] = None
        self.schedule_updates_consumer: Optional[GinkgoConsumer] = None

        # Kafkaç”Ÿäº§è€…ï¼ˆè®¢å•æäº¤ï¼‰
        self.order_producer = GinkgoProducer()

        # è¿è¡ŒçŠ¶æ€ï¼ˆåŒæ—¶å­˜å‚¨åˆ°Redisï¼‰
        self.is_running = False
        self.is_paused = False
        self.should_stop = False

        # æ¶ˆè´¹çº¿ç¨‹
        self.market_data_thread: Optional[Thread] = None
        self.order_feedback_thread: Optional[Thread] = None
        self.schedule_updates_thread: Optional[Thread] = None

        # å¿ƒè·³çº¿ç¨‹
        self.heartbeat_thread: Optional[Thread] = None
        self.heartbeat_interval = 10  # 10ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
        self.heartbeat_ttl = 30  # å¿ƒè·³TTL 30ç§’

        # èƒŒå‹ç»Ÿè®¡
        self.backpressure_count = 0
        self.dropped_event_count = 0
        self.total_event_count = 0

        # èŠ‚ç‚¹å…ƒæ•°æ®
        self.max_portfolios = 5  # æœ€å¤§å¯è¿è¡Œçš„Portfolioæ•°é‡
        self.started_at: Optional[str] = None

        # output_queue listener çº¿ç¨‹è¿½è¸ª
        self.output_queue_threads: Dict[str, Thread] = {}  # {portfolio_id: Thread}
        self.output_queue_stop_events: Dict[str, Event] = {}  # {portfolio_id: Event}

        # Portfolioé˜Ÿåˆ—ç®¡ç†ï¼ˆExecutionNodeæŒæœ‰æ‰€æœ‰é˜Ÿåˆ—ï¼‰
        self.input_queues: Dict[str, Queue] = {}  # {portfolio_id: Queue}
        self.output_queues: Dict[str, Queue] = {}  # {portfolio_id: Queue}

    def start(self):
        """
        å¯åŠ¨ ExecutionNodeï¼ˆæ”¯æŒé‡å¯ï¼‰

        æ¶æ„åŸåˆ™ï¼š
        - å•å‘æ§åˆ¶æµï¼šScheduler æ˜¯å”¯ä¸€çš„æ§åˆ¶ä¸­å¿ƒ
        - ExecutionNode è¢«åŠ¨æ¥æ”¶ Kafka å‘½ä»¤ï¼ˆportfolio.migrate, node.pause, node.resumeï¼‰
        - å¿ƒè·³æœºåˆ¶è®© Scheduler å‘ç°èŠ‚ç‚¹ï¼Œä½†æ‰€æœ‰åˆ†é…å†³ç­–ç”± Scheduler åšå‡º

        é‡å¯æ”¯æŒï¼š
        - âœ… æ”¯æŒé‡æ–°å¯åŠ¨ï¼ˆæ­£å¸¸åœæ­¢åå¯é‡å¯ï¼‰
        - âœ… çŠ¶æ€åœ¨å†…å­˜ï¼ˆé‡å¯åæ¸…ç©ºï¼‰
        - âœ… å¿ƒè·³æœºåˆ¶ï¼ˆTTL=30sï¼‰å®ç°è‡ªåŠ¨æ•…éšœæ£€æµ‹
        - âœ… å•å‘æ§åˆ¶ï¼šScheduler â†’ Kafka â†’ ExecutionNode

        å¯åŠ¨æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦å·²è¿è¡Œ
        2. é‡ç½®åœæ­¢æ ‡å¿—ï¼ˆæ”¯æŒé‡å¯ï¼‰
        3. æ¸…ç†æ—§çš„å¿ƒè·³æ•°æ®
        4. ä¸ŠæŠ¥å¿ƒè·³åˆ° Redisï¼ˆè®© Scheduler å‘ç°èŠ‚ç‚¹ï¼‰
        5. å¯åŠ¨å¿ƒè·³çº¿ç¨‹ï¼ˆç»´æŒèŠ‚ç‚¹åœ¨çº¿çŠ¶æ€ï¼‰
        6. å¯åŠ¨è°ƒåº¦æ›´æ–°çº¿ç¨‹ï¼ˆæ¥æ”¶ Scheduler å‘½ä»¤ï¼‰
        7. å¯åŠ¨å¸‚åœºæ•°æ®æ¶ˆè´¹çº¿ç¨‹ï¼ˆæ¥æ”¶ PriceUpdate äº‹ä»¶ï¼‰
        8. å¯åŠ¨è®¢å•å›æŠ¥æ¶ˆè´¹çº¿ç¨‹ï¼ˆæ¥æ”¶ OrderFeedback äº‹ä»¶ï¼‰

        Raises:
            RuntimeError: å¦‚æœèŠ‚ç‚¹å·²ç»åœ¨è¿è¡Œ
        """
        if self.is_running:
            raise RuntimeError(f"ExecutionNode {self.node_id} is already running")

        # æ£€æŸ¥node_idæ˜¯å¦å·²è¢«å…¶ä»–å®ä¾‹ä½¿ç”¨
        if self._is_node_id_in_use():
            print(f"\n[ERROR] ExecutionNode {self.node_id} is already in use by another process!")
            print(f"[ERROR] Cannot start duplicate node_id.")
            print(f"\nPossible solutions:")
            print(f"  1. Stop the other ExecutionNode instance (Ctrl+C)")
            print(f"  2. Use a different node_id: ginkgo execution start --node-id <new_id>")
            print(f"  3. Cleanup stale data: ginkgo execution cleanup --node-id {self.node_id}")
            raise RuntimeError(f"ExecutionNode {self.node_id} is already in use")

        # é‡ç½®åœæ­¢æ ‡å¿—ï¼ˆæ”¯æŒé‡å¯ï¼‰
        self.should_stop = False

        # è®¾ç½®è¿è¡Œæ ‡å¿—
        self.is_running = True
        self.started_at = datetime.now().isoformat()

        if self.is_paused:
            print(f"Resuming ExecutionNode {self.node_id} (was paused)")
            self.is_paused = False
        else:
            print(f"Starting ExecutionNode {self.node_id}")

        # 0. æ¸…ç†æ—§çš„å¿ƒè·³å’ŒæŒ‡æ ‡æ•°æ®ï¼ˆé˜²æ­¢èŠ‚ç‚¹å¼‚å¸¸é‡å¯åæ®‹ç•™ï¼‰
        self._cleanup_old_heartbeat_data()

        # 1. ç«‹å³å‘é€å¿ƒè·³ï¼ˆè®© Scheduler å‘ç°èŠ‚ç‚¹ï¼‰
        self._send_heartbeat()

        # 2. å¯åŠ¨å¿ƒè·³ä¸ŠæŠ¥çº¿ç¨‹ï¼ˆç»´æŒèŠ‚ç‚¹åœ¨çº¿çŠ¶æ€ï¼‰
        self._start_heartbeat_thread()

        # 3. å¯åŠ¨è°ƒåº¦æ›´æ–°è®¢é˜…çº¿ç¨‹ï¼ˆæ¥æ”¶ Scheduler å‘½ä»¤ï¼špause/resume/migrateï¼‰
        self._start_schedule_updates_thread()

        # 4. å¯åŠ¨å¸‚åœºæ•°æ®æ¶ˆè´¹çº¿ç¨‹ï¼ˆæ¥æ”¶ EventPriceUpdateï¼‰
        self._start_market_data_consumer_thread()

        # 5. å¯åŠ¨è®¢å•å›æŠ¥æ¶ˆè´¹çº¿ç¨‹ï¼ˆæ¥æ”¶ EventOrderPartiallyFilledï¼‰
        self._start_order_feedback_consumer_thread()

        print(f"[INFO] ExecutionNode {self.node_id} started")

        # å‘é€å¯åŠ¨é€šçŸ¥
        try:
            from ginkgo.notifier.core.notification_service import notify
            notify(
                f"æ‰§è¡ŒèŠ‚ç‚¹ {self.node_id} å·²å¯åŠ¨",
                level="INFO",
                module="ExecutionNode",
                details={
                    "èŠ‚ç‚¹ID": self.node_id,
                    "æœ€å¤§Portfolioæ•°": self.max_portfolios,
                    "å¿ƒè·³é—´éš”": f"{self.heartbeat_interval}ç§’"
                }
            )
        except Exception as e:
            logger.warning(f"Failed to send startup notification: {e}")
        print(f"[INFO] Portfolio count: {len(self.portfolios)} (waiting for Scheduler)")
        print(f"[INFO] Node is ready to receive portfolio.migrate commands from Scheduler")

    def stop(self):
        """
        åœæ­¢ExecutionNode - ä¼˜é›…å…³é—­æµç¨‹

        æ ¸å¿ƒç­–ç•¥ï¼š
        1. å…ˆå…³é—­ Consumerï¼Œåœæ­¢æ‹‰å–æ–°æ¶ˆæ¯
        2. ç­‰å¾… Portfolio æ¶ˆè´¹å®Œ input_queue
        3. ç­‰å¾… output_queue å‘é€å®Œæ¯•
        4. Portfolio å½»åº•å…³é—­
        5. ç­‰å¾…æ‰€æœ‰çº¿ç¨‹é€€å‡º
        6. ä¸ŠæŠ¥çŠ¶æ€ã€æ¸…ç†èµ„æº
        """
        if not self.is_running:
            print(f"[WARNING] ExecutionNode {self.node_id} is not running")
            return

        print(f"Stopping ExecutionNode {self.node_id}")

        # 0. è®¾ç½®åœæ­¢æ ‡å¿—ï¼ˆé€šçŸ¥æ‰€æœ‰çº¿ç¨‹ï¼‰
        self.should_stop = True
        self.is_running = False

        # 1. å…³é—­ Kafka Consumers - åˆ‡æ–­æ–°æ¶ˆæ¯æ¥æº
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ç¬¬ 1 æ­¥ï¼šå…³é—­ Kafka Consumersï¼ˆåœæ­¢æ‹‰å–æ–°æ¶ˆæ¯ï¼‰")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        if self.market_data_consumer:
            try:
                self.market_data_consumer.close()
                print(f"[INFO]   âœ… Market data consumer closed")
                print(f"[INFO]      â””â”€ ä¸å†æ‹‰å– Price Update")
                print(f"[INFO]      â””â”€ ä¸ä¼šè§¦å‘ç­–ç•¥ç”Ÿæˆæ–°è®¢å•")
            except Exception as e:
                print(f"[ERROR]   âœ— Error closing market data consumer: {e}")

        if self.order_feedback_consumer:
            try:
                self.order_feedback_consumer.close()
                print(f"[INFO]   âœ… Order feedback consumer closed")
                print(f"[INFO]      â””â”€ ä¸å†æ‹‰å– Order Feedback")
                print(f"[INFO]      â””â”€ ä¸ä¼šè§¦å‘é£æ§ç”Ÿæˆæ–°è®¢å•")
            except Exception as e:
                print(f"[ERROR]   âœ— Error closing order feedback consumer: {e}")

        if self.schedule_updates_consumer:
            try:
                self.schedule_updates_consumer.close()
                print(f"[INFO]   âœ… Schedule updates consumer closed")
                print(f"[INFO]      â””â”€ ä¸å†æ¥æ”¶è°ƒåº¦å‘½ä»¤")
            except Exception as e:
                print(f"[ERROR]   âœ— Error closing schedule updates consumer: {e}")

        # 2. ç­‰å¾… Portfolio æ¶ˆè´¹å®Œ input_queue
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ç¬¬ 2 æ­¥ï¼šç­‰å¾… Portfolio å¤„ç†å®Œ input_queue ä¸­çš„æ¶ˆæ¯")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        with self.portfolio_lock:
            processors = list(self.portfolios.values())

        if processors:
            wait_start = time.time()
            while time.time() - wait_start < 5:  # æœ€å¤šç­‰å¾… 5 ç§’
                total_remaining = 0
                for processor in processors:
                    remaining = processor.get_queue_size()
                    total_remaining += remaining

                if total_remaining == 0:
                    print(f"[INFO]   âœ… æ‰€æœ‰ input_queue å·²æ¸…ç©º")
                    print(f"[INFO]      â””â”€ å·²æ‹‰å–çš„æ¶ˆæ¯å·²å¤„ç†å®Œæ¯•")
                    break
                else:
                    print(f"[DEBUG]   ç­‰å¾… {total_remaining} ä¸ªäº‹ä»¶å¤„ç†å®Œæˆ...")
                    time.sleep(0.1)
            else:
                if total_remaining > 0:
                    print(f"[WARNING] âš ï¸  è¶…æ—¶ï¼Œä»æœ‰ {total_remaining} ä¸ªäº‹ä»¶æœªå¤„ç†")
        else:
            print(f"[INFO]   â„¹ï¸  æ²¡æœ‰ Portfolio è¿è¡Œï¼Œè·³è¿‡")

        # 3. ç­‰å¾… output_queue å‘é€å®Œæ¯•å¹¶åœæ­¢ listener
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ç¬¬ 3 æ­¥ï¼šç­‰å¾… output_queue ä¸­çš„è®¢å•å‘é€å®Œæˆ")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        if self.output_queue_threads:
            print(f"[INFO]   åœæ­¢ {len(self.output_queue_threads)} output queue listeners...")

            # è®¾ç½®åœæ­¢äº‹ä»¶
            for stop_event in self.output_queue_stop_events.values():
                stop_event.set()

            # ç­‰å¾…æ‰€æœ‰ listener å®Œæˆ
            for portfolio_id, thread in self.output_queue_threads.items():
                if thread.is_alive():
                    print(f"[DEBUG]   ç­‰å¾… output_queue listener ({portfolio_id[:8]}...) å®Œæˆ...")
                    thread.join(timeout=5)
                    if thread.is_alive():
                        print(f"[WARNING]   âš ï¸  Output queue listener ({portfolio_id[:8]}...) æœªèƒ½åœ¨ 5 ç§’å†…å®Œæˆ")
                    else:
                        print(f"[INFO]   âœ… Output queue listener ({portfolio_id[:8]}...) å·²å®Œæˆ")
                else:
                    print(f"[INFO]   âœ… Output queue listener ({portfolio_id[:8]}...) å·²åœæ­¢")

            # æ¸…ç©ºè¿½è¸ª
            self.output_queue_threads.clear()
            self.output_queue_stop_events.clear()
            print(f"[INFO]   âœ… æ‰€æœ‰ output_queue listener å·²åœæ­¢")
        else:
            print(f"[INFO]   â„¹ï¸  æ²¡æœ‰ output_queue listener è¿è¡Œï¼Œè·³è¿‡")

        # 4. å…³é—­ Producer - ç¡®ä¿æ‰€æœ‰è®¢å•å·²å‘é€
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ç¬¬ 4 æ­¥ï¼šå…³é—­ Producerï¼ˆç¡®ä¿æ‰€æœ‰è®¢å•å·²å‘é€ï¼‰")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        if hasattr(self, 'order_producer') and self.order_producer:
            try:
                self.order_producer.close()
                print(f"[INFO]   âœ… Order producer closed")
                print(f"[INFO]      â””â”€ flush() ç¡®ä¿æ‰€æœ‰è®¢å•å·²å‘é€")
                print(f"[INFO]      â””â”€ close() å…³é—­è¿æ¥")
            except Exception as e:
                print(f"[ERROR]   âœ— Error closing order producer: {e}")
        else:
            print(f"[INFO]   â„¹ï¸  Order producer ä¸å­˜åœ¨ï¼Œè·³è¿‡")

        # 5. ç­‰å¾…æ‰€æœ‰ Portfolio å…³é—­
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ç¬¬ 5 æ­¥ï¼šç­‰å¾…æ‰€æœ‰ PortfolioProcessor çº¿ç¨‹é€€å‡º")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        with self.portfolio_lock:
            processors = list(self.portfolios.values())

        for processor in processors:
            if processor.is_alive():
                portfolio_id_short = processor.portfolio_id[:8] if len(processor.portfolio_id) > 8 else processor.portfolio_id
                print(f"[DEBUG]   ç­‰å¾… Portfolio ({portfolio_id_short}...) é€€å‡º...")
                processor.join(timeout=5)
                if processor.is_alive():
                    print(f"[WARNING]   âš ï¸  Portfolio ({portfolio_id_short}...) æœªèƒ½åœ¨ 5 ç§’å†…é€€å‡º")
                else:
                    print(f"[INFO]   âœ… Portfolio ({portfolio_id_short}...) å·²é€€å‡º")
            else:
                portfolio_id_short = processor.portfolio_id[:8] if len(processor.portfolio_id) > 8 else processor.portfolio_id
                print(f"[INFO]   âœ… Portfolio ({portfolio_id_short}...) å·²åœæ­¢")

        if processors:
            print(f"[INFO]   âœ… æ‰€æœ‰ PortfolioProcessor çº¿ç¨‹å·²é€€å‡º")
        else:
            print(f"[INFO]   â„¹ï¸  æ²¡æœ‰ PortfolioProcessor è¿è¡Œï¼Œè·³è¿‡")

        # 6. ç­‰å¾…å…¶ä»–çº¿ç¨‹é€€å‡º
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ç¬¬ 6 æ­¥ï¼šç­‰å¾…å…¶ä»–çº¿ç¨‹é€€å‡º")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        threads_to_wait = [
            ("Market data thread", self.market_data_thread),
            ("Order feedback thread", self.order_feedback_thread),
            ("Schedule updates thread", self.schedule_updates_thread),
        ]

        for name, thread in threads_to_wait:
            if thread and thread.is_alive():
                print(f"[DEBUG]   ç­‰å¾… {name} é€€å‡º...")
                thread.join(timeout=5)
                if not thread.is_alive():
                    print(f"[INFO]   âœ… {name} å·²é€€å‡º")
                else:
                    print(f"[WARNING]   âš ï¸  {name} æœªèƒ½åœ¨ 5 ç§’å†…é€€å‡º")

        # 7. åœæ­¢å¿ƒè·³çº¿ç¨‹
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ç¬¬ 7 æ­¥ï¼šåœæ­¢å¿ƒè·³çº¿ç¨‹")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        if self.heartbeat_thread and self.heartbeat_thread.is_alive():
            self.heartbeat_thread.join(timeout=5)
            if not self.heartbeat_thread.is_alive():
                print(f"[INFO]   âœ… Heartbeat thread å·²é€€å‡º")
            else:
                print(f"[WARNING]   âš ï¸  Heartbeat thread æœªèƒ½åœ¨ 5 ç§’å†…é€€å‡º")

        # 8. æ¸…ç† Redisï¼ˆä¸ŠæŠ¥ç¦»çº¿çŠ¶æ€ï¼‰
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ç¬¬ 8 æ­¥ï¼šæ¸…ç† Redis æ•°æ®ï¼ˆä¸ŠæŠ¥ç¦»çº¿çŠ¶æ€ï¼‰")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        try:
            redis_client = self._get_redis_client()
            if redis_client:
                heartbeat_key = f"heartbeat:node:{self.node_id}"
                metrics_key = f"node:metrics:{self.node_id}"

                deleted_heartbeat = redis_client.delete(heartbeat_key)
                if deleted_heartbeat:
                    print(f"[INFO]   âœ… å¿ƒè·³æ•°æ®å·²åˆ é™¤ï¼ˆScheduler å°†æ£€æµ‹åˆ°èŠ‚ç‚¹ç¦»çº¿ï¼‰")

                deleted_metrics = redis_client.delete(metrics_key)
                if deleted_metrics:
                    print(f"[INFO]   âœ… æŒ‡æ ‡æ•°æ®å·²åˆ é™¤")

        except Exception as e:
            print(f"[ERROR]   âœ— æ¸…ç† Redis å¤±è´¥: {e}")

        # 9. æ¸…ç©ºå†…å­˜
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ç¬¬ 9 æ­¥ï¼šæ¸…ç©ºå†…å­˜æ•°æ®ç»“æ„")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        with self.portfolio_lock:
            portfolio_count = len(self.portfolios)
            self.portfolios.clear()

        self.input_queues.clear()
        self.output_queues.clear()

        print(f"[INFO]   âœ… å†…å­˜å·²æ¸…ç©º (portfolios: {portfolio_count}, queuesé‡Šæ”¾)")

        # 10. å®Œæˆ
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] âœ… ExecutionNode {self.node_id} å·²å®Œå…¨åœæ­¢")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        # å‘é€ä¼˜é›…é€€å‡ºé€šçŸ¥
        try:
            from ginkgo.notifier.core.notification_service import notify
            notify(
                f"æ‰§è¡ŒèŠ‚ç‚¹ {self.node_id} å·²ä¼˜é›…é€€å‡º",
                level="INFO",
                module="ExecutionNode",
                details={
                    "èŠ‚ç‚¹ID": self.node_id,
                    "å…³é—­çš„Portfolioæ•°": portfolio_count,
                    "è¿è¡Œæ—¶é•¿": self._get_uptime()
                }
            )
        except Exception as e:
            logger.warning(f"Failed to send shutdown notification: {e}")

    def load_portfolio(self, portfolio_id: str) -> bool:
        """
        ä»æ•°æ®åº“åŠ è½½Portfolioé…ç½®å¹¶åˆ›å»ºå®ä¾‹

        æ¶æ„è¯´æ˜ï¼ˆå•å‘æ§åˆ¶æµï¼‰ï¼š
        - æ­¤æ–¹æ³•åªåº”è¢« Scheduler é€šè¿‡ Kafka çš„ portfolio.migrate å‘½ä»¤è°ƒç”¨
        - ExecutionNode è¢«åŠ¨æ¥æ”¶å‘½ä»¤ï¼Œä¸ä¸»åŠ¨åŠ è½½ Portfolio
        - æ‰€æœ‰ Portfolio åˆ†é…å†³ç­–ç”± Scheduler ä¸­å¿ƒè°ƒåº¦æ§åˆ¶

        æ§åˆ¶æµï¼š
        Scheduler â†’ Redis schedule:plan â†’ Kafka schedule.updates â†’ ExecutionNode.load_portfolio()

        Args:
            portfolio_id: Portfolio IDï¼ˆUUIDï¼‰

        Returns:
            bool: åŠ è½½æˆåŠŸè¿”å›True

        Raises:
            ValueError: Portfolioä¸æ˜¯å®ç›˜Portfolioæˆ–ä¸å­˜åœ¨
        """
        try:
            logger.info(f"[LOAD] Loading portfolio {portfolio_id[:8]} from database...")

            # 1. é€šè¿‡PortfolioServiceä»æ•°æ®åº“æŸ¥è¯¢Portfolioé…ç½®
            portfolio_service = services.data.portfolio_service()
            portfolio_result = portfolio_service.get(portfolio_id=portfolio_id)

            if not portfolio_result.is_success():
                logger.error(f"[LOAD] Failed to load portfolio {portfolio_id[:8]}: {portfolio_result.error}")
                return False

            # portfolio_result.data æ˜¯MPortfolioå¯¹è±¡åˆ—è¡¨
            portfolios = portfolio_result.data
            if not portfolios or len(portfolios) == 0:
                logger.error(f"[LOAD] Portfolio {portfolio_id[:8]} not found in database")
                return False

            portfolio_model = portfolios[0]
            logger.info(f"[LOAD] Found portfolio: {portfolio_model.name} (is_live={portfolio_model.is_live})")

            # 2. éªŒè¯is_live=True
            if not portfolio_model.is_live:
                raise ValueError(f"Portfolio {portfolio_id} is not a live portfolio")

            # 3. ä½¿ç”¨PortfolioServiceåŠ è½½å®Œæ•´çš„Portfolioï¼ˆåŒ…å«æ‰€æœ‰ç»„ä»¶ï¼‰
            logger.info(f"[LOAD] Loading portfolio with all components via PortfolioService...")
            load_result = portfolio_service.load_portfolio_with_components(portfolio_id)

            if not load_result.is_success:
                logger.error(f"[LOAD] Failed to load portfolio with components: {load_result.error}")
                return False

            portfolio = load_result.data
            logger.info(f"[LOAD] âœ“ Portfolio loaded with all components")

            # 4. æ¢å¤ Portfolio çŠ¶æ€ï¼ˆä»æ•°æ®åº“ï¼‰
            logger.info(f"[LOAD] Restoring portfolio state from database...")
            self._restore_portfolio_state(portfolio, portfolio_id)

            with self.portfolio_lock:
                # 5. æ£€æŸ¥æ˜¯å¦å·²åŠ è½½
                if portfolio_id in self.portfolios:
                    logger.warning(f"[LOAD] Portfolio {portfolio_id[:8]} already loaded")
                    return False

                # 6. ä¿å­˜Portfolioå®ä¾‹ï¼ˆExecutionNodeæŒæœ‰å”¯ä¸€å®ä¾‹ï¼‰
                self._portfolio_instances[portfolio_id] = portfolio
                logger.info(f"[LOAD] Portfolio instance saved")

                # 7. åˆ›å»ºInput Queueå’ŒOutput Queueï¼ˆExecutionNodeæŒæœ‰æ‰€æœ‰é˜Ÿåˆ—ï¼‰
                logger.info(f"[LOAD] Creating dual queues (input/output)...")
                input_queue = Queue(maxsize=1000)
                output_queue = Queue(maxsize=1000)

                # ä¿å­˜åˆ°ExecutionNodeçš„é˜Ÿåˆ—å­—å…¸
                self.input_queues[portfolio_id] = input_queue
                self.output_queues[portfolio_id] = output_queue

                # 8. åˆ›å»ºPortfolioProcessorï¼ˆä¼ å…¥é˜Ÿåˆ—å¼•ç”¨ï¼‰
                logger.info(f"[LOAD] Creating PortfolioProcessor...")
                processor = PortfolioProcessor(
                    portfolio=portfolio,
                    input_queue=input_queue,
                    output_queue=output_queue,
                    max_queue_size=1000
                )

                # 9. å¯åŠ¨output_queueç›‘å¬å™¨ï¼ˆExecutionNodeè´Ÿè´£åºåˆ—åŒ–å¹¶å‘Kafkaï¼‰
                logger.info(f"[LOAD] Starting output queue listener...")
                self._start_output_queue_listener(output_queue, portfolio_id)

                # 10. å¯åŠ¨Processor
                logger.info(f"[LOAD] Starting PortfolioProcessor thread...")
                processor.start()

                # 11. æ³¨å†Œåˆ°ExecutionNode
                self.portfolios[portfolio_id] = processor
                logger.info(f"[LOAD] PortfolioProcessor registered")

                # 12. æ·»åŠ åˆ°InterestMapï¼ˆPhase 4å®ç°ï¼‰
                # è·å–Portfolioè®¢é˜…çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
                logger.info(f"[LOAD] Setting up interest map subscriptions...")
                subscribed_codes = self._get_subscribed_codes(portfolio)
                if subscribed_codes:
                    self.interest_map.add_portfolio(portfolio_id, subscribed_codes)
                    logger.info(f"[LOAD] Portfolio subscribed to {len(subscribed_codes)} codes: {subscribed_codes[:5]}...")
                else:
                    logger.warning(f"[LOAD] Portfolio has no subscribed codes, using default subscription")
                    # MVPé˜¶æ®µï¼šä½¿ç”¨é»˜è®¤è®¢é˜…ï¼ˆå‰5ä¸ªAè‚¡ï¼‰
                    default_codes = ["000001.SZ", "000002.SZ", "000004.SZ", "600000.SH", "600036.SH"]
                    self.interest_map.add_portfolio(portfolio_id, default_codes)

                logger.info(f"[LOAD] âœ“ Portfolio {portfolio_id[:8]} loaded successfully with dual queues")
                logger.info(f"[LOAD] Total portfolios on node: {len(self.portfolios)}")

                # å‘é€PortfolioåŠ è½½æˆåŠŸé€šçŸ¥
                try:
                    from ginkgo.notifier.core.notification_service import notify
                    notify(
                        f"Portfolio {portfolio_model.name} å·²åŠ è½½åˆ°èŠ‚ç‚¹ {self.node_id}",
                        level="INFO",
                        module="ExecutionNode",
                        details={
                            "Portfolioåç§°": portfolio_model.name,
                            "èŠ‚ç‚¹ID": self.node_id,
                            "è®¢é˜…è‚¡ç¥¨æ•°": len(subscribed_codes) if subscribed_codes else 0,
                            "å½“å‰èŠ‚ç‚¹Portfolioæ•°": len(self.portfolios)
                        }
                    )
                except Exception as e:
                    logger.warning(f"Failed to send portfolio load notification: {e}")

                # è¾“å‡ºè¿è¡Œæ—¶ç»„ä»¶å¿«ç…§
                self._print_portfolio_runtime_snapshot(portfolio)

                # TODO: ä¸ŠæŠ¥çŠ¶æ€åˆ°Redisï¼ˆPhase 5å®ç°ï¼‰
                return True

        except ValueError as e:
            logger.error(f"[LOAD] Validation error loading portfolio {portfolio_id[:8]}: {e}")
            return False
        except Exception as e:
            logger.error(f"[LOAD] Error loading portfolio {portfolio_id[:8]}: {e}")
            return False

    def _restore_portfolio_state(self, portfolio: "PortfolioLive", portfolio_id: str):
        """
        ä»æ•°æ®åº“æ¢å¤PortfolioçŠ¶æ€ï¼ˆMVPé˜¶æ®µï¼šå ä½ç¬¦å®ç°ï¼‰

        Phase 4éœ€è¦æ¢å¤çš„çŠ¶æ€ï¼š
        - å½“å‰æŒä»“ï¼ˆpositionsï¼‰
        - æ´»è·ƒè®¢å•ï¼ˆactive ordersï¼‰
        - ç°é‡‘ä½™é¢ï¼ˆcash balanceï¼‰
        - å·²å®ç°ç›ˆäºï¼ˆrealized P&Lï¼‰

        MVPé˜¶æ®µï¼š
        - å ä½ç¬¦å®ç°ï¼Œä¸æ¢å¤ä»»ä½•çŠ¶æ€
        - Portfolioä»¥å…¨æ–°çŠ¶æ€å¯åŠ¨
        - TODO: Phase 4å®ç°å®Œæ•´çš„çŠ¶æ€æ¢å¤é€»è¾‘

        Args:
            portfolio: Portfolioå®ä¾‹
            portfolio_id: Portfolio ID
        """
        logger.info(f"[RESTORE] Portfolio state restoration (MVP placeholder)")
        logger.info(f"[RESTORE] TODO: Implement state restoration in Phase 4")
        # MVPé˜¶æ®µï¼šä¸æ¢å¤ä»»ä½•çŠ¶æ€ï¼ŒPortfolioä»¥å…¨æ–°çŠ¶æ€å¯åŠ¨
        # Phase 4éœ€è¦ï¼š
        # 1. ä»æ•°æ®åº“è¯»å–å½“å‰æŒä»“
        # 2. ä»æ•°æ®åº“è¯»å–æ´»è·ƒè®¢å•
        # 3. æ¢å¤ç°é‡‘ä½™é¢
        # 4. æ¢å¤å·²å®ç°ç›ˆäº

    def _load_portfolio_components(self, portfolio: "PortfolioLive", portfolio_model):
        """
        [DEPRECATED] æ­¤æ–¹æ³•å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨PortfolioService.load_portfolio_with_components()

        ç»„ä»¶åŠ è½½é€»è¾‘å·²ç§»åˆ°PortfolioServiceä¸­ï¼Œè¿™æ ·å¯ä»¥ï¼š
        - èŒè´£åˆ†ç¦»ï¼ˆServiceè´Ÿè´£ä¸šåŠ¡é€»è¾‘ï¼ŒNodeè´Ÿè´£è°ƒåº¦ï¼‰
        - ä»£ç å¤ç”¨ï¼ˆå…¶ä»–åœ°æ–¹ä¹Ÿå¯ä»¥ä½¿ç”¨ServiceåŠ è½½Portfolioï¼‰
        - ç®€åŒ–ExecutionNodeä»£ç 

        Args:
            portfolio: PortfolioLiveå®ä¾‹
            portfolio_model: æ•°æ®åº“ä¸­çš„Portfolioæ¨¡å‹
        """
        # ä¸å†ä½¿ç”¨æ­¤æ–¹æ³•ï¼Œç›´æ¥è¿”å›
        logger.warning("[DEPRECATED] _load_portfolio_componentså·²åºŸå¼ƒï¼Œç»„ä»¶ç”±PortfolioServiceåŠ è½½")
        return

        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ğŸ“¦ Portfolio Components Loading")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] Portfolio: {portfolio.name} ({portfolio.portfolio_id[:8]})")

        try:
            # è·å–Portfolioçš„æ‰€æœ‰ç»„ä»¶
            # Portfolioç°åœ¨å·²ç»ä½¿ç”¨æ•°æ®åº“UUIDï¼Œæ‰€ä»¥portfolio.portfolio_idå°±æ˜¯æ­£ç¡®çš„ID
            components_result = portfolio_service.get_components(portfolio_id=portfolio.portfolio_id)

            if not components_result.is_success():
                print(f"[WARNING] Failed to load components: {components_result.error}")
                return

            components = components_result.data

            # åˆ†ç±»ç»Ÿè®¡
            strategies = []
            sizers = []
            risk_managers = []

            if components:
                print(f"[INFO] Found {len(components)} components in database")

                # ç¬¬äºŒç‰ˆï¼šå®é™…åŠ è½½ç»„ä»¶åˆ°Portfolio
                # ç»„ä»¶åˆ†ç±»
                strategies_list = []
                selectors_list = []
                sizers_list = []
                risk_managers_list = []

                for component in components:
                    comp_type = component.get('component_type', 'UNKNOWN')

                    if comp_type == 'strategy':
                        strategies_list.append(component)
                    elif comp_type == 'selector':
                        selectors_list.append(component)
                    elif comp_type == 'sizer':
                        sizers_list.append(component)
                    elif comp_type == 'risk_management':
                        risk_managers_list.append(component)

                # ç»„ä»¶ç»Ÿè®¡
                print(f"[INFO]")
                print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
                print(f"[INFO] ğŸ“Š Component Summary")
                print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
                print(f"[INFO] Strategies:   {len(strategies_list)}")
                print(f"[INFO] Selectors:    {len(selectors_list)}")
                print(f"[INFO] Sizers:       {len(sizers_list)}")
                print(f"[INFO] Risk Managers: {len(risk_managers_list)}")
                print(f"[INFO] Total:        {len(components)}")

                # å®é™…åŠ è½½ç»„ä»¶
                self._bind_components_to_portfolio(
                    portfolio,
                    strategies_list,
                    selectors_list,
                    sizers_list,
                    risk_managers_list
                )
            else:
                print(f"[INFO] No components found in database")
                print(f"[INFO] Using default components for portfolio")

                # ä½¿ç”¨é»˜è®¤ç»„ä»¶
                self._bind_components_to_portfolio(
                    portfolio,
                    [],  # ç©ºç­–ç•¥åˆ—è¡¨ - ä¼šä½¿ç”¨é»˜è®¤RandomSignalStrategy
                    [],  # ç©ºselectoråˆ—è¡¨ - ä¼šä½¿ç”¨é»˜è®¤CNAllSelector
                    [],  # ç©ºsizeråˆ—è¡¨ - ä¼šä½¿ç”¨é»˜è®¤FixedSizer
                    []   # ç©ºé£æ§åˆ—è¡¨ - ä¼šä½¿ç”¨é»˜è®¤PositionRatioRisk
                )

        except Exception as e:
            print(f"[ERROR] Error loading portfolio components: {e}")
            import traceback
            print(f"[ERROR] Traceback: {traceback.format_exc()}")

        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

    def _print_portfolio_runtime_snapshot(self, portfolio: "PortfolioLive"):
        """
        è¾“å‡º Portfolio è¿è¡Œæ—¶ç»„ä»¶å¿«ç…§

        æ˜¾ç¤ºå½“å‰åŠ è½½åˆ° Portfolio ä¸­çš„æ‰€æœ‰ç»„ä»¶åŠå…¶é…ç½®å‚æ•°ã€‚

        Args:
            portfolio: PortfolioLive å®ä¾‹
        """
        print(f"[INFO]")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ğŸ” Portfolio Runtime Snapshot")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] Portfolio: {portfolio.name} ({portfolio.portfolio_id[:8]})")
        print(f"[INFO] Engine ID: {portfolio.engine_id[:8] if portfolio.engine_id else 'N/A'}")
        print(f"[INFO] Run ID: {portfolio.run_id[:8] if portfolio.run_id else 'N/A'}")
        print(f"[INFO]")

        # 1. åŸºæœ¬ä¿¡æ¯
        print(f"[INFO] ğŸ“‹ Basic Information")
        print(f"[INFO] â”œâ”€ Initial Capital: {portfolio.initial_capital}")
        print(f"[INFO] â”œâ”€ Current Cash: {portfolio.cash}")
        print(f"[INFO] â”œâ”€ Frozen Cash: {portfolio.frozen_cash}")
        # PortfolioLive å¯èƒ½æ²¡æœ‰ get_total_value() æ–¹æ³•ï¼Œä½¿ç”¨ cash ä»£æ›¿
        total_value = portfolio.get_total_value() if hasattr(portfolio, 'get_total_value') else portfolio.cash
        print(f"[INFO] â”œâ”€ Total Value: {total_value}")
        print(f"[INFO] â”œâ”€ Position Count: {len(portfolio.positions)}")
        print(f"[INFO] â””â”€ Status: {portfolio._status}")
        print(f"[INFO]")

        # 2. ç­–ç•¥ç»„ä»¶
        print(f"[INFO] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"[INFO] ğŸ“Š Strategy Components ({len(portfolio.strategies)})")
        print(f"[INFO] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

        if portfolio.strategies:
            for i, strategy in enumerate(portfolio.strategies, 1):
                print(f"[INFO]")
                print(f"[INFO] Strategy #{i}: {strategy.name}")
                print(f"[INFO]   â”œâ”€ Type: {type(strategy).__name__}")
                print(f"[INFO]   â”œâ”€ UUID: {strategy.uuid[:8] if strategy.uuid else 'N/A'}")
                print(f"[INFO]   â””â”€ Parameters:")

                # è·å–ç­–ç•¥å‚æ•°
                params = self._get_component_parameters(strategy)
                for param_name, param_value in params.items():
                    print(f"[INFO]      â”œâ”€ {param_name}: {param_value}")
        else:
            print(f"[INFO] âš ï¸  No strategies loaded (Portfolio will not generate signals)")

        print(f"[INFO]")

        # 3. Sizer ç»„ä»¶
        print(f"[INFO] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"[INFO] ğŸ“ Sizer Component")
        print(f"[INFO] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

        if portfolio.sizer:
            print(f"[INFO]")
            print(f"[INFO] Sizer: {portfolio.sizer.name}")
            print(f"[INFO]   â”œâ”€ Type: {type(portfolio.sizer).__name__}")
            print(f"[INFO]   â”œâ”€ UUID: {portfolio.sizer.uuid[:8] if portfolio.sizer.uuid else 'N/A'}")
            print(f"[INFO]   â””â”€ Parameters:")

            # è·å– Sizer å‚æ•°
            params = self._get_component_parameters(portfolio.sizer)
            for param_name, param_value in params.items():
                print(f"[INFO]      â”œâ”€ {param_name}: {param_value}")
        else:
            print(f"[INFO] âš ï¸  No sizer loaded (Orders will use default size)")

        print(f"[INFO]")

        # 4. é£æ§ç»„ä»¶
        print(f"[INFO] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"[INFO] ğŸ›¡ï¸  Risk Management Components ({len(portfolio.risk_managers)})")
        print(f"[INFO] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

        if portfolio.risk_managers:
            for i, risk_manager in enumerate(portfolio.risk_managers, 1):
                print(f"[INFO]")
                print(f"[INFO] Risk Manager #{i}: {risk_manager.name}")
                print(f"[INFO]   â”œâ”€ Type: {type(risk_manager).__name__}")
                print(f"[INFO]   â”œâ”€ UUID: {risk_manager.uuid[:8] if risk_manager.uuid else 'N/A'}")
                print(f"[INFO]   â””â”€ Parameters:")

                # è·å–é£æ§å‚æ•°
                params = self._get_component_parameters(risk_manager)
                for param_name, param_value in params.items():
                    print(f"[INFO]      â”œâ”€ {param_name}: {param_value}")
        else:
            print(f"[INFO] âš ï¸  No risk managers loaded (Orders will not be filtered)")

        print(f"[INFO]")

        # 5. æŒä»“å¿«ç…§
        print(f"[INFO] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"[INFO] ğŸ’¼ Current Positions ({len(portfolio.positions)})")
        print(f"[INFO] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

        if portfolio.positions:
            for code, position in list(portfolio.positions.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"[INFO]   {code}: {position.volume} shares @ {position.price}")
            if len(portfolio.positions) > 5:
                print(f"[INFO]   ... and {len(portfolio.positions) - 5} more")
        else:
            print(f"[INFO]   No positions yet")

        print(f"[INFO]")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] âœ… Runtime Snapshot Complete")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

    def _get_component_parameters(self, component) -> dict:
        """
        è·å–ç»„ä»¶çš„æ‰€æœ‰é…ç½®å‚æ•°

        é€šè¿‡åå°„è·å–ç»„ä»¶å®ä¾‹çš„æ‰€æœ‰å±æ€§ï¼Œè¿‡æ»¤æ‰å†…éƒ¨å±æ€§å’Œæ–¹æ³•ã€‚

        Args:
            component: ç»„ä»¶å®ä¾‹ï¼ˆStrategyã€Sizerã€RiskManagementï¼‰

        Returns:
            dict: å‚æ•°å­—å…¸
        """
        params = {}

        # éœ€è¦è¿‡æ»¤çš„å±æ€§
        filtered_attrs = {
            '_logger', '_name', '_uuid', 'logger', 'name', 'uuid',
            '__class__', '__module__', '__dict__', '__weakref__',
            'is_active', 'set_active', 'get_info', 'cal', 'generate_signals'
        }

        try:
            # è·å–æ‰€æœ‰å®ä¾‹å±æ€§
            for attr_name in dir(component):
                # è¿‡æ»¤æ‰æ–¹æ³•å’Œç‰¹æ®Šå±æ€§
                if attr_name.startswith('_') or callable(getattr(component, attr_name)):
                    continue

                if attr_name in filtered_attrs:
                    continue

                try:
                    attr_value = getattr(component, attr_name)

                    # è¿‡æ»¤æ‰å¤æ‚å¯¹è±¡
                    if isinstance(attr_value, (str, int, float, bool, list, dict, type(None))):
                        params[attr_name] = attr_value
                except:
                    pass

        except Exception as e:
            print(f"[WARNING] Error getting parameters for {type(component).__name__}: {e}")

        return params

    def _bind_components_to_portfolio(
        self,
        portfolio: "PortfolioLive",
        strategies_list: list,
        selectors_list: list,
        sizers_list: list,
        risk_managers_list: list
    ):
        """
        å°†æ•°æ®åº“ä¸­çš„ç»„ä»¶é…ç½®å®ä¾‹åŒ–å¹¶ç»‘å®šåˆ°Portfolio

        å‚è€ƒå›æµ‹å¼•æ“çš„_perform_component_bindingæ–¹æ³•å®ç°

        Args:
            portfolio: PortfolioLiveå®ä¾‹
            strategies_list: ç­–ç•¥ç»„ä»¶é…ç½®åˆ—è¡¨
            selectors_list: é€‰è‚¡å™¨ç»„ä»¶é…ç½®åˆ—è¡¨
            sizers_list: ä»“ä½ç®¡ç†ç»„ä»¶é…ç½®åˆ—è¡¨
            risk_managers_list: é£æ§ç®¡ç†å™¨ç»„ä»¶é…ç½®åˆ—è¡¨
        """
        print(f"[INFO]")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"[INFO] ğŸ”§ Binding Components to Portfolio")
        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        try:
            # 1. åŠ è½½ç­–ç•¥ (å¿…éœ€)
            if len(strategies_list) == 0:
                print(f"[WARNING] No strategy found, using default RandomSignalStrategy")
                default_strategy = self._get_default_component('strategy')
                if default_strategy:
                    portfolio.add_strategy(default_strategy)
                    print(f"[INFO] âœ… Added default strategy: {default_strategy.__class__.__name__}")
            else:
                for strategy_config in strategies_list:
                    strategy = self._instantiate_component_from_config(strategy_config, 'strategy')
                    if strategy:
                        portfolio.add_strategy(strategy)
                        print(f"[INFO] âœ… Added strategy: {strategy.__class__.__name__}")

            # 2. åŠ è½½é€‰è‚¡å™¨ (å¿…éœ€)
            if len(selectors_list) == 0:
                print(f"[WARNING] No selector found, using default CNAllSelector")
                default_selector = self._get_default_component('selector')
                if default_selector:
                    portfolio.bind_selector(default_selector)
                    print(f"[INFO] âœ… Bound default selector: {default_selector.__class__.__name__}")
            else:
                selector_config = selectors_list[0]  # åªä½¿ç”¨ç¬¬ä¸€ä¸ªselector
                selector = self._instantiate_component_from_config(selector_config, 'selector')
                if selector:
                    portfolio.bind_selector(selector)
                    print(f"[INFO] âœ… Bound selector: {selector.__class__.__name__}")

            # 3. åŠ è½½ä»“ä½ç®¡ç† (å¿…éœ€)
            if len(sizers_list) == 0:
                print(f"[WARNING] No sizer found, using default FixedSizer")
                default_sizer = self._get_default_component('sizer')
                if default_sizer:
                    portfolio.bind_sizer(default_sizer)
                    print(f"[INFO] âœ… Bound default sizer: {default_sizer.__class__.__name__}")
            else:
                sizer_config = sizers_list[0]  # åªä½¿ç”¨ç¬¬ä¸€ä¸ªsizer
                sizer = self._instantiate_component_from_config(sizer_config, 'sizer')
                if sizer:
                    portfolio.bind_sizer(sizer)
                    print(f"[INFO] âœ… Bound sizer: {sizer.__class__.__name__}")

            # 4. åŠ è½½é£æ§ç®¡ç†å™¨ (å¯é€‰)
            if len(risk_managers_list) == 0:
                print(f"[INFO] No risk managers found, using default PositionRatioRisk")
                default_risk = self._get_default_component('risk_management')
                if default_risk:
                    portfolio.add_risk_manager(default_risk)
                    print(f"[INFO] âœ… Added default risk manager: {default_risk.__class__.__name__}")
            else:
                for risk_config in risk_managers_list:
                    risk_manager = self._instantiate_component_from_config(risk_config, 'risk_management')
                    if risk_manager:
                        portfolio.add_risk_manager(risk_manager)
                        print(f"[INFO] âœ… Added risk manager: {risk_manager.__class__.__name__}")

            print(f"[INFO]")
            print(f"[INFO] âœ… Component binding completed")

        except Exception as e:
            print(f"[ERROR] Failed to bind components: {e}")
            import traceback
            print(f"[ERROR] Traceback: {traceback.format_exc()}")

        print(f"[INFO] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

    def _instantiate_component_from_config(self, component_config: dict, component_type: str):
        """
        ä»ç»„ä»¶é…ç½®å®ä¾‹åŒ–ç»„ä»¶

        å‚è€ƒå›æµ‹å¼•æ“çš„_instantiate_component_from_fileæ–¹æ³•

        Args:
            component_config: ç»„ä»¶é…ç½®å­—å…¸ (åŒ…å«component_id=file_id)
            component_type: ç»„ä»¶ç±»å‹ (strategy/selector/sizer/risk_management)

        Returns:
            ç»„ä»¶å®ä¾‹ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # component_configåŒ…å«: mount_id, portfolio_id, component_id(file_id), component_name, component_type
            file_id = component_config.get('component_id')  # æ³¨æ„ï¼šè¿™é‡Œæ˜¯component_idï¼Œå¯¹åº”file_id
            if not file_id:
                print(f"[WARNING] No component_id in component config")
                return None

            # è·å–å‚æ•°
            mount_id = component_config.get('mount_id')
            component_params = []

            if mount_id:
                try:
                    from ginkgo.data.containers import container
                    param_crud = container.cruds.param()
                    param_records = param_crud.find(filters={"mapping_id": mount_id})

                    if param_records:
                        # æŒ‰indexæ’åº
                        sorted_params = sorted(param_records, key=lambda p: p.index)
                        component_params = [param.value for param in sorted_params]
                        print(f"[DEBUG] Found {len(component_params)} params for {component_config.get('component_name')}")
                    else:
                        print(f"[DEBUG] No params found for mount_id {mount_id[:8]}...")

                except Exception as e:
                    print(f"[WARNING] Failed to get params: {e}")

            # è·å–file_service
            file_service = services.data.file_service()

            # è·å–æ–‡ä»¶å†…å®¹
            file_result = file_service.get_by_uuid(file_id)
            if not file_result.success or not file_result.data:
                print(f"[WARNING] Failed to get file {file_id[:8]}...: {file_result.error}")
                # å°è¯•ä½¿ç”¨é»˜è®¤ç»„ä»¶
                return self._get_default_component(component_type)

            file_info = file_result.data
            if isinstance(file_info, dict) and "file" in file_info:
                mfile = file_info["file"]
                if hasattr(mfile, "data") and mfile.data:
                    if isinstance(mfile.data, bytes):
                        code_content = mfile.data.decode("utf-8", errors="ignore")
                    else:
                        code_content = str(mfile.data)
                else:
                    # Fallback: ä½¿ç”¨é»˜è®¤ç»„ä»¶
                    print(f"[WARNING] No file data, using default component")
                    return self._get_default_component(component_type)
            else:
                return self._get_default_component(component_type)

            # åŠ¨æ€æ‰§è¡Œä»£ç 
            import importlib.util
            import tempfile
            import os
            import sys

            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as temp_file:
                temp_file.write(code_content)
                temp_file_path = temp_file.name

            try:
                # ä¸ºå…¼å®¹æ€§æ·»åŠ get_barså‡½æ•°
                from ginkgo.data.containers import container as data_container

                def get_bars_stub(*args, **kwargs):
                    """å…¼å®¹æ€§å­˜æ ¹"""
                    bar_service = data_container.bar_service()
                    return bar_service.get(*args, **kwargs)

                sys.modules["ginkgo.data"] = type(sys)("ginkgo.data")
                sys.modules["ginkgo.data"].get_bars = get_bars_stub
                sys.modules["ginkgo.data"].container = data_container

                # åŠ¨æ€å¯¼å…¥æ¨¡å—
                spec = importlib.util.spec_from_file_location("dynamic_component", temp_file_path)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)

                # æŸ¥æ‰¾ç»„ä»¶ç±»
                component_class = None
                for attr_name in dir(module):
                    if attr_name.startswith("_"):
                        continue
                    attr = getattr(module, attr_name)
                    if isinstance(attr, type) and hasattr(attr, "__bases__"):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»„ä»¶ç±»
                        is_component = False

                        # æ£€æŸ¥__abstract__å±æ€§
                        if hasattr(attr, "__abstract__") and not getattr(attr, "__abstract__", True):
                            is_component = True
                        else:
                            # æ£€æŸ¥åŸºç±»åç§°
                            for base in attr.__bases__:
                                base_name = base.__name__
                                if base_name.endswith("Strategy") or base_name.endswith("Selector") or \
                                   base_name.endswith("Sizer") or base_name.endswith("RiskManagement") or \
                                   base_name == "BaseStrategy" or base_name == "BaseSelector" or \
                                   base_name == "BaseSizer" or base_name == "BaseRiskManagement":
                                    is_component = True
                                    break

                        if is_component:
                            component_class = attr
                            break

                if component_class is None:
                    print(f"[ERROR] No component class found in file")
                    return self._get_default_component(component_type)

                # å®ä¾‹åŒ–ç»„ä»¶
                try:
                    if component_params:
                        # æœ‰å‚æ•°ï¼šä½¿ç”¨å‚æ•°å®ä¾‹åŒ–
                        print(f"[DEBUG] Creating {component_class.__name__} with params: {component_params}")
                        component = component_class(*component_params)
                    else:
                        # æ— å‚æ•°ï¼šå°è¯•æ— å‚å®ä¾‹åŒ–ï¼ˆå…è®¸ä½¿ç”¨é»˜è®¤å€¼ï¼‰
                        print(f"[INFO] No params found for {component_class.__name__}, attempting instantiation with defaults")
                        component = component_class()

                    print(f"[DEBUG] Created {component_class.__name__} instance")
                    return component
                except Exception as e:
                    print(f"[ERROR] Failed to instantiate {component_class.__name__}: {e}")
                    return self._get_default_component(component_type)

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_file_path)
                except:
                    pass

        except Exception as e:
            print(f"[ERROR] Failed to instantiate component: {e}")
            return self._get_default_component(component_type)

    def _get_default_component(self, component_type: str):
        """
        è·å–é»˜è®¤ç»„ä»¶ä½œä¸ºfallback

        Args:
            component_type: ç»„ä»¶ç±»å‹

        Returns:
            é»˜è®¤ç»„ä»¶å®ä¾‹
        """
        if component_type == 'strategy':
            print(f"[INFO] Using default RandomSignalStrategy")
            from ginkgo.trading.strategies.random_signal_strategy import RandomSignalStrategy
            return RandomSignalStrategy()

        elif component_type == 'selector':
            print(f"[INFO] Using default CNAllSelector")
            from ginkgo.trading.selectors.cn_all_selector import CNAllSelector
            return CNAllSelector()

        elif component_type == 'sizer':
            print(f"[INFO] Using default FixedSizer")
            from ginkgo.trading.sizers.fixed_sizer import FixedSizer
            return FixedSizer()

        elif component_type == 'risk_management':
            print(f"[INFO] Using default PositionRatioRisk")
            from ginkgo.trading.risk_management.position_ratio_risk import PositionRatioRisk
            return PositionRatioRisk()

        else:
            print(f"[WARNING] Unknown component type: {component_type}")
            return None

    def _get_subscribed_codes(self, portfolio: "PortfolioLive") -> List[str]:
        """
        è·å–Portfolioè®¢é˜…çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨

        Args:
            portfolio: PortfolioLiveå®ä¾‹

        Returns:
            List[str]: è®¢é˜…çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨

        MVPé˜¶æ®µï¼šè¿”å›ç©ºåˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤è®¢é˜…
        Phase 4ï¼šä»Portfolioçš„strategyä¸­è·å–è®¢é˜…åˆ—è¡¨
        """
        # MVPé˜¶æ®µï¼šè¿”å›ç©ºï¼Œè®©load_portfolioä½¿ç”¨é»˜è®¤è®¢é˜…
        # Phase 4ï¼šå¯ä»¥ä»portfolio.strategy.get_subscribed_codes()è·å–
        # æˆ–è€…ä»æ•°æ®åº“é…ç½®ä¸­è¯»å–
        return []

    def unload_portfolio(self, portfolio_id: str) -> bool:
        """
        å¸è½½Portfolioå®ä¾‹ï¼ˆä¼˜é›…åœæ­¢ï¼‰

        Args:
            portfolio_id: Portfolio ID

        Returns:
            bool: å¸è½½æˆåŠŸè¿”å›True
        """
        with self.portfolio_lock:
            if portfolio_id not in self.portfolios:
                print(f"[WARNING] Portfolio {portfolio_id} not found")
                return False

            # ä¼˜é›…åœæ­¢PortfolioProcessorï¼ˆç­‰å¾…é˜Ÿåˆ—æ¸…ç©ºï¼‰
            processor = self.portfolios[portfolio_id]
            print(f"[INFO] Unloading Portfolio {portfolio_id}...")
            processor.graceful_stop(timeout=30.0)

        # åœ¨é”å¤–ç­‰å¾… PortfolioProcessor çº¿ç¨‹é€€å‡º
        processor.join(timeout=10)
        if processor.is_alive():
            print(f"[WARNING] Processor {portfolio_id} did not stop gracefully")
        else:
            print(f"[INFO] Processor {portfolio_id} stopped")

        # åœ¨é”å¤–åœæ­¢ output_queue listener çº¿ç¨‹
        if portfolio_id in self.output_queue_stop_events:
            print(f"[INFO] Stopping output queue listener for {portfolio_id}...")
            self.output_queue_stop_events[portfolio_id].set()

        if portfolio_id in self.output_queue_threads:
            thread = self.output_queue_threads[portfolio_id]
            thread.join(timeout=10)
            if thread.is_alive():
                print(f"[WARNING] Output queue listener for {portfolio_id} did not stop gracefully")
            else:
                print(f"[INFO] Output queue listener for {portfolio_id} stopped")

            del self.output_queue_threads[portfolio_id]
            del self.output_queue_stop_events[portfolio_id]

        # å†æ¬¡è·å–é”ï¼Œä»ExecutionNodeç§»é™¤
        with self.portfolio_lock:
            del self.portfolios[portfolio_id]
            del self._portfolio_instances[portfolio_id]

            # æ¸…ç†é˜Ÿåˆ—ï¼ˆExecutionNodeæŒæœ‰æ‰€æœ‰é˜Ÿåˆ—ï¼‰
            if portfolio_id in self.input_queues:
                del self.input_queues[portfolio_id]
            if portfolio_id in self.output_queues:
                del self.output_queues[portfolio_id]

            print(f"[INFO] Portfolio {portfolio_id} unloaded successfully")

            # ä»InterestMapç§»é™¤è®¢é˜…ï¼ˆPhase 4å®ç°ï¼‰
            subscribed_codes = self.interest_map.get_all_subscriptions(portfolio_id)
            if subscribed_codes:
                self.interest_map.remove_portfolio(portfolio_id, subscribed_codes)
                print(f"[INFO] Removed {len(subscribed_codes)} subscriptions from InterestMap")

            return True

    def _start_market_data_consumer_thread(self):
        """
        å¯åŠ¨å¸‚åœºæ•°æ®æ¶ˆè´¹çº¿ç¨‹

        åˆ›å»º Kafka Consumer å¹¶å¯åŠ¨æ¶ˆè´¹çº¿ç¨‹ï¼Œæ¥æ”¶ EventPriceUpdate äº‹ä»¶
        """
        if self.market_data_thread and self.market_data_thread.is_alive():
            logger.warning(f"Market data consumer thread already running for node {self.node_id}")
            return

        # åˆ›å»ºKafkaæ¶ˆè´¹è€…
        self.market_data_consumer = GinkgoConsumer(
            KafkaTopics.MARKET_DATA,
            group_id=f"execution_node_{self.node_id}"
        )

        # å¯åŠ¨æ¶ˆè´¹çº¿ç¨‹
        self.market_data_thread = Thread(
            target=self._consume_market_data,
            daemon=True,
            name=f"market_data_{self.node_id}"
        )
        self.market_data_thread.start()
        logger.info(f"Market data consumer thread started for node {self.node_id}")

    def _start_order_feedback_consumer_thread(self):
        """
        å¯åŠ¨è®¢å•å›æŠ¥æ¶ˆè´¹çº¿ç¨‹

        åˆ›å»º Kafka Consumer å¹¶å¯åŠ¨æ¶ˆè´¹çº¿ç¨‹ï¼Œæ¥æ”¶ EventOrderPartiallyFilled äº‹ä»¶
        """
        if self.order_feedback_thread and self.order_feedback_thread.is_alive():
            logger.warning(f"Order feedback consumer thread already running for node {self.node_id}")
            return

        # åˆ›å»ºKafkaæ¶ˆè´¹è€…
        self.order_feedback_consumer = GinkgoConsumer(
            KafkaTopics.ORDERS_FEEDBACK,
            group_id=f"execution_node_{self.node_id}"
        )

        # å¯åŠ¨æ¶ˆè´¹çº¿ç¨‹
        self.order_feedback_thread = Thread(
            target=self._consume_order_feedback,
            daemon=True,
            name=f"order_feedback_{self.node_id}"
        )
        self.order_feedback_thread.start()
        logger.info(f"Order feedback consumer thread started for node {self.node_id}")

    def _consume_market_data(self):
        """
        æ¶ˆè´¹å¸‚åœºæ•°æ®çº¿ç¨‹ï¼ˆå•çº¿ç¨‹å¿«é€Ÿæ¶ˆè´¹å’Œè·¯ç”±ï¼‰

        çº¿ç¨‹èŒè´£ï¼š
        1. ä»Kafkaå¿«é€Ÿæ¶ˆè´¹EventPriceUpdateæ¶ˆæ¯
        2. æŸ¥è¯¢InterestMapè·å–è®¢é˜…è¯¥è‚¡ç¥¨çš„Portfolioåˆ—è¡¨
        3. éé˜»å¡åˆ†å‘æ¶ˆæ¯åˆ°å„PortfolioProcessorçš„Queue
        4. æ¶ˆæ¯æˆåŠŸæ”¾å…¥é˜Ÿåˆ—åç«‹å³æäº¤ offset
        """
        from ginkgo.trading.events.price_update import EventPriceUpdate

        print(f"Market data consumer thread started for node {self.node_id}")

        while self.is_running:
            try:
                # æš‚åœçŠ¶æ€ï¼šä¸å¤„ç†æ–°çš„äº‹ä»¶
                if self.is_paused:
                    time.sleep(0.1)  # çŸ­æš‚ä¼‘çœ é¿å…CPUç©ºè½¬
                    continue

                for message in self.market_data_consumer.consumer:
                    if not self.is_running:
                        break

                    # æš‚åœçŠ¶æ€æ£€æŸ¥
                    if self.is_paused:
                        break

                    event_data = message.value

                    # è§£æEventPriceUpdate
                    event = EventPriceUpdate(
                        code=event_data['code'],
                        timestamp=datetime.fromisoformat(event_data['timestamp']),
                        price=event_data['price'],
                        volume=event_data.get('volume', 0)
                    )

                    # è·¯ç”±åˆ°å¯¹åº”çš„Portfolio
                    self._route_event_to_portfolios(event)

                    # æ¶ˆæ¯æˆåŠŸæ”¾å…¥é˜Ÿåˆ—åç«‹å³æäº¤ offset
                    # æ­¤æ—¶æ¶ˆæ¯å·²ç»åœ¨ ExecutionNode çš„å†…å­˜ä¸­ï¼Œä¸ä¼šä¸¢å¤±ï¼ˆé™¤éè¿›ç¨‹å´©æºƒï¼‰
                    self.market_data_consumer.commit()

            except Exception as e:
                if self.is_running:
                    print(f"[ERROR] Error consuming market data: {e}")

        print(f"Market data consumer thread stopped for node {self.node_id}")

    def _consume_order_feedback(self):
        """æ¶ˆè´¹è®¢å•å›æŠ¥çº¿ç¨‹ - æ¶ˆæ¯æˆåŠŸæ”¾å…¥é˜Ÿåˆ—åç«‹å³æäº¤ offset"""
        from ginkgo.trading.events.order_lifecycle_events import EventOrderPartiallyFilled

        print(f"Order feedback consumer thread started for node {self.node_id}")

        while self.is_running:
            try:
                # æš‚åœçŠ¶æ€ï¼šä¸å¤„ç†è®¢å•å›æŠ¥
                if self.is_paused:
                    time.sleep(0.1)  # çŸ­æš‚ä¼‘çœ é¿å…CPUç©ºè½¬
                    continue

                for message in self.order_feedback_consumer.consumer:
                    if not self.is_running:
                        break

                    # æš‚åœçŠ¶æ€æ£€æŸ¥
                    if self.is_paused:
                        break

                    event_data = message.value

                    # è§£æEventOrderPartiallyFilled
                    event = EventOrderPartiallyFilled(
                        order_id=event_data['order_id'],
                        code=event_data['code'],
                        timestamp=datetime.fromisoformat(event_data['timestamp']),
                        direction=event_data['direction'],
                        filled_volume=event_data['filled_volume'],
                        filled_price=event_data['filled_price']
                    )

                    # è·¯ç”±åˆ°å¯¹åº”çš„Portfolio
                    portfolio_id = event_data.get('portfolio_id')
                    if portfolio_id and portfolio_id in self.portfolios:
                        self.input_queues[portfolio_id].put(event)

                    # æ¶ˆæ¯æˆåŠŸæ”¾å…¥é˜Ÿåˆ—åç«‹å³æäº¤ offset
                    # æ­¤æ—¶æ¶ˆæ¯å·²ç»åœ¨ ExecutionNode çš„å†…å­˜ä¸­ï¼Œä¸ä¼šä¸¢å¤±ï¼ˆé™¤éè¿›ç¨‹å´©æºƒï¼‰
                    self.order_feedback_consumer.commit()

            except Exception as e:
                if self.is_running:
                    print(f"[ERROR] Error consuming order feedback: {e}")

        print(f"Order feedback consumer thread stopped for node {self.node_id}")

    def _route_event_to_portfolios(self, event):
        """
        è·¯ç”±äº‹ä»¶åˆ°å¯¹åº”çš„Portfolioï¼ˆä½¿ç”¨InterestMapä¼˜åŒ–ï¼‰

        è·¯ç”±ç­–ç•¥ï¼š
        1. æ£€æŸ¥æš‚åœçŠ¶æ€ï¼ˆPAUSEDæ—¶ä¸å¤„ç†äº‹ä»¶ï¼‰
        2. ä½¿ç”¨InterestMapæŸ¥è¯¢è®¢é˜…è¯¥è‚¡ç¥¨çš„Portfolioåˆ—è¡¨ï¼ˆO(1)æŸ¥è¯¢ï¼‰
        3. ä½¿ç”¨çŸ­æš‚è¶…æ—¶ï¼ˆ100msï¼‰å°è¯•æ”¾å…¥é˜Ÿåˆ—
        4. è¶…æ—¶åè®°å½•èƒŒå‹ç»Ÿè®¡ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªPortfolio
        5. ä¸¢å¼ƒæ—¶è®°å½•è¯¦ç»†æ—¥å¿—å’Œé˜Ÿåˆ—ä½¿ç”¨ç‡

        æ€§èƒ½ä¼˜åŠ¿ï¼š
        - Phase 3ï¼ˆæ— InterestMapï¼‰ï¼šO(n) éå†æ‰€æœ‰Portfolio
        - Phase 4ï¼ˆæœ‰InterestMapï¼‰ï¼šO(1) ç›´æ¥æŸ¥è¯¢è®¢é˜…è€…

        Args:
            event: EventPriceUpdateäº‹ä»¶
        """
        import queue

        # æš‚åœçŠ¶æ€ï¼šä¸å¤„ç†äº‹ä»¶
        if self.is_paused:
            logger.debug(f"ExecutionNode {self.node_id} is paused, skipping event routing for {event.code}")
            return

        self.total_event_count += 1

        # Phase 4ï¼šä½¿ç”¨InterestMapä¼˜åŒ–è·¯ç”±ï¼ˆO(1)æŸ¥è¯¢ï¼‰
        # è·å–è®¢é˜…è¯¥è‚¡ç¥¨çš„Portfolioåˆ—è¡¨
        portfolio_ids = self.interest_map.get_portfolios(event.code)

        # å¦‚æœInterestMapä¸­æ²¡æœ‰è®°å½•ï¼Œå›é€€åˆ°éå†æ‰€æœ‰Portfolioï¼ˆå…¼å®¹æ€§ï¼‰
        if not portfolio_ids:
            # MVPé˜¶æ®µå…¼å®¹ï¼šéå†æ‰€æœ‰Portfolio
            with self.portfolio_lock:
                portfolio_ids = list(self.portfolios.keys())

        # è·¯ç”±äº‹ä»¶åˆ°è®¢é˜…çš„Portfolio
        for portfolio_id in portfolio_ids:
            # è·å–processorï¼ˆéœ€è¦çº¿ç¨‹å®‰å…¨ï¼‰
            with self.portfolio_lock:
                if portfolio_id not in self.portfolios:
                    # Portfolioå¯èƒ½å·²å¸è½½ï¼Œè·³è¿‡
                    continue
                processor = self.portfolios[portfolio_id]

            try:
                # ä½¿ç”¨çŸ­æš‚è¶…æ—¶ï¼ˆ100msï¼‰å°è¯•æ”¾å…¥é˜Ÿåˆ—
                # ä¼˜åŠ¿ï¼šç»™é˜Ÿåˆ—å¤„ç†æ—¶é—´ï¼Œå‡å°‘äº‹ä»¶ä¸¢å¤±
                self.input_queues[portfolio_id].put(event, block=True, timeout=0.1)

            except queue.Full:
                # é˜Ÿåˆ—æ»¡ï¼Œè®°å½•èƒŒå‹
                self.backpressure_count += 1
                self.dropped_event_count += 1

                # è·å–é˜Ÿåˆ—ä½¿ç”¨ç‡
                try:
                    queue_size = self.input_queues[portfolio_id].qsize()
                    # max_queue_sizeåœ¨åˆ›å»ºé˜Ÿåˆ—æ—¶å®šä¹‰ï¼ˆ1000ï¼‰
                    queue_usage = queue_size / 1000 if 1000 > 0 else 0
                except:
                    queue_size = -1
                    queue_usage = -1

                # è®°å½•è¯¦ç»†èƒŒå‹æ—¥å¿—
                print(f"[BACKPRESSURE] Portfolio {portfolio_id} queue full")
                print(f"  - Event: {event.code} at {event.timestamp if hasattr(event, 'timestamp') else 'N/A'}")
                print(f"  - Queue: {queue_size}/1000 ({queue_usage*100:.1f}%)")
                print(f"  - Total backpressure: {self.backpressure_count}, dropped: {self.dropped_event_count}")

                # TODO: Phase 4 - å‘é€èƒŒå‹å‘Šè­¦åˆ°ç›‘æ§ç³»ç»Ÿ
                # self._send_backpressure_alert(portfolio_id, queue_usage, event)

            except Exception as e:
                # å…¶ä»–å¼‚å¸¸ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰
                print(f"[ERROR] Failed to route event to {portfolio_id}: {type(e).__name__}: {e}")
                continue

    def _start_output_queue_listener(self, queue: Queue, portfolio_id: str):
        """
        å¯åŠ¨output_queueç›‘å¬å™¨ï¼ˆåŒé˜Ÿåˆ—æ¨¡å¼ï¼‰

        ç›‘å¬PortfolioProcessorçš„output_queueï¼Œå¤„ç†è®¢å•ç­‰é¢†åŸŸäº‹ä»¶ï¼š
        - æ¥æ”¶Portfolioå‘å¸ƒçš„äº‹ä»¶ï¼ˆOrderç­‰ï¼‰
        - åºåˆ—åŒ–è®¢å•ä¸ºDTO
        - å‘é€åˆ°Kafka orders.submission topic

        Args:
            queue: PortfolioProcessorçš„output_queue
            portfolio_id: Portfolio ID
        """
        import threading

        # åˆ›å»ºåœæ­¢äº‹ä»¶ï¼ˆç”¨äºä¼˜é›…é€€å‡ºï¼‰
        stop_event = threading.Event()
        self.output_queue_stop_events[portfolio_id] = stop_event

        def listener_thread():
            print(f"Output queue listener started for portfolio {portfolio_id}")

            while not stop_event.is_set():  # æ£€æŸ¥åœæ­¢äº‹ä»¶
                try:
                    # ä»é˜Ÿåˆ—å–é¢†åŸŸäº‹ä»¶
                    event = queue.get(timeout=0.1)

                    # å¤„ç†è®¢å•äº‹ä»¶
                    from ginkgo.trading.entities import Order
                    if isinstance(event, Order):
                        # æš‚åœçŠ¶æ€ï¼šä¸æäº¤æ–°è®¢å•
                        if self.is_paused:
                            logger.warning(f"ExecutionNode {self.node_id} is paused, order {event.uuid} not submitted")
                            queue.task_done()
                            continue

                        # ORDER PERSISTENCE: å†™å…¥æ–°è®¢å•åˆ°æ•°æ®åº“ (status=NEW) - order_crud.insert(event)
                        # from ginkgo.data.crud import OrderCRUD; from ginkgo.enums import ORDERSTATUS_TYPES
                        # order_crud = OrderCRUD(); event.status = ORDERSTATUS_TYPES.NEW; order_crud.insert(event)

                        # åºåˆ—åŒ–è®¢å•ä¸ºDTOå¹¶å‘é€åˆ°Kafka
                        order_data = {
                            "order_id": str(event.uuid),
                            "portfolio_id": event.portfolio_id,
                            "code": event.code,
                            "direction": event.direction.value,
                            "volume": event.volume,
                            "price": str(event.price) if event.price else None,
                            "timestamp": event.timestamp.isoformat() if event.timestamp else None
                        }

                        # å‘é€åˆ°Kafka
                        success = self.order_producer.send(KafkaTopics.ORDERS_SUBMISSION, order_data)
                        if success:
                            print(f"Order {event.uuid} sent to Kafka via output_queue")
                        else:
                            print(f"[ERROR] Failed to send order {event.uuid} to Kafka")
                    else:
                        # å…¶ä»–äº‹ä»¶ç±»å‹ï¼ˆå¦‚Signalï¼‰ï¼Œæš‚æ—¶è®°å½•æ—¥å¿—
                        print(f"[DEBUG] Output queue event received for {portfolio_id}: {type(event).__name__}")

                    queue.task_done()

                except Exception as e:
                    # å¯¼å…¥queue.Emptyç”¨äºç±»å‹æ£€æŸ¥
                    from queue import Empty

                    # å¿½ç•¥é˜Ÿåˆ—è¶…æ—¶å¼‚å¸¸ï¼ˆæ­£å¸¸çš„ç©ºé˜Ÿåˆ—è¶…æ—¶ï¼‰
                    if isinstance(e, Empty):
                        continue

                    # å…¶ä»–å¼‚å¸¸ï¼šæ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆ
                    import traceback
                    print(f"\n{'='*80}")
                    print(f"[ERROR] Error processing output_queue for {portfolio_id}")
                    print(f"{'='*80}")
                    print(f"Exception Type: {type(e).__name__}")
                    print(f"Exception Message: {str(e)}")
                    if 'event' in locals():
                        print(f"Event Type: {type(event).__name__}")
                        print(f"Event Object: {event}")
                    print(f"\nFull Traceback:")
                    traceback.print_exc()
                    print(f"{'='*80}\n")

                    # ä»ç„¶æ ‡è®°task_doneï¼Œé¿å…é˜»å¡é˜Ÿåˆ—
                    try:
                        queue.task_done()
                    except:
                        pass

            print(f"Output queue listener stopped for portfolio {portfolio_id}")

        thread = threading.Thread(
            target=listener_thread,
            daemon=True,  # å®ˆæŠ¤çº¿ç¨‹ï¼Œä¸»è¿›ç¨‹é€€å‡ºæ—¶è‡ªåŠ¨ç»ˆæ­¢
            name=f"output_queue_{portfolio_id}"
        )
        thread.start()

        # è¿½è¸ªçº¿ç¨‹
        self.output_queue_threads[portfolio_id] = thread
        print(f"[DEBUG] Output queue listener thread started for portfolio {portfolio_id}")



    # ========================================================================
    # å¿ƒè·³æœºåˆ¶ï¼ˆPhase 5å®ç°ï¼‰
    # ========================================================================

    def _start_heartbeat_thread(self):
        """å¯åŠ¨å¿ƒè·³ä¸ŠæŠ¥çº¿ç¨‹"""
        if self.heartbeat_thread and self.heartbeat_thread.is_alive():
            logger.warning(f"Heartbeat thread already running for node {self.node_id}")
            return

        self.heartbeat_thread = Thread(
            target=self._heartbeat_loop,
            daemon=True,
            name=f"heartbeat_{self.node_id}"
        )
        self.heartbeat_thread.start()
        logger.info(f"Heartbeat thread started for node {self.node_id}")

    def _heartbeat_loop(self):
        """
        å¿ƒè·³ä¸ŠæŠ¥å¾ªç¯ï¼ˆæ¯10ç§’å‘é€ä¸€æ¬¡ï¼‰

        å¿ƒè·³æ•°æ®åŒ…å«ï¼š
        - å¿ƒè·³æ—¶é—´æˆ³
        - Portfolio æ•°é‡
        - é˜Ÿåˆ—ä½¿ç”¨æƒ…å†µ
        - æ€§èƒ½æŒ‡æ ‡
        """
        while self.is_running:
            try:
                # å‘é€å¿ƒè·³åˆ° Redis
                self._send_heartbeat()

                # æ›´æ–°æ€§èƒ½æŒ‡æ ‡åˆ° Redis
                self._update_node_metrics()

                # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€åˆ° Redis (T068)
                self._update_node_state()

                # æ›´æ–°æ‰€æœ‰PortfolioçŠ¶æ€åˆ° Redis (T067)
                self._update_all_portfolios_state()

                # ç­‰å¾…ä¸‹ä¸€æ¬¡å¿ƒè·³
                for _ in range(self.heartbeat_interval):
                    if not self.is_running:
                        break
                    time.sleep(1)

            except Exception as e:
                logger.error(f"Error in heartbeat loop for node {self.node_id}: {e}")
                time.sleep(5)  # å‡ºé”™åç­‰å¾…5ç§’å†é‡è¯•

        logger.info(f"Heartbeat loop stopped for node {self.node_id}")

    def _is_node_id_in_use(self) -> bool:
        """
        æ£€æŸ¥node_idæ˜¯å¦å·²è¢«å…¶ä»–å®ä¾‹ä½¿ç”¨

        é€šè¿‡æ£€æŸ¥Redisä¸­çš„å¿ƒè·³é”®å’ŒTTLæ¥åˆ¤æ–­ï¼š
        - å¿ƒè·³é”®ä¸å­˜åœ¨ â†’ å¯ç”¨
        - å¿ƒè·³é”®å­˜åœ¨ä½†TTL < 10ç§’ â†’ æ®‹ç•™æ•°æ®ï¼Œå¯ç”¨
        - å¿ƒè·³é”®å­˜åœ¨ä¸”TTL >= 10ç§’ â†’ è¢«å…¶ä»–å®ä¾‹ä½¿ç”¨ï¼Œä¸å¯ç”¨

        Returns:
            bool: Trueè¡¨ç¤ºnode_idå·²è¢«ä½¿ç”¨ï¼ŒFalseè¡¨ç¤ºå¯ç”¨
        """
        try:
            redis_client = self._get_redis_client()
            if not redis_client:
                logger.warning("Failed to get Redis client for node_id check")
                return False  # æ— æ³•æ£€æŸ¥ï¼Œä¿å®ˆç­–ç•¥ï¼šå…è®¸å¯åŠ¨

            heartbeat_key = f"heartbeat:node:{self.node_id}"
            heartbeat_exists = redis_client.exists(heartbeat_key)

            if not heartbeat_exists:
                # å¿ƒè·³ä¸å­˜åœ¨ï¼Œnode_idå¯ç”¨
                return False

            # å¿ƒè·³å­˜åœ¨ï¼Œæ£€æŸ¥TTL
            ttl = redis_client.ttl(heartbeat_key)

            if ttl < 0:
                # æ°¸ä¸è¿‡æœŸçš„é”®ï¼ˆå¼‚å¸¸æƒ…å†µï¼‰ï¼Œè®¤ä¸ºè¢«å ç”¨
                logger.warning(f"Heartbeat for {self.node_id} has no expiration")
                return True
            elif ttl < 10:
                # TTL < 10ç§’ï¼Œå¾ˆå¯èƒ½æ˜¯æ®‹ç•™æ•°æ®ï¼Œå…è®¸å¯åŠ¨
                logger.info(f"Heartbeat TTL ({ttl}s) is short, treating as stale data")
                return False
            else:
                # TTL >= 10ç§’ï¼Œæœ‰å…¶ä»–å®ä¾‹åœ¨è¿è¡Œ
                logger.warning(f"Heartbeat for {self.node_id} exists with TTL {ttl}s (in use)")
                return True

        except Exception as e:
            logger.error(f"Failed to check if node_id is in use: {e}")
            return False  # æ£€æŸ¥å¤±è´¥ï¼Œä¿å®ˆç­–ç•¥ï¼šå…è®¸å¯åŠ¨

    def _cleanup_old_heartbeat_data(self):
        """
        æ¸…ç†æ—§çš„å¿ƒè·³å’ŒæŒ‡æ ‡æ•°æ®

        åœ¨èŠ‚ç‚¹å¯åŠ¨æ—¶è°ƒç”¨ï¼Œç¡®ä¿æ²¡æœ‰æ®‹ç•™çš„è¿‡æœŸæ•°æ®ï¼š
        - åˆ é™¤æ—§çš„ heartbeat:node:{node_id}
        - åˆ é™¤æ—§çš„ node:metrics:{node_id}

        äº‘åŸç”Ÿè®¾è®¡ï¼šèŠ‚ç‚¹é‡å¯åå®Œå…¨æ¸…ç©ºæ—§çŠ¶æ€
        """
        try:
            # è·å– Redis å®¢æˆ·ç«¯
            redis_client = self._get_redis_client()
            if not redis_client:
                logger.error("Failed to get Redis client for cleanup")
                return

            # æ„é€ é”®å
            heartbeat_key = f"heartbeat:node:{self.node_id}"
            metrics_key = f"node:metrics:{self.node_id}"

            # åˆ é™¤æ—§çš„å¿ƒè·³æ•°æ®
            deleted_heartbeat = redis_client.delete(heartbeat_key)
            if deleted_heartbeat:
                logger.info(f"Cleaned up old heartbeat data for node {self.node_id}")

            # åˆ é™¤æ—§çš„æŒ‡æ ‡æ•°æ®
            deleted_metrics = redis_client.delete(metrics_key)
            if deleted_metrics:
                logger.info(f"Cleaned up old metrics data for node {self.node_id}")

            logger.debug(f"Cleanup completed for node {self.node_id}")

        except Exception as e:
            logger.error(f"Failed to cleanup old data for node {self.node_id}: {e}")

    def _check_initial_assignments(self):
        """
        [DEPRECATED] å¯åŠ¨æ—¶æ£€æŸ¥Redisä¸­çš„è°ƒåº¦è®¡åˆ’ï¼ŒåŠ è½½åˆ†é…ç»™æœ¬èŠ‚ç‚¹çš„Portfolio

        âš ï¸ æ­¤æ–¹æ³•å·²åºŸå¼ƒï¼
        ä¸ºäº†ä¿æŒå•å‘æ§åˆ¶æµï¼ŒExecutionNode ä¸å†ä¸»åŠ¨æŸ¥è¯¢ Redisã€‚
        æ‰€æœ‰ Portfolio åˆ†é…å¿…é¡»é€šè¿‡ Scheduler çš„ Kafka å‘½ä»¤ï¼ˆportfolio.migrateï¼‰ã€‚

        æ–°æ¶æ„ï¼š
        - Scheduler â†’ Kafka schedule.updates â†’ ExecutionNode
        - ExecutionNode å¯åŠ¨æ—¶å‘é€å¿ƒè·³ï¼Œç­‰å¾… Scheduler å‘é€è¿ç§»å‘½ä»¤
        - å®Œå…¨çš„ä¸­å¿ƒè°ƒåº¦ï¼ŒExecutionNode åªè¢«åŠ¨æ¥æ”¶å‘½ä»¤

        æ­¤æ–¹æ³•ä¿ç•™ä»…ä¸ºå‘åå…¼å®¹ï¼Œä¸åº”å†è¢«è°ƒç”¨ã€‚
        """
        # åºŸå¼ƒè­¦å‘Š
        logger.warning("[DEPRECATED] _check_initial_assignments() is deprecated and should not be called.")
        logger.warning("[DEPRECATED] Portfolio assignments must come through Kafka portfolio.migrate commands from Scheduler.")

        try:
            logger.info(f"[INIT] Checking initial portfolio assignments from Redis...")

            # è·å–Rediså®¢æˆ·ç«¯
            redis_client = self._get_redis_client()
            if not redis_client:
                logger.error("[INIT] Failed to get Redis client")
                return

            # ä»Redisè¯»å–è°ƒåº¦è®¡åˆ’
            schedule_plan_key = "schedule:plan"
            schedule_plan = redis_client.hgetall(schedule_plan_key)

            if not schedule_plan:
                logger.info("[INIT] No portfolios in schedule plan yet")
                return

            # è§£æè°ƒåº¦è®¡åˆ’ï¼ˆbytesè½¬strï¼‰
            plan_dict = {
                k.decode('utf-8'): v.decode('utf-8')
                for k, v in schedule_plan.items()
            }

            logger.info(f"[INIT] Schedule plan contains {len(plan_dict)} portfolios total")

            # æ‰¾å‡ºåˆ†é…ç»™æœ¬nodeçš„portfolio
            my_portfolios = [
                portfolio_id
                for portfolio_id, node_id in plan_dict.items()
                if node_id == self.node_id
            ]

            if not my_portfolios:
                logger.info(f"[INIT] No portfolios assigned to node {self.node_id} yet")
                return

            logger.info(f"[INIT] Found {len(my_portfolios)} portfolios assigned to this node:")
            for pid in my_portfolios:
                logger.info(f"[INIT]   - {pid[:8]}")

            # åŠ è½½æ¯ä¸ªportfolio
            for portfolio_id in my_portfolios:
                try:
                    logger.info(f"[INIT] Loading portfolio {portfolio_id[:8]}...")
                    success = self.load_portfolio(portfolio_id)
                    if success:
                        logger.info(f"[INIT] âœ“ Portfolio {portfolio_id[:8]} loaded successfully")
                    else:
                        logger.error(f"[INIT] âœ— Failed to load portfolio {portfolio_id[:8]}")
                except Exception as e:
                    logger.error(f"[INIT] âœ— Error loading portfolio {portfolio_id[:8]}: {e}")

            logger.info(f"[INIT] Initial assignment check completed. Total loaded: {len(self.portfolios)}")

        except Exception as e:
            logger.error(f"[INIT] Failed to check initial assignments: {e}")

    def _send_heartbeat(self):
        """
        å‘é€å¿ƒè·³åˆ° Redis

        Redis Key: heartbeat:node:{node_id}
        Value: å½“å‰æ—¶é—´æˆ³
        TTL: 30ç§’ï¼ˆè¶…è¿‡30ç§’æ— å¿ƒè·³è®¤ä¸ºèŠ‚ç‚¹ç¦»çº¿ï¼‰
        """
        try:
            # è·å– Redis å®¢æˆ·ç«¯
            redis_client = self._get_redis_client()
            if not redis_client:
                logger.error("Failed to get Redis client for heartbeat")
                return

            # æ„é€ å¿ƒè·³é”®
            heartbeat_key = f"heartbeat:node:{self.node_id}"

            # è®¾ç½®å¿ƒè·³å€¼ï¼ˆå½“å‰æ—¶é—´æˆ³ï¼‰
            heartbeat_value = datetime.now().isoformat()

            # è®¾ç½®é”®å¹¶é™„å¸¦TTL
            redis_client.setex(
                heartbeat_key,
                self.heartbeat_ttl,
                heartbeat_value
            )

            logger.debug(f"Heartbeat sent for node {self.node_id}")

        except Exception as e:
            logger.error(f"Failed to send heartbeat for node {self.node_id}: {e}")

    def _update_node_metrics(self):
        """
        æ›´æ–°èŠ‚ç‚¹æ€§èƒ½æŒ‡æ ‡åˆ° Redis

        Redis Key: node:metrics:{node_id} (Hash)
        Fields:
        - portfolio_count: Portfolio æ•°é‡
        - queue_size: å¹³å‡é˜Ÿåˆ—å¤§å°
        - status: èŠ‚ç‚¹çŠ¶æ€ (RUNNING/PAUSED/STOPPED)
        - cpu_usage: CPU ä½¿ç”¨ç‡ï¼ˆé¢„ç•™ï¼‰
        - memory_usage: å†…å­˜ä½¿ç”¨ï¼ˆé¢„ç•™ï¼‰
        """
        try:
            # è·å– Redis å®¢æˆ·ç«¯
            redis_client = self._get_redis_client()
            if not redis_client:
                return

            # ç¡®å®šèŠ‚ç‚¹çŠ¶æ€
            if not self.is_running:
                status = "STOPPED"
            elif self.is_paused:
                status = "PAUSED"
            else:
                status = "RUNNING"

            # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
            metrics = {
                "portfolio_count": str(len(self.portfolios)),
                "queue_size": str(self._get_average_queue_size()),
                "status": status,  # èŠ‚ç‚¹çŠ¶æ€
                "cpu_usage": "0.0",  # é¢„ç•™ï¼Œæœªæ¥å®ç°
                "memory_usage": "0",  # é¢„ç•™ï¼Œæœªæ¥å®ç°
                "total_events": str(self.total_event_count),
                "backpressure_count": str(self.backpressure_count),
                "dropped_events": str(self.dropped_event_count)
            }

            # æ›´æ–°åˆ° Redis
            metrics_key = f"node:metrics:{self.node_id}"
            redis_client.hset(metrics_key, mapping=metrics)

            logger.debug(f"Metrics updated for node {self.node_id}: {metrics}")

        except Exception as e:
            logger.error(f"Failed to update metrics for node {self.node_id}: {e}")

    def _get_average_queue_size(self) -> int:
        """
        è·å–æ‰€æœ‰ Portfolio çš„å¹³å‡é˜Ÿåˆ—å¤§å°

        Returns:
            int: å¹³å‡é˜Ÿåˆ—å¤§å°
        """
        try:
            if not self.portfolios:
                return 0

            total_size = 0
            # ä½¿ç”¨ExecutionNodeæŒæœ‰çš„é˜Ÿåˆ—å­—å…¸
            for portfolio_id, queue in self.input_queues.items():
                total_size += queue.qsize()

            return total_size // len(self.input_queues)

        except Exception as e:
            logger.error(f"Failed to get average queue size: {e}")
            return 0

    def _update_portfolio_state(self, portfolio_id: str):
        """
        æ›´æ–°PortfolioçŠ¶æ€åˆ°Redis (T067)

        Redis Key: portfolio:{portfolio_id}:state (Hash)
        Fields:
        - status: Portfolioè¿è¡ŒçŠ¶æ€ (RUNNING/PAUSED/STOPPED/RELOADING/MIGRATING)
        - queue_size: è¾“å…¥é˜Ÿåˆ—å¤§å°
        - buffer_size: ç¼“å­˜æ¶ˆæ¯å¤§å°
        - position_count: æŒä»“æ•°é‡
        - node_id: æ‰€åœ¨èŠ‚ç‚¹ID

        Args:
            portfolio_id: Portfolio ID
        """
        try:
            redis_client = self._get_redis_client()
            if not redis_client:
                return

            # è·å–Portfolioå®ä¾‹
            portfolio = self._portfolio_instances.get(portfolio_id)
            if not portfolio:
                logger.warning(f"Portfolio {portfolio_id} not found for state update")
                return

            # è·å–é˜Ÿåˆ—å¤§å°
            queue_size = 0
            if portfolio_id in self.input_queues:
                queue_size = self.input_queues[portfolio_id].qsize()

            # è·å–ç¼“å­˜å¤§å°ï¼ˆå¦‚æœæœ‰bufferæœºåˆ¶ï¼‰
            buffer_size = 0
            # TODO: ä»PortfolioProcessorè·å–bufferå¤§å°

            # è·å–æŒä»“æ•°é‡
            position_count = 0
            if hasattr(portfolio, 'positions'):
                position_count = len(portfolio.positions)

            # è·å–PortfolioçŠ¶æ€
            status = "UNKNOWN"
            if hasattr(portfolio, 'get_status'):
                status_obj = portfolio.get_status()
                status = str(status_obj).split('.')[-1] if status_obj else "UNKNOWN"

            # æ„é€ çŠ¶æ€å­—å…¸
            state = {
                "status": status,
                "queue_size": str(queue_size),
                "buffer_size": str(buffer_size),
                "position_count": str(position_count),
                "node_id": self.node_id
            }

            # å†™å…¥Redis
            state_key = f"portfolio:{portfolio_id}:state"
            redis_client.hset(state_key, mapping=state)

            logger.debug(f"Portfolio state updated: {portfolio_id} -> {state}")

        except Exception as e:
            logger.error(f"Failed to update portfolio state {portfolio_id}: {e}")

    def _update_all_portfolios_state(self):
        """
        æ›´æ–°æ‰€æœ‰Portfolioçš„çŠ¶æ€åˆ°Redis (T067)

        åœ¨å¿ƒè·³å‘¨æœŸä¸­è°ƒç”¨ï¼Œæ‰¹é‡æ›´æ–°æ‰€æœ‰PortfolioçŠ¶æ€
        """
        try:
            for portfolio_id in list(self._portfolio_instances.keys()):
                self._update_portfolio_state(portfolio_id)

        except Exception as e:
            logger.error(f"Failed to update all portfolios state: {e}")

    def _update_node_state(self):
        """
        æ›´æ–°ExecutionNodeçŠ¶æ€åˆ°Redis (T068)

        Redis Key: execution_node:{node_id}:info (Hash)
        Fields:
        - status: èŠ‚ç‚¹çŠ¶æ€ (RUNNING/PAUSED/STOPPED)
        - portfolio_count: Portfolioæ•°é‡
        - max_portfolios: æœ€å¤§Portfolioæ•°é‡
        - queue_usage_70pct: é˜Ÿåˆ—ä½¿ç”¨ç‡æ˜¯å¦è¶…è¿‡70%
        - queue_usage_95pct: é˜Ÿåˆ—ä½¿ç”¨ç‡æ˜¯å¦è¶…è¿‡95%
        - uptime_seconds: è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰
        - started_at: å¯åŠ¨æ—¶é—´
        """
        try:
            redis_client = self._get_redis_client()
            if not redis_client:
                return

            # ç¡®å®šèŠ‚ç‚¹çŠ¶æ€
            if not self.is_running:
                status = "STOPPED"
            elif self.is_paused:
                status = "PAUSED"
            else:
                status = "RUNNING"

            # è®¡ç®—é˜Ÿåˆ—ä½¿ç”¨ç‡
            avg_queue_size = self._get_average_queue_size()
            queue_usage_70pct = avg_queue_size > 700  # å‡è®¾é˜Ÿåˆ—ä¸Šé™1000
            queue_usage_95pct = avg_queue_size > 950

            # è®¡ç®—è¿è¡Œæ—¶é•¿
            uptime_seconds = 0
            if self.started_at:
                try:
                    from datetime import datetime
                    started = datetime.fromisoformat(self.started_at)
                    uptime_seconds = int((datetime.now() - started).total_seconds())
                except Exception:
                    pass

            # æ„é€ çŠ¶æ€å­—å…¸
            state = {
                "status": status,
                "portfolio_count": str(len(self.portfolios)),
                "max_portfolios": str(self.max_portfolios),
                "queue_usage_70pct": str(queue_usage_70pct),
                "queue_usage_95pct": str(queue_usage_95pct),
                "uptime_seconds": str(uptime_seconds),
                "started_at": self.started_at or ""
            }

            # å†™å…¥Redis
            info_key = f"execution_node:{self.node_id}:info"
            redis_client.hset(info_key, mapping=state)

            logger.debug(f"Node state updated: {self.node_id} -> {state}")

        except Exception as e:
            logger.error(f"Failed to update node state {self.node_id}: {e}")

    # ========================================================================
    # èŠ‚ç‚¹æ§åˆ¶å‘½ä»¤ï¼ˆpause/resume/stopï¼‰
    # ========================================================================

    def pause(self):
        """
        æš‚åœ ExecutionNode

        æš‚åœåï¼š
        - å¿ƒè·³ç»§ç»­ä¸ŠæŠ¥ï¼ˆçŠ¶æ€=PAUSEDï¼‰
        - ä¸å¤„ç†æ–°çš„äº‹ä»¶ï¼ˆPriceUpdateã€OrderFeedbackï¼‰
        - ä¸æäº¤æ–°è®¢å•åˆ°Kafka
        - ä»å“åº”è°ƒåº¦å‘½ä»¤ï¼ˆpause/resume/reload/migrateï¼‰
        """
        if self.is_paused:
            logger.warning(f"ExecutionNode {self.node_id} is already paused")
            return

        logger.info(f"Pausing ExecutionNode {self.node_id}")
        self.is_paused = True
        logger.info(f"ExecutionNode {self.node_id} PAUSED")
        logger.info(f"  - Market data consumption: SUSPENDED")
        logger.info(f"  - Order feedback consumption: SUSPENDED")
        logger.info(f"  - Order submission: SUSPENDED")
        logger.info(f"  - Heartbeat: ACTIVE (status=PAUSED)")
        logger.info(f"  - Command handling: ACTIVE")

    def resume(self):
        """
        æ¢å¤ ExecutionNode

        æ¢å¤åï¼š
        - ç»§ç»­å¤„ç†äº‹ä»¶ï¼ˆPriceUpdateã€OrderFeedbackï¼‰
        - ç»§ç»­æäº¤è®¢å•åˆ°Kafka
        - å¿ƒè·³çŠ¶æ€æ¢å¤ä¸ºRUNNING
        """
        if not self.is_paused:
            logger.warning(f"ExecutionNode {self.node_id} is not paused")
            return

        logger.info(f"Resuming ExecutionNode {self.node_id}")
        self.is_paused = False
        logger.info(f"ExecutionNode {self.node_id} RESUMED")
        logger.info(f"  - Market data consumption: ACTIVE")
        logger.info(f"  - Order feedback consumption: ACTIVE")
        logger.info(f"  - Order submission: ACTIVE")
        logger.info(f"  - Heartbeat: ACTIVE (status=RUNNING)")

    def get_status(self) -> dict:
        """
        è·å–èŠ‚ç‚¹çŠ¶æ€

        Returns:
            dict: åŒ…å«èŠ‚ç‚¹çŠ¶æ€ä¿¡æ¯çš„å­—å…¸ï¼ŒåŒ…æ‹¬ï¼š
                - åŸºæœ¬çŠ¶æ€ï¼šnode_id, status, is_running, is_paused, should_stop
                - Portfolioä¿¡æ¯ï¼športfolio_count, portfoliosï¼ˆè¯¦ç»†çŠ¶æ€ï¼‰
                - èƒŒå‹ç»Ÿè®¡ï¼štotal_events, backpressure_count, dropped_events, backpressure_rate
        """
        # ç¡®å®šèŠ‚ç‚¹çŠ¶æ€
        if not self.is_running:
            status = "STOPPED"
        elif self.is_paused:
            status = "PAUSED"
        else:
            status = "RUNNING"

        # è®¡ç®—èƒŒå‹ç‡
        backpressure_rate = 0.0
        if self.total_event_count > 0:
            backpressure_rate = self.backpressure_count / self.total_event_count

        # è·å–æ‰€æœ‰Portfolioçš„è¯¦ç»†çŠ¶æ€
        with self.portfolio_lock:
            portfolio_statuses = {}
            for portfolio_id, processor in self.portfolios.items():
                portfolio_statuses[portfolio_id] = processor.get_status()

        return {
            # åŸºæœ¬çŠ¶æ€
            "node_id": self.node_id,
            "status": status,
            "is_running": self.is_running,
            "is_paused": self.is_paused,
            "should_stop": self.should_stop,
            "portfolio_count": len(self.portfolios),
            "started_at": self.started_at,

            # Portfolioè¯¦ç»†çŠ¶æ€
            "portfolios": portfolio_statuses,

            # èƒŒå‹ç»Ÿè®¡
            "backpressure": {
                "total_events": self.total_event_count,
                "backpressure_count": self.backpressure_count,
                "dropped_events": self.dropped_event_count,
                "backpressure_rate": backpressure_rate
            }
        }

    def _get_uptime(self) -> str:
        """
        è®¡ç®—èŠ‚ç‚¹è¿è¡Œæ—¶é•¿

        Returns:
            str: æ ¼å¼åŒ–çš„è¿è¡Œæ—¶é•¿ï¼ˆå¦‚ "2å°æ—¶30åˆ†é’Ÿ"ï¼‰
        """
        if not self.started_at:
            return "æœªçŸ¥"

        try:
            from datetime import datetime
            start_time = datetime.fromisoformat(self.started_at)
            uptime_seconds = (datetime.now() - start_time).total_seconds()

            hours = int(uptime_seconds // 3600)
            minutes = int((uptime_seconds % 3600) // 60)
            seconds = int(uptime_seconds % 60)

            if hours > 0:
                return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds}ç§’"
            elif minutes > 0:
                return f"{minutes}åˆ†é’Ÿ{seconds}ç§’"
            else:
                return f"{seconds}ç§’"
        except Exception:
            return "æœªçŸ¥"

    def _get_redis_client(self):
        """
        è·å– Redis å®¢æˆ·ç«¯

        Returns:
            Redis: Redis å®¢æˆ·ç«¯å®ä¾‹ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            from ginkgo.data.crud import RedisCRUD
            redis_crud = RedisCRUD()
            return redis_crud.redis
        except Exception as e:
            logger.error(f"Failed to get Redis client: {e}")
            return None


    # ========================================================================
    # è°ƒåº¦æ›´æ–°è®¢é˜…ï¼ˆPhase 5å®ç° - T046ï¼‰
    # ========================================================================

    def _start_schedule_updates_thread(self):
        """å¯åŠ¨è°ƒåº¦æ›´æ–°è®¢é˜…çº¿ç¨‹"""
        if self.schedule_updates_thread and self.schedule_updates_thread.is_alive():
            logger.warning(f"Schedule updates thread already running for node {self.node_id}")
            return

        self.schedule_updates_thread = Thread(
            target=self._schedule_updates_loop,
            daemon=True,
            name=f"schedule_updates_{self.node_id}"
        )
        self.schedule_updates_thread.start()
        logger.info(f"Schedule updates thread started for node {self.node_id}")

    def _schedule_updates_loop(self):
        """
        è°ƒåº¦æ›´æ–°æ¶ˆè´¹å¾ªç¯

        è®¢é˜… Kafka schedule.updates topicï¼Œå¤„ç†è°ƒåº¦å‘½ä»¤ï¼š
        - portfolio.reload: é‡æ–°åŠ è½½Portfolioé…ç½®
        - portfolio.migrate: è¿ç§»Portfolioåˆ°å…¶ä»–Node
        - node.shutdown: å…³é—­ExecutionNode
        """
        try:
            # åˆ›å»º Kafka æ¶ˆè´¹è€…ï¼ˆç›´æ¥è®¢é˜… topicï¼‰
            topic = KafkaTopics.SCHEDULE_UPDATES
            self.schedule_updates_consumer = GinkgoConsumer(
                topic=topic,
                group_id=f"execution_node_{self.node_id}",
                offset="latest"  # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹æ¶ˆè´¹
            )

            logger.info(f"Subscribed to {topic} topic for node {self.node_id}")
            print(f"[INFO] Subscribed to {topic} topic")

            while self.is_running:
                try:
                    # æ¶ˆè´¹æ¶ˆæ¯ï¼ˆè¶…æ—¶1ç§’ï¼‰
                    # GinkgoConsumer.consumer æ˜¯åº•å±‚çš„ KafkaConsumer
                    messages = self.schedule_updates_consumer.consumer.poll(timeout_ms=1000)

                    if not messages:
                        continue

                    # å¤„ç†æ¯ä¸ªæ¶ˆæ¯
                    for tp, records in messages.items():
                        for msg in records:
                            self._handle_schedule_update(msg)

                except Exception as e:
                    logger.error(f"Error consuming schedule updates: {e}")
                    time.sleep(1)  # å‡ºé”™åç­‰å¾…1ç§’å†é‡è¯•

        except Exception as e:
            logger.error(f"Failed to start schedule updates consumer: {e}")
        finally:
            logger.info(f"Schedule updates loop stopped for node {self.node_id}")

    def _handle_schedule_update(self, msg):
        """
        å¤„ç†è°ƒåº¦æ›´æ–°æ¶ˆæ¯

        Args:
            msg: Kafkaæ¶ˆæ¯å¯¹è±¡ï¼ˆGinkgoConsumerå·²ååºåˆ—åŒ–ï¼Œmsg.valueæ˜¯dictï¼‰

        æ¶ˆæ¯æ ¼å¼ï¼ˆJSONï¼‰ï¼š
        {
            "command": "portfolio.reload" | "portfolio.migrate" | "node.shutdown",
            "portfolio_id": "portfolio_uuid",
            "target_node": "target_node_id",  // ä»…portfolio.migrateéœ€è¦
            "timestamp": "2026-01-06T10:00:00"
        }
        """
        try:
            # GinkgoConsumer å·²ç»ååºåˆ—åŒ–äº†æ¶ˆæ¯ï¼Œmsg.value ç›´æ¥æ˜¯ dict
            command_data = msg.value

            command = command_data.get('command')
            portfolio_id = command_data.get('portfolio_id', '')
            timestamp = command_data.get('timestamp')
            target_node = command_data.get('target_node', '')
            source_node = command_data.get('source_node', '')

            logger.info(f"{'â”€'*80}")
            logger.info(f"[KAFKA] Received schedule command: {command}")
            logger.info(f"  Portfolio ID: {portfolio_id[:8] if portfolio_id else 'N/A'}")
            logger.info(f"  Source Node:  {source_node if source_node else 'None (new assignment)'}")
            logger.info(f"  Target Node:  {target_node}")
            logger.info(f"  Timestamp:    {timestamp}")
            logger.info(f"{'â”€'*80}")

            # è·¯ç”±åˆ°ä¸åŒçš„å¤„ç†æ–¹æ³•
            if command == 'portfolio.reload':
                self._handle_portfolio_reload(portfolio_id, command_data)
            elif command == 'portfolio.migrate':
                self._handle_portfolio_migrate(portfolio_id, command_data)
            elif command == 'node.pause':
                self._handle_node_pause(command_data)
            elif command == 'node.resume':
                self._handle_node_resume(command_data)
            elif command == 'node.shutdown':
                self._handle_node_shutdown(command_data)
            else:
                logger.warning(f"Unknown schedule command: {command}")

        except Exception as e:
            logger.error(f"Error handling schedule update: {e}")

    def _handle_portfolio_reload(self, portfolio_id: str, command_data: dict):
        """
        å¤„ç†Portfolioé‡æ–°åŠ è½½å‘½ä»¤ï¼ˆT048 - å®Œæ•´å®ç°ï¼‰

        å®Œæ•´æµç¨‹ï¼š
        1. æ£€æŸ¥Portfolioæ˜¯å¦å­˜åœ¨
        2. è°ƒç”¨Portfolio.graceful_reload()
        3. å¤„ç†æ¶ˆæ¯ç¼“å­˜ï¼ˆå¦‚æœéœ€è¦ï¼‰
        4. éªŒè¯é‡è½½ç»“æœ

        Args:
            portfolio_id: Portfolio ID
            command_data: å‘½ä»¤æ•°æ®
        """
        logger.info(f"Reloading portfolio {portfolio_id}")

        try:
            # æ£€æŸ¥Portfolioæ˜¯å¦å­˜åœ¨
            if portfolio_id not in self._portfolio_instances:
                logger.warning(f"Portfolio {portfolio_id} not found in node {self.node_id}")
                return

            # è·å–Portfolioå®ä¾‹
            portfolio = self._portfolio_instances[portfolio_id]

            # è°ƒç”¨ä¼˜é›…é‡è½½
            logger.info(f"Calling graceful_reload() for portfolio {portfolio_id}")
            success = portfolio.graceful_reload(timeout=30)

            if success:
                logger.info(f"Portfolio {portfolio_id} reloaded successfully")
            else:
                logger.error(f"Portfolio {portfolio_id} reload failed")

        except Exception as e:
            logger.error(f"Failed to reload portfolio {portfolio_id}: {e}")

    def _handle_portfolio_migrate(self, portfolio_id: str, command_data: dict):
        """
        å¤„ç†Portfolioè¿ç§»å‘½ä»¤ï¼ˆT050 - å®Œæ•´å®ç°ï¼‰

        å®Œæ•´æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦æ˜¯è¿ç§»åˆ°æœ¬èŠ‚ç‚¹ï¼ˆæ¥æ”¶ç«¯ï¼‰
        2. å¦‚æœæ˜¯è¿å‡ºæœ¬èŠ‚ç‚¹ï¼šä¼˜é›…åœæ­¢å¹¶ç§»é™¤
        3. æ›´æ–°è°ƒåº¦è®¡åˆ’

        Args:
            portfolio_id: Portfolio ID
            command_data: å‘½ä»¤æ•°æ®ï¼ŒåŒ…å«target_node
        """
        target_node = command_data.get('target_node')

        logger.info(f"[MIGRATE] Processing portfolio migration: {portfolio_id[:8]} -> {target_node}")

        try:
            # æƒ…å†µ 1: è¿ç§»åˆ°æœ¬èŠ‚ç‚¹ï¼ˆæ¥æ”¶ç«¯ï¼‰
            if target_node == self.node_id:
                logger.info(f"[MIGRATE] Portfolio {portfolio_id[:8]} is being migrated TO this node ({self.node_id})")
                logger.info(f"[MIGRATE] Starting portfolio receive and load process...")
                self._receive_portfolio(portfolio_id)
                return

            # æƒ…å†µ 2: ä»æœ¬èŠ‚ç‚¹è¿å‡ºï¼ˆå‘é€ç«¯ï¼‰
            if portfolio_id not in self._portfolio_instances:
                logger.warning(f"[MIGRATE] Portfolio {portfolio_id[:8]} not found in node {self.node_id} (nothing to migrate away)")
                return

            logger.info(f"[MIGRATE] Migrating portfolio {portfolio_id[:8]} AWAY from this node")

            # è·å–Portfolioå®ä¾‹
            portfolio = self._portfolio_instances[portfolio_id]

            # è®¾ç½®è¿ç§»çŠ¶æ€
            portfolio._set_status(PORTFOLIO_RUNSTATE_TYPES.MIGRATING)
            logger.info(f"[MIGRATE] Set portfolio status to MIGRATING")

            # åœæ­¢PortfolioProcessor
            if portfolio_id in self.portfolios:
                processor = self.portfolios[portfolio_id]
                processor.stop()
                logger.info(f"[MIGRATE] Processor stopped for portfolio {portfolio_id[:8]}")

            # ä»æœ¬èŠ‚ç‚¹ç§»é™¤
            with self.portfolio_lock:
                if portfolio_id in self.portfolios:
                    del self.portfolios[portfolio_id]

                if portfolio_id in self._portfolio_instances:
                    del self._portfolio_instances[portfolio_id]

            # ä»InterestMapç§»é™¤è®¢é˜…
            # TODO: å®ç° InterestMap.remove_portfolio() æ–¹æ³•
            logger.info(f"[MIGRATE] Portfolio {portfolio_id[:8]} removed from node {self.node_id}")
            logger.info(f"[MIGRATE] Migration away completed successfully")

        except Exception as e:
            logger.error(f"[MIGRATE] Failed to migrate portfolio {portfolio_id[:8]}: {e}")

    def _receive_portfolio(self, portfolio_id: str):
        """
        æ¥æ”¶è¿ç§»çš„Portfolioï¼ˆä»å…¶ä»–èŠ‚ç‚¹è¿ç§»åˆ°æœ¬èŠ‚ç‚¹ï¼‰

        Args:
            portfolio_id: Portfolio ID
        """
        try:
            logger.info(f"[RECEIVE] Starting portfolio receive process: {portfolio_id[:8]}")
            logger.info(f"[RECEIVE] Loading portfolio configuration from database...")

            # ä»æ•°æ®åº“åŠ è½½Portfolio
            load_result = self.load_portfolio(portfolio_id)

            if load_result:
                logger.info(f"[RECEIVE] âœ“ Portfolio {portfolio_id[:8]} received and loaded successfully")
                logger.info(f"[RECEIVE] Portfolio is now running on node {self.node_id}")

                # æ›´æ–°Redis metricsï¼ˆportfolio_countï¼‰
                self._update_node_metrics()
            else:
                logger.error(f"[RECEIVE] âœ— Failed to load portfolio {portfolio_id[:8]}")
                # å‘é€åŠ è½½å¤±è´¥è­¦å‘Š
                try:
                    from ginkgo.notifier.core.notification_service import notify
                    notify(
                        f"PortfolioåŠ è½½å¤±è´¥ - {portfolio_id[:8]}",
                        level="WARN",
                        module="ExecutionNode",
                        details={
                            "Portfolio ID": portfolio_id[:8],
                            "èŠ‚ç‚¹ID": self.node_id,
                            "å¤±è´¥åŸå› ": "load_portfolioè¿”å›False"
                        }
                    )
                except Exception as e:
                    logger.warning(f"Failed to send load failure notification: {e}")

        except Exception as e:
            logger.error(f"[RECEIVE] âœ— Failed to receive portfolio {portfolio_id[:8]}: {e}")

    def _handle_node_pause(self, command_data: dict):
        """
        å¤„ç†èŠ‚ç‚¹æš‚åœå‘½ä»¤

        Args:
            command_data: å‘½ä»¤æ•°æ®
        """
        logger.info(f"Received node pause command for {self.node_id}")
        self.pause()

    def _handle_node_resume(self, command_data: dict):
        """
        å¤„ç†èŠ‚ç‚¹æ¢å¤å‘½ä»¤

        Args:
            command_data: å‘½ä»¤æ•°æ®
        """
        logger.info(f"Received node resume command for {self.node_id}")
        self.resume()

    def _handle_node_shutdown(self, command_data: dict):
        """
        å¤„ç†èŠ‚ç‚¹å…³é—­å‘½ä»¤

        Args:
            command_data: å‘½ä»¤æ•°æ®
        """
        logger.info(f"Received node shutdown command for {self.node_id}")

        try:
            # ä¼˜é›…å…³é—­èŠ‚ç‚¹
            logger.info(f"Shutting down node {self.node_id} gracefully")

            # TODO: å®ç°ä¼˜é›…å…³é—­æµç¨‹
            # 1. åœæ­¢æ¥æ”¶æ–°æ¶ˆæ¯
            # 2. ç­‰å¾…ç°æœ‰æ¶ˆæ¯å¤„ç†å®Œæˆ
            # 3. å…³é—­æ‰€æœ‰Portfolio
            # 4. é€€å‡º

            self.stop()

        except Exception as e:
            logger.error(f"Failed to shutdown node {self.node_id}: {e}")
