"""
BacktestWorker Node

å›æµ‹Workerä¸»èŠ‚ç‚¹ï¼ˆå¯¹åº”ExecutionNodeçš„node.pyï¼‰

èŒè´£ï¼š
- ä»Kafkaæ¥æ”¶å›æµ‹ä»»åŠ¡åˆ†é…
- ç®¡ç†å¤šä¸ªBacktestProcessorå¹¶å‘æ‰§è¡Œï¼ˆmax_backtests=5ï¼‰
- ä¸ŠæŠ¥å¿ƒè·³åˆ°Redisï¼ˆTTL=30sï¼Œ10sç»­çº¦ï¼‰
- ä¼˜é›…å…³é—­å’Œèµ„æºæ¸…ç†
"""

from typing import Dict, Optional
<<<<<<< HEAD
from threading import Thread, Lock, Event
=======
from threading import Thread, RLock, Event
>>>>>>> 011-quant-research
from datetime import datetime
import time
import logging

from ginkgo.workers.backtest_worker.task_processor import BacktestProcessor
from ginkgo.workers.backtest_worker.progress_tracker import ProgressTracker
from ginkgo.workers.backtest_worker.metrics import BacktestMetrics
from ginkgo.workers.backtest_worker.models import BacktestTask, BacktestTaskState, AnalyzerConfig
from ginkgo.data.drivers.ginkgo_kafka import GinkgoConsumer, GinkgoProducer
from ginkgo.data.drivers import create_redis_connection
from ginkgo.libs import GCONF
<<<<<<< HEAD
from ginkgo.interfaces.kafka_topics import KafkaTopics
=======
>>>>>>> 011-quant-research


class BacktestWorker:
    """å›æµ‹WorkerèŠ‚ç‚¹"""

    def __init__(self, worker_id: str):
        """
        åˆå§‹åŒ–BacktestWorker

        Args:
            worker_id: Workerå”¯ä¸€æ ‡è¯†
        """
        self.worker_id = worker_id

        # ä»»åŠ¡ç®¡ç†ï¼š{task_uuid: BacktestProcessor}
        self.tasks: Dict[str, BacktestProcessor] = {}
<<<<<<< HEAD
        self.task_lock = Lock()
=======
        self.task_lock = RLock()
>>>>>>> 011-quant-research

        # Kafka
        self.task_consumer: Optional[GinkgoConsumer] = None
        self.progress_producer: Optional[GinkgoProducer] = None

        # è¿›åº¦è·Ÿè¸ªå’ŒæŒ‡æ ‡
        self.progress_tracker: Optional[ProgressTracker] = None
        self.metrics = BacktestMetrics()

        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.should_stop = False

        # çº¿ç¨‹
        self.task_consumer_thread: Optional[Thread] = None
        self.heartbeat_thread: Optional[Thread] = None
        self.cleanup_thread: Optional[Thread] = None

        # å¿ƒè·³é…ç½®
        self.heartbeat_interval = 10  # 10ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
        self.heartbeat_ttl = 30  # å¿ƒè·³TTL 30ç§’

        # èŠ‚ç‚¹é…ç½®
        self.max_backtests = 5  # æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ï¼ˆå¯¹åº”ExecutionNodeçš„max_portfoliosï¼‰
        self.started_at: Optional[str] = None

        # Rediså®¢æˆ·ç«¯
        self._redis = None

<<<<<<< HEAD
=======
        # ä»»åŠ¡å®¹é‡æ§åˆ¶ï¼šç”¨äºé˜»å¡ç­‰å¾…ç©ºé—²æ§½ä½
        self._slot_available = Event()
        self._slot_available.set()  # åˆå§‹æ—¶æœ‰ç©ºé—²æ§½ä½

>>>>>>> 011-quant-research
    def start(self):
        """å¯åŠ¨BacktestWorker"""
        if self.is_running:
            raise RuntimeError(f"BacktestWorker {self.worker_id} is already running")

        # æ£€æŸ¥worker_idæ˜¯å¦å·²è¢«ä½¿ç”¨
        if self._is_worker_id_in_use():
            raise RuntimeError(f"Worker {self.worker_id} is already in use")

        self.should_stop = False
        self.is_running = True
        self.started_at = datetime.now().isoformat()

        print(f"Starting BacktestWorker {self.worker_id}")

        # æ¸…ç†æ—§æ•°æ®
        self._cleanup_old_heartbeat_data()

<<<<<<< HEAD
        # åˆå§‹åŒ–Kafka Producerï¼ˆè¿›åº¦ä¸ŠæŠ¥ï¼‰
        self.progress_producer = GinkgoProducer()
        self.progress_tracker = ProgressTracker(self.worker_id, self.progress_producer)
=======
        # è·å–ä»»åŠ¡æœåŠ¡ï¼ˆç”¨äºå†™å…¥è¿›åº¦åˆ°æ•°æ®åº“ï¼‰
        from ginkgo import services
        task_service = services.data.backtest_task_service()

        # åˆå§‹åŒ–Kafka Producerï¼ˆè¿›åº¦ä¸ŠæŠ¥ï¼‰
        self.progress_producer = GinkgoProducer()
        self.progress_tracker = ProgressTracker(
            self.worker_id, self.progress_producer, task_service
        )
>>>>>>> 011-quant-research

        # å‘é€åˆå§‹å¿ƒè·³
        self._send_heartbeat()

        # å¯åŠ¨å¿ƒè·³çº¿ç¨‹
        self._start_heartbeat_thread()

        # å¯åŠ¨ä»»åŠ¡æ¶ˆè´¹çº¿ç¨‹
        self._start_task_consumer_thread()

        # å¯åŠ¨æ¸…ç†çº¿ç¨‹
        self._start_cleanup_thread()

        print(f"BacktestWorker {self.worker_id} started")
        print(f"Max concurrent backtests: {self.max_backtests}")
        print(f"Ready to receive tasks from Kafka")

    def stop(self):
        """åœæ­¢BacktestWorkerï¼ˆä¼˜é›…å…³é—­ï¼‰"""
        if not self.is_running:
            print(f"BacktestWorker {self.worker_id} is not running")
            return

        print(f"Stopping BacktestWorker {self.worker_id}")

        # è®¾ç½®åœæ­¢æ ‡å¿—
        self.should_stop = True
        self.is_running = False

        # 1. å…³é—­Kafka Consumer
        if self.task_consumer:
            self.task_consumer.close()
            print("Task consumer closed")

        # 2. ç­‰å¾…ä»»åŠ¡å®Œæˆæˆ–å–æ¶ˆ
        with self.task_lock:
            if self.tasks:
                print(f"Waiting for {len(self.tasks)} tasks to complete...")
                wait_start = time.time()
                while time.time() - wait_start < 10:  # æœ€å¤šç­‰10ç§’
                    for task_uuid, processor in list(self.tasks.items()):
                        if not processor.is_alive():
                            self._remove_task(task_uuid)
                    if not self.tasks:
                        break
                    time.sleep(0.5)

                # è¿˜æœ‰æœªå®Œæˆçš„ä»»åŠ¡ï¼Œå¼ºåˆ¶å–æ¶ˆ
                if self.tasks:
                    print(f"Cancelling {len(self.tasks)} remaining tasks...")
                    for processor in self.tasks.values():
                        processor.cancel()

        # 3. ç­‰å¾…çº¿ç¨‹é€€å‡º
        for thread in [self.task_consumer_thread, self.heartbeat_thread, self.cleanup_thread]:
            if thread and thread.is_alive():
                thread.join(timeout=5)

        # 4. æ¸…ç†Rediså¿ƒè·³
        self._clear_heartbeat()

        # 5. å…³é—­Producer
        if self.progress_producer:
            self.progress_producer.close()

        print(f"BacktestWorker {self.worker_id} stopped")

    def _start_task_consumer_thread(self):
        """å¯åŠ¨ä»»åŠ¡æ¶ˆè´¹çº¿ç¨‹"""
        if self.task_consumer_thread and self.task_consumer_thread.is_alive():
            return

        def consume_tasks():
            print("Task consumer thread started")
<<<<<<< HEAD
            self.task_consumer = GinkgoConsumer(
                topic=KafkaTopics.BACKTEST_ASSIGNMENTS,
                group_id="backtest-workers",
=======
            # ä½¿ç”¨ç‹¬ç‰¹çš„ consumer group ID é¿å…ä¸å…¶ä»–å®ä¾‹å†²çª
            unique_group_id = f"backtest-workers-{self.worker_id}"
            self.task_consumer = GinkgoConsumer(
                topic="backtest.assignments",
                group_id=unique_group_id,
>>>>>>> 011-quant-research
                offset="earliest",
            )

            while not self.should_stop:
                try:
                    # GinkgoConsumer.consumer æ˜¯åº•å±‚çš„ KafkaConsumer
                    messages = self.task_consumer.consumer.poll(timeout_ms=1000)

                    if not messages:
                        continue

                    # å¤„ç†æ¶ˆæ¯ {TopicPartition: [ConsumerRecord]}
                    for tp, records in messages.items():
                        for message in records:
                            # GinkgoConsumer å·²ååºåˆ—åŒ–ï¼Œmessage.value ç›´æ¥æ˜¯ dict
                            assignment = message.value
<<<<<<< HEAD
=======

                            # ğŸ”¥ [FIX] åœ¨æ¥æ”¶ä»»åŠ¡åç«‹å³æäº¤ offsetï¼Œé˜²æ­¢ worker é‡å¯åé‡å¤æ¶ˆè´¹
                            # æ³¨æ„ï¼šè¿™é‡Œåªç¡®è®¤"æ¶ˆæ¯å·²æ¥æ”¶"ï¼Œä¸æ˜¯"ä»»åŠ¡å·²å®Œæˆ"
                            # ä»»åŠ¡å®ŒæˆçŠ¶æ€ç”± progress_tracker è·Ÿè¸ª
                            try:
                                self.task_consumer.commit()
                            except Exception as e:
                                print(f"Failed to commit offset after receiving task: {e}")

>>>>>>> 011-quant-research
                            self._handle_task_assignment(assignment)

                except Exception as e:
                    if not self.should_stop:
                        print(f"Error consuming task: {e}")

        self.task_consumer_thread = Thread(target=consume_tasks, daemon=True)
        self.task_consumer_thread.start()

    def _handle_task_assignment(self, assignment: dict):
        """å¤„ç†ä»»åŠ¡åˆ†é…"""
        task_uuid = assignment.get("task_uuid")
        command = assignment.get("command", "start")

        if command == "start":
            self._start_task(assignment)
        elif command == "cancel":
            self._cancel_task(task_uuid)

    def _start_task(self, assignment: dict):
<<<<<<< HEAD
        """å¯åŠ¨æ–°ä»»åŠ¡"""
        if not self._can_accept_task():
            print(f"Worker at full capacity ({len(self.tasks)}/{self.max_backtests})")
=======
        """å¯åŠ¨æ–°ä»»åŠ¡ï¼ˆé˜»å¡ç­‰å¾…ç©ºé—²æ§½ä½ï¼‰"""
        task_uuid = assignment.get("task_uuid", "unknown")[:8]

        # ğŸ”¥ [FIX] æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²ç»å®Œæˆï¼Œé¿å…é‡å¤æ‰§è¡Œ
        existing_status = self.progress_tracker.get_task_status(assignment.get("task_uuid"))
        if existing_status and existing_status in ["completed", "failed", "cancelled"]:
            print(f"[{task_uuid}] Task already {existing_status}, skipping...")
            return

        # é˜»å¡ç­‰å¾…ç©ºé—²æ§½ä½
        while not self._can_accept_task():
            print(f"[{task_uuid}] Worker at full capacity, waiting for slot...")
            # æ¸…é™¤æ ‡å¿—ï¼Œç­‰å¾…ä»»åŠ¡å®Œæˆæ—¶è¢«è®¾ç½®
            self._slot_available.clear()
            # ç­‰å¾…æœ€å¤š 60 ç§’ï¼Œæ¯éš” 1 ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦åº”è¯¥åœæ­¢
            for _ in range(60):
                if self.should_stop:
                    print(f"[{task_uuid}] Worker stopping, discarding task")
                    return
                if self._slot_available.wait(timeout=1):
                    break
            else:
                # 60ç§’åä»ç„¶æ²¡æœ‰æ§½ä½ï¼Œç»§ç»­ç­‰å¾…
                continue

            # è¢«å”¤é†’åå†æ¬¡æ£€æŸ¥å®¹é‡
            if self._can_accept_task():
                print(f"[{task_uuid}] Slot available, proceeding with task")
                break

        # éªŒè¯å¿…è¦çš„ä»»åŠ¡å‚æ•°
        portfolio_uuid = assignment.get("portfolio_uuid")
        if not portfolio_uuid:
            print(f"[{task_uuid}] ERROR: portfolio_uuid is required but missing, discarding task")
            # ä¸ŠæŠ¥ä»»åŠ¡å¤±è´¥åˆ°æ•°æ®åº“
            self.progress_tracker.report_failed_by_uuid(
                task_uuid=assignment.get("task_uuid", ""),
                error="portfolio_uuid is required"
            )
>>>>>>> 011-quant-research
            return

        # è§£æä»»åŠ¡é…ç½®
        from ginkgo.workers.backtest_worker.models import BacktestConfig

        config_dict = assignment.get("config", {})

        # è½¬æ¢ analyzers é…ç½®
        analyzers = []
        if "analyzers" in config_dict:
            for analyzer_dict in config_dict["analyzers"]:
                analyzers.append(AnalyzerConfig(**analyzer_dict))

        # åˆ›å»º BacktestConfigï¼ˆåŒ…å« analyzersï¼‰
        config = BacktestConfig(
            start_date=config_dict.get("start_date"),
            end_date=config_dict.get("end_date"),
            initial_cash=config_dict.get("initial_cash", 100000.0),
            commission_rate=config_dict.get("commission_rate", 0.0003),
            slippage_rate=config_dict.get("slippage_rate", 0.0001),
            benchmark_return=config_dict.get("benchmark_return", 0.0),
            max_position_ratio=config_dict.get("max_position_ratio", 0.3),
            stop_loss_ratio=config_dict.get("stop_loss_ratio", 0.05),
            take_profit_ratio=config_dict.get("take_profit_ratio", 0.15),
            frequency=config_dict.get("frequency", "DAY"),
            analyzers=analyzers,  # Engine çº§åˆ«çš„åˆ†æå™¨
        )

        task = BacktestTask(
            task_uuid=assignment["task_uuid"],
            portfolio_uuid=assignment["portfolio_uuid"],
            name=assignment["name"],
            config=config,
            state=BacktestTaskState.PENDING,
        )

        print(f"Starting task {task.task_uuid[:8]}: {task.name}")
        if analyzers:
            print(f"  with {len(analyzers)} analyzers: {[a.name for a in analyzers]}")

        # åˆ›å»ºProcessor
        processor = BacktestProcessor(task, self.worker_id, self.progress_tracker)

        with self.task_lock:
            self.tasks[task.task_uuid] = processor

        self.metrics.record_task_start(task.task_uuid, task.name)

<<<<<<< HEAD
        # å°å»¶è¿Ÿç¡®ä¿æ•°æ®åº“äº‹åŠ¡å·²æäº¤ï¼ˆé¢å¤–å®‰å…¨æªæ–½ï¼‰
        time.sleep(0.05)  # 50ms

=======
>>>>>>> 011-quant-research
        # å¯åŠ¨çº¿ç¨‹
        processor.start()

    def _cancel_task(self, task_uuid: str):
        """å–æ¶ˆä»»åŠ¡"""
        with self.task_lock:
            if task_uuid not in self.tasks:
                print(f"Task {task_uuid[:8]} not found")
                return

            processor = self.tasks[task_uuid]
            processor.cancel()
            self.metrics.record_task_cancelled(task_uuid)
            print(f"Task {task_uuid[:8]} cancelled")

    def _remove_task(self, task_uuid: str):
        """ç§»é™¤å·²å®Œæˆçš„ä»»åŠ¡"""
        with self.task_lock:
            if task_uuid in self.tasks:
                processor = self.tasks[task_uuid]
                success = processor.task.state != BacktestTaskState.FAILED
                self.metrics.record_task_complete(task_uuid, success)
                del self.tasks[task_uuid]
<<<<<<< HEAD
=======
                # é€šçŸ¥ç­‰å¾…çš„çº¿ç¨‹æœ‰æ–°æ§½ä½å¯ç”¨
                self._slot_available.set()

        # ä»»åŠ¡å®Œæˆåæäº¤ Kafka offsetï¼Œé˜²æ­¢é‡å¤æ¶ˆè´¹
        if self.task_consumer and self.task_consumer.is_connected:
            try:
                self.task_consumer.commit()
                print(f"[{task_uuid[:8]}] Kafka offset committed")
            except Exception as e:
                print(f"[{task_uuid[:8]}] Failed to commit offset: {e}")
>>>>>>> 011-quant-research

    def _can_accept_task(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿˜èƒ½æ¥å—ä»»åŠ¡"""
        with self.task_lock:
            return len(self.tasks) < self.max_backtests

    def _start_cleanup_thread(self):
        """å¯åŠ¨æ¸…ç†çº¿ç¨‹"""
        def cleanup():
            while not self.should_stop:
                try:
                    time.sleep(1)
<<<<<<< HEAD
                    with self.task_lock:
                        completed_tasks = [
                            uuid for uuid, p in self.tasks.items()
                            if not p.is_alive()
                        ]
                        for uuid in completed_tasks:
                            self._remove_task(uuid)
=======
                    # æ”¶é›†å·²å®Œæˆçš„ä»»åŠ¡ï¼ˆä¸æŒæœ‰é”å¤ªä¹…ï¼‰
                    completed_uuids = []
                    with self.task_lock:
                        for uuid, p in list(self.tasks.items()):
                            if not p.is_alive():
                                completed_uuids.append(uuid)

                    # ç§»é™¤å·²å®Œæˆçš„ä»»åŠ¡ï¼ˆ_remove_task ä¼šè‡ªå·±è·å–é”ï¼‰
                    for uuid in completed_uuids:
                        print(f"[Cleanup] Task {uuid[:8]} thread exited, removing...")
                        self._remove_task(uuid)
                        print(f"[Cleanup] Task {uuid[:8]} removed, slot available")
>>>>>>> 011-quant-research
                except Exception as e:
                    print(f"Error in cleanup: {e}")

        self.cleanup_thread = Thread(target=cleanup, daemon=True)
        self.cleanup_thread.start()

    def _start_heartbeat_thread(self):
        """å¯åŠ¨å¿ƒè·³çº¿ç¨‹"""
        if self.heartbeat_thread and self.heartbeat_thread.is_alive():
            return

        def send_heartbeat():
            while not self.should_stop:
                try:
                    self._send_heartbeat()
                    time.sleep(self.heartbeat_interval)
                except Exception as e:
                    print(f"Error sending heartbeat: {e}")

        self.heartbeat_thread = Thread(target=send_heartbeat, daemon=True)
        self.heartbeat_thread.start()

    def _send_heartbeat(self):
        """å‘é€å¿ƒè·³åˆ°Redis"""
        try:
<<<<<<< HEAD
            redis = self._get_redis()
            key = f"backtest:worker:{self.worker_id}"
            value = {
                "worker_id": self.worker_id,
                "status": "running" if self.is_running else "stopped",
                "running_tasks": len(self.tasks),
                "max_tasks": self.max_backtests,
                "started_at": self.started_at,
                "last_heartbeat": datetime.now().isoformat(),
            }

            import json
            redis.setex(key, self.heartbeat_ttl, json.dumps(value))
=======
            from ginkgo.data.redis_schema import (
                RedisKeyBuilder, BacktestWorkerHeartbeat, WorkerStatus, RedisTTL
            )

            redis = self._get_redis()
            key = RedisKeyBuilder.backtest_worker_heartbeat(self.worker_id)

            heartbeat = BacktestWorkerHeartbeat.create(
                worker_id=self.worker_id,
                status=WorkerStatus.RUNNING if self.is_running else WorkerStatus.STOPPED,
                running_tasks=len(self.tasks),
                max_tasks=self.max_backtests,
                started_at=self.started_at
            )

            redis.setex(key, RedisTTL.BACKTEST_WORKER_HEARTBEAT, heartbeat.to_json())
>>>>>>> 011-quant-research
            print(f"Heartbeat sent: {len(self.tasks)}/{self.max_backtests} tasks running")

        except Exception as e:
            print(f"Failed to send heartbeat: {e}")

    def _clear_heartbeat(self):
        """æ¸…ç†Rediså¿ƒè·³"""
        try:
<<<<<<< HEAD
            redis = self._get_redis()
            key = f"backtest:worker:{self.worker_id}"
=======
            from ginkgo.data.redis_schema import RedisKeyBuilder

            redis = self._get_redis()
            key = RedisKeyBuilder.backtest_worker_heartbeat(self.worker_id)
>>>>>>> 011-quant-research
            redis.delete(key)
            print("Heartbeat cleared")
        except Exception as e:
            print(f"Failed to clear heartbeat: {e}")

    def _cleanup_old_heartbeat_data(self):
        """æ¸…ç†æ—§çš„å¿ƒè·³æ•°æ®"""
        try:
<<<<<<< HEAD
            redis = self._get_redis()
            key = f"backtest:worker:{self.worker_id}"
=======
            from ginkgo.data.redis_schema import RedisKeyBuilder

            redis = self._get_redis()
            key = RedisKeyBuilder.backtest_worker_heartbeat(self.worker_id)
>>>>>>> 011-quant-research
            if redis.exists(key):
                print(f"Old heartbeat data found for {self.worker_id}, cleaning up...")
                redis.delete(key)
        except Exception as e:
            print(f"Failed to cleanup old heartbeat: {e}")

    def _is_worker_id_in_use(self) -> bool:
        """æ£€æŸ¥worker_idæ˜¯å¦å·²è¢«ä½¿ç”¨"""
        try:
<<<<<<< HEAD
            redis = self._get_redis()
            key = f"backtest:worker:{self.worker_id}"
=======
            from ginkgo.data.redis_schema import RedisKeyBuilder
            redis = self._get_redis()
            key = RedisKeyBuilder.backtest_worker_heartbeat(self.worker_id)
>>>>>>> 011-quant-research
            return redis.exists(key)
        except Exception:
            return False

    def _get_redis(self):
        """è·å–Rediså®¢æˆ·ç«¯"""
        if self._redis is None:
            self._redis = create_redis_connection()
        return self._redis

    def get_status(self) -> dict:
        """è·å–WorkerçŠ¶æ€"""
        with self.task_lock:
            task_statuses = {}
            for uuid, processor in self.tasks.items():
                task_statuses[uuid] = processor.get_status()

        return {
            "worker_id": self.worker_id,
            "status": "running" if self.is_running else "stopped",
            "running_tasks": len(self.tasks),
            "max_tasks": self.max_backtests,
            "started_at": self.started_at,
            "tasks": task_statuses,
            "metrics": self.metrics.get_metrics(),
        }
