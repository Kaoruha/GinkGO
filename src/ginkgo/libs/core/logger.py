# Upstream: All Modules
# Downstream: Standard Library
# Role: GLOGæ—¥å¿—æ ¸å¿ƒï¼ŒåŸºäºŽ structlog å®žçŽ°ç»“æž„åŒ–æ—¥å¿—è¾“å‡ºï¼Œæ”¯æŒå®¹å™¨çŽ¯å¢ƒ JSON æ ¼å¼å’Œæœ¬åœ° Rich æŽ§åˆ¶å°è¾“å‡º


# Imports for structlog and distributed logging
import contextvars
import contextlib
import platform
from datetime import datetime
from enum import Enum
from typing import Optional, Dict, Any, List


# ==================== T029: åˆ›å»º contextvars.ContextVar ====================

_trace_id_ctx: contextvars.ContextVar[Optional[str]] = contextvars.ContextVar(
    "trace_id", default=None
)

# ä¸šåŠ¡ä¸Šä¸‹æ–‡ context variables
_log_category_ctx: contextvars.ContextVar[Optional[str]] = contextvars.ContextVar(
    "log_category", default=None
)
_business_context_ctx: contextvars.ContextVar[Dict[str, Any]] = contextvars.ContextVar(
    "business_context", default={}
)






from typing import List
import os
import inspect
import logging
import threading
import hashlib
import time
import re
from logging.handlers import RotatingFileHandler
from rich.logging import RichHandler
from pathlib import Path
from ginkgo.libs.core.config import GCONF

# ==================== T006-T008: æ—¥å¿—æ ¸å¿ƒæžšä¸¾ç±»åž‹ ====================


class LogMode(str, Enum):
    """
    æ—¥å¿—æ¨¡å¼æžšä¸¾ (T006)

    ç”¨äºŽæŽ§åˆ¶ç³»ç»Ÿæ—¥å¿—è¾“å‡ºè¡Œä¸ºï¼š
    - container: å®¹å™¨æ¨¡å¼ï¼Œè¾“å‡ºJSONæ ¼å¼æ—¥å¿—åˆ°stdout/stderr
    - local: æœ¬åœ°æ¨¡å¼ï¼Œè¾“å‡ºåˆ°æ–‡ä»¶å’ŒæŽ§åˆ¶å°
    - auto: è‡ªåŠ¨æ£€æµ‹ï¼Œæ ¹æ®è¿è¡ŒçŽ¯å¢ƒè‡ªåŠ¨é€‰æ‹©
    """
    CONTAINER = "container"
    LOCAL = "local"
    AUTO = "auto"


class LogCategory(str, Enum):
    """
    æ—¥å¿—ç±»åˆ«æžšä¸¾ (T007)

    ç”¨äºŽåŒºåˆ†ä¸åŒä¸šåŠ¡åœºæ™¯çš„æ—¥å¿—ï¼š
    - system: ç³»ç»Ÿçº§åˆ«æ—¥å¿—
    - backtest: å›žæµ‹ç›¸å…³æ—¥å¿—
    """
    SYSTEM = "system"
    BACKTEST = "backtest"


class LogLevel(str, Enum):
    """
    æ—¥å¿—çº§åˆ«æžšä¸¾ (T008)

    ECSæ ‡å‡†æ—¥å¿—çº§åˆ«ï¼š
    - debug: è°ƒè¯•ä¿¡æ¯
    - info: ä¸€èˆ¬ä¿¡æ¯
    - warning: è­¦å‘Šä¿¡æ¯
    - error: é”™è¯¯ä¿¡æ¯
    - critical: ä¸¥é‡é”™è¯¯
    """
    DEBUG = "debug"
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


# ==================== T009-T012: structlog å¤„ç†å™¨ ====================


def ecs_processor(logger, log_method, event_dict):
    """
    ECS å­—æ®µæ˜ å°„å¤„ç†å™¨ (T009)

    å°†æ ‡å‡†æ—¥å¿—å­—æ®µæ˜ å°„åˆ° Elastic Common Schema (ECS) æ ¼å¼ï¼š
    - @timestamp: ISO 8601æ ¼å¼æ—¶é—´æˆ³
    - log.level: æ—¥å¿—çº§åˆ«
    - log.logger: æ—¥å¿—è®°å½•å™¨åç§°
    - message: æ—¥å¿—æ¶ˆæ¯
    - process.pid: è¿›ç¨‹ID
    - host.hostname: ä¸»æœºå
    - trace.id: è¿½è¸ªID (T034)

    Args:
        logger: structlog loggerå¯¹è±¡
        log_method: æ—¥å¿—æ–¹æ³•
        event_dict: æ—¥å¿—äº‹ä»¶å­—å…¸

    Returns:
        Dict: æ›´æ–°åŽçš„æ—¥å¿—äº‹ä»¶å­—å…¸
    """
    # æ—¶é—´æˆ³æ˜ å°„
    event_dict["@timestamp"] = event_dict.pop("timestamp", datetime.utcnow().isoformat())

    # log.* å­—æ®µæ˜ å°„
    event_dict["log"] = {
        "level": event_dict.pop("level", "info"),
        "logger": event_dict.pop("logger_name", "ginkgo")
    }

    # æ¶ˆæ¯å­—æ®µ
    event_dict["message"] = event_dict.pop("event", "")

    # è¿›ç¨‹å’Œä¸»æœºä¿¡æ¯ï¼ˆä»…åœ¨ä¸å­˜åœ¨æ—¶è®¾ç½®ï¼Œé¿å…è¦†ç›– container_metadata_processor çš„å€¼ï¼‰
    if "process" not in event_dict:
        event_dict["process"] = {"pid": os.getpid()}
    if "host" not in event_dict:
        event_dict["host"] = {"hostname": os.getenv("HOSTNAME", platform.node())}

    # T034: æ·»åŠ  trace_id
    trace_id = _trace_id_ctx.get()
    if trace_id:
        event_dict["trace"] = {"id": trace_id}

    return event_dict


def ginkgo_processor(logger, log_method, event_dict):
    """
    Ginkgo ä¸šåŠ¡å­—æ®µå¤„ç†å™¨ (T010)

    æ³¨å…¥Ginkgoä¸šåŠ¡ç›¸å…³çš„æ‰©å±•å­—æ®µï¼š
    - ginkgo.log_category: æ—¥å¿—ç±»åˆ«
    - ginkgo.strategy_id: ç­–ç•¥ID
    - ginkgo.portfolio_id: ç»„åˆID
    - ginkgo.event_type: äº‹ä»¶ç±»åž‹
    - ginkgo.symbol: äº¤æ˜“æ ‡çš„

    Args:
        logger: structlog loggerå¯¹è±¡
        log_method: æ—¥å¿—æ–¹æ³•
        event_dict: æ—¥å¿—äº‹ä»¶å­—å…¸

    Returns:
        Dict: æ›´æ–°åŽçš„æ—¥å¿—äº‹ä»¶å­—å…¸
    """
    if "ginkgo" not in event_dict:
        event_dict["ginkgo"] = {}

    # ä»Ž contextvars èŽ·å–ä¸šåŠ¡ä¸Šä¸‹æ–‡
    log_category = _log_category_ctx.get()
    if log_category:
        event_dict["ginkgo"]["log_category"] = log_category

    # èŽ·å–æ‰€æœ‰ç»‘å®šçš„ä¸šåŠ¡ä¸Šä¸‹æ–‡
    business_context = _business_context_ctx.get()
    for key, value in business_context.items():
        event_dict["ginkgo"][key] = value

    return event_dict


def container_metadata_processor(logger, log_method, event_dict):
    """
    å®¹å™¨å…ƒæ•°æ®å¤„ç†å™¨ (T011)

    åœ¨å®¹å™¨çŽ¯å¢ƒä¸­æ³¨å…¥å®¹å™¨å’ŒKuberneteså…ƒæ•°æ®ï¼š
    - container.id: å®¹å™¨ID
    - kubernetes.pod.name: Podåç§°
    - kubernetes.namespace: å‘½åç©ºé—´

    Args:
        logger: structlog loggerå¯¹è±¡
        log_method: æ—¥å¿—æ–¹æ³•
        event_dict: æ—¥å¿—äº‹ä»¶å­—å…¸

    Returns:
        Dict: æ›´æ–°åŽçš„æ—¥å¿—äº‹ä»¶å­—å…¸
    """
    try:
        from ginkgo.libs.utils.log_utils import get_container_metadata
        metadata = get_container_metadata()
        if "container" in metadata:
            event_dict["container"] = metadata["container"]
        if "kubernetes" in metadata:
            event_dict["kubernetes"] = metadata["kubernetes"]
        # ç¡®ä¿ host å’Œ process å­—æ®µå­˜åœ¨
        if "host" in metadata:
            event_dict["host"] = metadata["host"]
        if "process" in metadata:
            event_dict["process"] = metadata["process"]
    except ImportError:
        pass

    return event_dict


def masking_processor(logger, log_method, event_dict):
    """
    æ•æ„Ÿæ•°æ®è„±æ•å¤„ç†å™¨ (T012)

    æ ¹æ® GCONF.LOGGING_MASK_FIELDS é…ç½®å¯¹æ•æ„Ÿå­—æ®µè¿›è¡Œè„±æ•å¤„ç†ã€‚

    Args:
        logger: structlog loggerå¯¹è±¡
        log_method: æ—¥å¿—æ–¹æ³•
        event_dict: æ—¥å¿—äº‹ä»¶å­—å…¸

    Returns:
        Dict: æ›´æ–°åŽçš„æ—¥å¿—äº‹ä»¶å­—å…¸
    """
    # TODO: åœ¨ T005 ä»»åŠ¡ä¸­å®žçŽ° GCONF.LOGGING_MASK_FIELDS é…ç½®
    mask_fields = []
    if hasattr(GCONF, "LOGGING_MASK_FIELDS"):
        mask_fields = GCONF.LOGGING_MASK_FIELDS

    for field in mask_fields:
        if field in event_dict:
            event_dict[field] = "***MASKED***"

    return event_dict


# ==================== T013: structlog é…ç½® ====================


def configure_structlog():
    """
    é…ç½® structlog (T013, T055)

    è®¾ç½®å®Œæ•´çš„å¤„ç†å™¨é“¾ï¼ˆæŒ‰æ€§èƒ½ä¼˜åŒ–æŽ’åºï¼‰ï¼š

    === å¿«é€Ÿå¤„ç†å™¨ï¼ˆæ—  I/Oï¼Œç®€å•æ“ä½œï¼‰===
    1. contextvars.merge_contextvars - åˆå¹¶ä¸Šä¸‹æ–‡å˜é‡
    2. stdlib.add_log_level - æ·»åŠ æ—¥å¿—çº§åˆ«
    3. stdlib.add_logger_name - æ·»åŠ æ—¥å¿—è®°å½•å™¨åç§°
    4. UnicodeDecoder - Unicodeè§£ç 

    === å¿«é€Ÿå¤„ç†å™¨ï¼ˆç®€å•é€»è¾‘ï¼‰===
    5. ginkgo_processor - Ginkgoä¸šåŠ¡å­—æ®µï¼ˆç®€å•å­—å…¸æ£€æŸ¥ï¼‰
    6. masking_processor - æ•æ„Ÿæ•°æ®è„±æ•ï¼ˆå­—æ®µè¿­ä»£ï¼‰

    === ä¸­ç­‰å¤„ç†å™¨ï¼ˆæ ¼å¼åŒ–/é‡ç»„ï¼‰===
    7. TimeStamper - æ·»åŠ æ—¶é—´æˆ³ï¼ˆæ—¥æœŸæ—¶é—´æ ¼å¼åŒ–ï¼‰
    8. ecs_processor - ECSå­—æ®µæ˜ å°„ï¼ˆå­—å…¸é‡ç»„ï¼‰

    === æ…¢é€Ÿå¤„ç†å™¨ï¼ˆI/O æˆ–å¤æ‚å¤„ç†ï¼‰===
    9. container_metadata_processor - å®¹å™¨å…ƒæ•°æ®ï¼ˆå¯èƒ½è§¦å‘æ–‡ä»¶ I/Oï¼‰
    10. StackInfoRenderer - æ¸²æŸ“å †æ ˆä¿¡æ¯ï¼ˆå †æ ˆéåŽ†ï¼‰
    11. format_exc_info - æ ¼å¼åŒ–å¼‚å¸¸ä¿¡æ¯ï¼ˆå¼‚å¸¸å¤„ç†ï¼‰

    === æœ€æ…¢å¤„ç†å™¨ï¼ˆæ”¾åœ¨æœ€åŽï¼‰===
    12. JSONRenderer - JSONæ¸²æŸ“å™¨ï¼ˆJSON åºåˆ—åŒ–ï¼‰

    Performance Notes (T055):
    - cache_logger_on_first_use=True: é¦–æ¬¡è°ƒç”¨åŽç¼“å­˜ logger å®žä¾‹ï¼Œæå‡ 10-20%
    - å¤„ç†å™¨æŒ‰æ€§èƒ½æŽ’åºï¼šå¿«é€Ÿå¤„ç†å™¨åœ¨å‰ï¼Œå‡å°‘ä¸å¿…è¦çš„æ•°æ®å¤„ç†
    - JSONRenderer æ”¾åœ¨æœ€åŽï¼šä»…åœ¨æœ€ç»ˆè¾“å‡ºæ—¶æ‰è¿›è¡Œåºåˆ—åŒ–

    Args:
        None

    Returns:
        None
    """
    try:
        import structlog

        structlog.configure(
            processors=[
                # === å¿«é€Ÿå¤„ç†å™¨ï¼ˆæžå¿«ï¼‰===
                structlog.contextvars.merge_contextvars,
                structlog.stdlib.add_log_level,
                structlog.stdlib.add_logger_name,
                structlog.processors.UnicodeDecoder(),
                # === å¿«é€Ÿå¤„ç†å™¨ï¼ˆç®€å•é€»è¾‘ï¼‰===
                ginkgo_processor,
                masking_processor,
                # === ä¸­ç­‰å¤„ç†å™¨ï¼ˆæ ¼å¼åŒ–ï¼‰===
                structlog.processors.TimeStamper(fmt="iso"),
                ecs_processor,
                # === æ…¢é€Ÿå¤„ç†å™¨ï¼ˆå¯é€‰ï¼‰===
                container_metadata_processor,
                structlog.processors.StackInfoRenderer(),
                structlog.processors.format_exc_info,
                # === æœ€æ…¢å¤„ç†å™¨ï¼ˆæ”¾åœ¨æœ€åŽï¼‰===
                structlog.processors.JSONRenderer()
            ],
            wrapper_class=structlog.stdlib.BoundLogger,
            context_class=dict,
            logger_factory=structlog.stdlib.LoggerFactory(),
            # T055: ç¼“å­˜ logger å®žä¾‹ä»¥æå‡æ€§èƒ½
            cache_logger_on_first_use=True,
        )
    except ImportError:
        # structlog æœªå®‰è£…ï¼Œä½¿ç”¨æ ‡å‡†æ—¥å¿—
        pass


# ==================== åŽŸæœ‰é…ç½®è¯»å– ====================

# Read Configure
LOGGING_LEVEL_CONSOLE = GCONF.LOGGING_LEVEL_CONSOLE
LOGGING_LEVEL_FILE = GCONF.LOGGING_LEVEL_FILE
LOGGING_COLOR = GCONF.LOGGING_COLOR
LOGGING_PATH = GCONF.LOGGING_PATH
LOGGING_DEFAULT_FILE = GCONF.LOGGING_DEFAULT_FILE
LOGGING_FILE_ON = GCONF.LOGGING_FILE_ON


class GinkgoLogger:
    """
    GinkgoLogger - åŸºäºŽ structlog çš„ç»“æž„åŒ–æ—¥å¿—è®°å½•å™¨

    Args:
        logger_name(str): logger name
        file_names(List): file names
        console_log(bool): if turn on console
    Return:
        None
    """

    def __init__(self, logger_name: str, file_names: List = None, console_log=False):
        self.logger_name = logger_name
        self.backup_count = 3
        self.max_file_bytes = 2 * 1024 * 1024 * 1024
        self._file_names = file_names
        self.file_handlers = []
        self._console_handler_name = "ginkgo_console_logger"
        self.file_formatter = logging.Formatter(
            fmt="[%(asctime)s][%(levelname)s]:%(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )
        self.console_formatter = logging.Formatter(
            "P:%(process)d %(message)s",
            datefmt="%m-%d %H:%M",
        )

        if not os.path.exists(LOGGING_PATH):
            Path(LOGGING_PATH).mkdir(parents=True, exist_ok=True)
            print(f"Create folder {LOGGING_PATH}")

        self.logger = logging.getLogger(logger_name)
        self.logger.setLevel(logging.INFO)

        # é”™è¯¯è¿½è¸ªç›¸å…³çš„å®žä¾‹å˜é‡
        self._error_patterns = {}  # é”™è¯¯æ¨¡å¼è®¡æ•° {pattern_hash: count}
        self._error_timestamps = {}  # é”™è¯¯æ—¶é—´æˆ³ {pattern_hash: last_log_time}
        self._error_lock = threading.RLock()  # çº¿ç¨‹å®‰å…¨é”
        self._max_error_history = 1000  # æœ€å¤§é”™è¯¯åŽ†å²è®°å½•æ•°

        # T037: æ£€æµ‹æ—¥å¿—æ¨¡å¼
        mode = getattr(GCONF, 'LOGGING_MODE', 'auto')
        if mode == 'auto':
            from ginkgo.libs.utils.log_utils import is_container_environment
            self._is_container = is_container_environment()
        elif mode == 'container':
            self._is_container = True
        else:  # local
            self._is_container = False

        # é…ç½® structlog å’Œ handlers
        if self._is_container:
            # å®¹å™¨æ¨¡å¼ï¼šJSON è¾“å‡ºåˆ° stdout/stderr
            configure_structlog()
        else:
            # æœ¬åœ°æ¨¡å¼ï¼šRich æŽ§åˆ¶å° + æ–‡ä»¶
            # åœ¨æœ¬åœ°æ¨¡å¼ä¸‹ä»ç„¶é…ç½® structlog ç”¨äºŽä¸šåŠ¡é€»è¾‘
            configure_structlog()

        self._setup_handlers(console_log)

    def _setup_handlers(self, console_log):
        # T037-T039: æœ¬åœ°æ¨¡å¼æ–‡ä»¶æ—¥å¿—æ”¯æŒ
        # åœ¨æœ¬åœ°æ¨¡å¼ä¸‹å¯ç”¨æ–‡ä»¶æ—¥å¿—ï¼Œå®¹å™¨æ¨¡å¼ç¦ç”¨
        if not self._is_container:
            # æœ¬åœ°æ¨¡å¼ï¼šå¯ç”¨æ–‡ä»¶æ—¥å¿—
            if LOGGING_FILE_ON:
                self._setup_file_handler()
        self._setup_console_handler(console_log)
        # self._setup_error_handler()

    def _should_log_error(self, msg: str) -> tuple[bool, str]:
        """
        æ™ºèƒ½æµé‡æŽ§åˆ¶ï¼šåˆ¤æ–­æ˜¯å¦åº”è¯¥è®°å½•é”™è¯¯æ—¥å¿—
        
        Args:
            msg: é”™è¯¯æ¶ˆæ¯
            
        Returns:
            tuple[bool, str]: (æ˜¯å¦åº”è¯¥è®°å½•, å¤„ç†åŽçš„æ¶ˆæ¯)
        """
        # ç”Ÿæˆé”™è¯¯æ¨¡å¼å“ˆå¸Œï¼ˆåŸºäºŽæ¶ˆæ¯çš„å‰100ä¸ªå­—ç¬¦ï¼Œå¿½ç•¥åŠ¨æ€å‚æ•°ï¼‰
        pattern_msg = msg[:100] if len(msg) > 100 else msg
        # ç§»é™¤å¸¸è§çš„åŠ¨æ€éƒ¨åˆ†ï¼ˆæ•°å­—ã€æ—¶é—´æˆ³ç­‰ï¼‰æ¥ç”Ÿæˆæ¨¡å¼
        pattern_msg = re.sub(r'\d{4}-\d{2}-\d{2}', 'DATE', pattern_msg)  # æ—¥æœŸ
        pattern_msg = re.sub(r'\d{2}:\d{2}:\d{2}', 'TIME', pattern_msg)  # æ—¶é—´
        pattern_msg = re.sub(r'\b\d+\b', 'NUM', pattern_msg)  # æ•°å­—
        pattern_hash = hashlib.md5(pattern_msg.encode()).hexdigest()[:8]
        
        current_time = time.time()
        
        with self._error_lock:
            # èŽ·å–å½“å‰æ¨¡å¼çš„è®¡æ•°
            count = self._error_patterns.get(pattern_hash, 0) + 1
            self._error_patterns[pattern_hash] = count
            self._error_timestamps[pattern_hash] = current_time
            
            # æ¸…ç†è¿‡æœŸçš„é”™è¯¯è®°å½•ï¼ˆä¿ç•™æœ€è¿‘çš„è®°å½•ï¼‰
            if len(self._error_patterns) > self._max_error_history:
                # åˆ é™¤æœ€æ—§çš„100ä¸ªè®°å½•
                sorted_items = sorted(
                    self._error_timestamps.items(), 
                    key=lambda x: x[1]
                )
                for old_hash, _ in sorted_items[:100]:
                    self._error_patterns.pop(old_hash, None)
                    self._error_timestamps.pop(old_hash, None)
            
            # æ™ºèƒ½é¢‘çŽ‡æŽ§åˆ¶é€»è¾‘
            if count == 1:
                # é¦–æ¬¡å‡ºçŽ°ï¼Œå®Œæ•´è®°å½•
                return True, f"ðŸ”¥ [{pattern_hash}] {msg}"
            elif count <= 5:
                # å°‘é‡é‡å¤ï¼Œç®€åŒ–è®°å½•
                return True, f"âš ï¸ [{pattern_hash}] {msg} ({count}th occurrence)"
            elif count == 10:
                # è¾¾åˆ°é˜ˆå€¼ï¼Œå‘å‡ºè­¦å‘Š
                return True, f"ðŸš¨ [{pattern_hash}] Error pattern occurred {count} times, consider investigation: {msg}"
            elif count % 50 == 0:
                # æ¯50æ¬¡è®°å½•ä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯
                return True, f"ðŸ“Š [{pattern_hash}] Error pattern count: {count} - {msg}"
            else:
                # é«˜é¢‘é”™è¯¯ï¼Œä¸è®°å½•
                return False, msg

    def get_error_stats(self) -> dict:
        """èŽ·å–é”™è¯¯ç»Ÿè®¡ä¿¡æ¯"""
        with self._error_lock:
            total_patterns = len(self._error_patterns)
            top_errors = sorted(
                self._error_patterns.items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]
            
            return {
                "total_error_patterns": total_patterns,
                "top_error_patterns": [
                    {"pattern_hash": pattern, "count": count}
                    for pattern, count in top_errors
                ],
                "total_error_count": sum(self._error_patterns.values())
            }
    
    def clear_error_stats(self):
        """æ¸…é™¤é”™è¯¯ç»Ÿè®¡"""
        with self._error_lock:
            self._error_patterns.clear()
            self._error_timestamps.clear()

    def _setup_file_handler(self):
        if not self._file_names:
            self._file_names = [LOGGING_DEFAULT_FILE]
        for i in self._file_names:
            handler = self.add_file_handler(i, LOGGING_LEVEL_FILE)
            self.file_handlers.append(handler)

    def gen_file_handler_name(self, file_name) -> str:
        return f"file_handler_{file_name}"

    def remove_file_handler(self, handler_name: str) -> None:
        for handler in self.logger.handlers:
            if handler.name == self.gen_file_handler_name(handler_name):
                self.logger.removeHandler(handler)

    def add_file_handler(self, file_name: str, level: str) -> None:
        if not file_name.endswith(".log"):
            file_name += ".log"
        # åˆ é™¤åŒåæ–‡ä»¶å¤„ç†å™¨
        self.remove_file_handler(file_name)

        # æ·»åŠ æ–°çš„æ–‡ä»¶å¤„ç†å™¨
        file_path = os.path.join(LOGGING_PATH, file_name)
        file_handler = RotatingFileHandler(
            filename=file_path,
            encoding="utf-8",
            mode="a",
            maxBytes=self.max_file_bytes,
            backupCount=self.backup_count,
        )
        file_handler.set_name(self.gen_file_handler_name(file_name))
        file_handler.setLevel(self.get_log_level(level))
        file_handler.setFormatter(self.file_formatter)
        self.file_handlers.append(file_handler)
        self.logger.addHandler(file_handler)
        return file_handler

    def _setup_console_handler(self, console_log):
        self.console_handler = RichHandler(
            show_time=True,
            omit_repeated_times=False,
            rich_tracebacks=True,
            log_time_format="[%X]",
        )
        self.console_handler.set_name(self._console_handler_name)
        self.console_handler.setLevel(self.get_log_level(LOGGING_LEVEL_CONSOLE))
        self.console_handler.setFormatter(self.console_formatter)

        if console_log:
            self.logger.addHandler(self.console_handler)

    def _setup_error_handler(self):
        error_path = os.path.join(LOGGING_PATH, "error.log")
        error_handler = RotatingFileHandler(
            filename=error_path,
            encoding="utf-8",
            mode="a",
            maxBytes=self.max_file_bytes,
            backupCount=self.backup_count,
        )
        error_handler.set_name("ginkgo_error")
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(self.file_formatter)
        self.logger.addHandler(error_handler)

    def reset_logfile(self, file_name: str) -> None:
        [self.logger.removeHandler(i) for i in self.file_handlers]
        if not LOGGING_FILE_ON:
            return
        self._file_names = []
        self._file_names.append(file_name)
        self._setup_file_handler()

    def set_level(self, level: str, handler_type: str = 'all') -> None:
        """è®¾ç½®æ—¥å¿—çº§åˆ«ï¼Œæ”¯æŒæŒ‡å®šhandlerç±»åž‹
        
        Args:
            level: æ—¥å¿—çº§åˆ« (DEBUG, INFO, WARNING, ERROR, CRITICAL)
            handler_type: handlerç±»åž‹ ('all', 'console', 'file', 'error')
        """
        level_int = self.get_log_level(level)
        
        if handler_type == 'all':
            self.logger.setLevel(level_int)
            if hasattr(self, 'console_handler'):
                self.console_handler.setLevel(level_int)
            for handler in self.file_handlers:
                handler.setLevel(level_int)
        elif handler_type == 'console':
            self.set_console_level(level)
        elif handler_type == 'file':
            self.set_file_level(level)
        elif handler_type == 'error':
            self.set_error_level(level)

    def set_console_level(self, level: str):
        """å•ç‹¬è®¾ç½®æŽ§åˆ¶å°æ—¥å¿—çº§åˆ«"""
        if hasattr(self, 'console_handler'):
            self.console_handler.setLevel(self.get_log_level(level))

    def set_file_level(self, level: str):
        """è®¾ç½®æ‰€æœ‰æ–‡ä»¶æ—¥å¿—çº§åˆ«"""
        level_int = self.get_log_level(level)
        for handler in self.file_handlers:
            handler.setLevel(level_int)

    def set_error_level(self, level: str):
        """è®¾ç½®é”™è¯¯æ—¥å¿—çº§åˆ«"""
        for handler in self.logger.handlers:
            if handler.name == 'ginkgo_error':
                handler.setLevel(self.get_log_level(level))
                break

    def get_log_level(self, level: str) -> int:
        return logging.getLevelName(level.upper())

    def get_current_levels(self) -> dict:
        """èŽ·å–å½“å‰æ‰€æœ‰Handlerçš„æ—¥å¿—çº§åˆ«"""
        levels = {
            'logger': logging.getLevelName(self.logger.level),
            'handlers': {}
        }
        
        for handler in self.logger.handlers:
            handler_name = handler.name or str(type(handler).__name__)
            levels['handlers'][handler_name] = logging.getLevelName(handler.level)
        
        return levels

    def log(self, level, msg: str):
        caller = inspect.stack()[2]
        function = caller.function
        filename = caller.filename.split("/")[-1]
        lineno = caller.lineno
        log_method = getattr(self.logger, level.lower())
        # log_method(f"{msg}  [{filename} -> {function}()  L:{lineno}]", stacklevel=2)
        log_method(msg, stacklevel=4)

    def DEBUG(self, msg: str) -> None:
        """è®°å½• DEBUG çº§åˆ«æ—¥å¿—"""
        if not self.logger.isEnabledFor(logging.DEBUG):
            return

        # T037: æœ¬åœ°æ¨¡å¼ä½¿ç”¨æ ‡å‡† logging è¾“å‡ºåˆ°æ–‡ä»¶ï¼Œå®¹å™¨æ¨¡å¼ä½¿ç”¨ structlog
        if not self._is_container:
            # æœ¬åœ°æ¨¡å¼ï¼šä½¿ç”¨æ ‡å‡† loggingï¼ˆæ”¯æŒæ–‡ä»¶è¾“å‡ºï¼‰
            self.log("DEBUG", msg)
        else:
            # å®¹å™¨æ¨¡å¼ï¼šä½¿ç”¨ structlog JSON è¾“å‡º
            try:
                import structlog
                log = structlog.get_logger(self.logger_name)
                log.debug(msg)
            except ImportError:
                self.log("DEBUG", msg)

    def INFO(self, msg: str) -> None:
        """è®°å½• INFO çº§åˆ«æ—¥å¿—"""
        if not self.logger.isEnabledFor(logging.INFO):
            return

        # T037: æœ¬åœ°æ¨¡å¼ä½¿ç”¨æ ‡å‡† logging è¾“å‡ºåˆ°æ–‡ä»¶ï¼Œå®¹å™¨æ¨¡å¼ä½¿ç”¨ structlog
        if not self._is_container:
            # æœ¬åœ°æ¨¡å¼ï¼šä½¿ç”¨æ ‡å‡† loggingï¼ˆæ”¯æŒæ–‡ä»¶è¾“å‡ºï¼‰
            self.log("INFO", msg)
        else:
            # å®¹å™¨æ¨¡å¼ï¼šä½¿ç”¨ structlog JSON è¾“å‡º
            try:
                import structlog
                log = structlog.get_logger(self.logger_name)
                log.info(msg)
            except ImportError:
                self.log("INFO", msg)

    def WARN(self, msg: str) -> None:
        """è®°å½• WARNING çº§åˆ«æ—¥å¿—"""
        if not self.logger.isEnabledFor(logging.WARNING):
            return

        # T037: æœ¬åœ°æ¨¡å¼ä½¿ç”¨æ ‡å‡† logging è¾“å‡ºåˆ°æ–‡ä»¶ï¼Œå®¹å™¨æ¨¡å¼ä½¿ç”¨ structlog
        if not self._is_container:
            # æœ¬åœ°æ¨¡å¼ï¼šä½¿ç”¨æ ‡å‡† loggingï¼ˆæ”¯æŒæ–‡ä»¶è¾“å‡ºï¼‰
            self.log("WARNING", msg)
        else:
            # å®¹å™¨æ¨¡å¼ï¼šä½¿ç”¨ structlog JSON è¾“å‡º
            try:
                import structlog
                log = structlog.get_logger(self.logger_name)
                log.warning(msg)
            except ImportError:
                self.log("WARNING", msg)

    def ERROR(self, msg: str) -> None:
        """è®°å½• ERROR çº§åˆ«æ—¥å¿—ï¼ˆå«æ™ºèƒ½æµé‡æŽ§åˆ¶ï¼‰"""
        if not self.logger.isEnabledFor(logging.ERROR):
            return

        # ä½¿ç”¨æ™ºèƒ½æµé‡æŽ§åˆ¶
        should_log, processed_msg = self._should_log_error(msg)
        if should_log:
            # T037: æœ¬åœ°æ¨¡å¼ä½¿ç”¨æ ‡å‡† logging è¾“å‡ºåˆ°æ–‡ä»¶ï¼Œå®¹å™¨æ¨¡å¼ä½¿ç”¨ structlog
            if not self._is_container:
                # æœ¬åœ°æ¨¡å¼ï¼šä½¿ç”¨æ ‡å‡† loggingï¼ˆæ”¯æŒæ–‡ä»¶è¾“å‡ºï¼‰
                self.log("ERROR", processed_msg)
            else:
                # å®¹å™¨æ¨¡å¼ï¼šä½¿ç”¨ structlog JSON è¾“å‡º
                try:
                    import structlog
                    log = structlog.get_logger(self.logger_name)
                    log.error(processed_msg)
                except ImportError:
                    self.log("ERROR", processed_msg)

    def CRITICAL(self, msg: str) -> None:
        """è®°å½• CRITICAL çº§åˆ«æ—¥å¿—"""
        if not self.logger.isEnabledFor(logging.CRITICAL):
            return

        # T037: æœ¬åœ°æ¨¡å¼ä½¿ç”¨æ ‡å‡† logging è¾“å‡ºåˆ°æ–‡ä»¶ï¼Œå®¹å™¨æ¨¡å¼ä½¿ç”¨ structlog
        if not self._is_container:
            # æœ¬åœ°æ¨¡å¼ï¼šä½¿ç”¨æ ‡å‡† loggingï¼ˆæ”¯æŒæ–‡ä»¶è¾“å‡ºï¼‰
            self.log("CRITICAL", msg)
        else:
            # å®¹å™¨æ¨¡å¼ï¼šä½¿ç”¨ structlog JSON è¾“å‡º
            try:
                import structlog
                log = structlog.get_logger(self.logger_name)
                log.critical(msg)
            except ImportError:
                self.log("CRITICAL", msg)

    # ==================== T030-T033: trace_id ä¸Šä¸‹æ–‡ç®¡ç† ====================

    def set_trace_id(self, trace_id: str) -> contextvars.Token:
        """
        è®¾ç½®å½“å‰ trace_idï¼ˆä½¿ç”¨ contextvarsï¼‰(T030)

        Args:
            trace_id: è¿½è¸ªIDå­—ç¬¦ä¸²

        Returns:
            contextvars.Token: ç”¨äºŽæ¢å¤ä¸Šä¸‹æ–‡çš„ä»¤ç‰Œ
        """
        return _trace_id_ctx.set(trace_id)

    def get_trace_id(self) -> Optional[str]:
        """
        èŽ·å–å½“å‰ trace_id (T031)

        Returns:
            Optional[str]: å½“å‰è¿½è¸ªIDï¼Œå¦‚æžœæœªè®¾ç½®åˆ™è¿”å›ž None
        """
        return _trace_id_ctx.get()

    def clear_trace_id(self, token: contextvars.Token) -> None:
        """
        æ¸…é™¤ trace_idï¼Œæ¢å¤ä¹‹å‰çš„å€¼ (T032)

        Args:
            token: set_trace_id è¿”å›žçš„ä»¤ç‰Œ
        """
        _trace_id_ctx.reset(token)

    @contextlib.contextmanager
    def with_trace_id(self, trace_id: str):
        """
        ä¸´æ—¶è®¾ç½® trace_id çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ (T033)

        Args:
            trace_id: ä¸´æ—¶è¿½è¸ªIDå­—ç¬¦ä¸²

        Yields:
            None

        Example:
            >>> with logger.with_trace_id("trace-123"):
            ...     logger.INFO("This log has trace_id")
        """
        token = _trace_id_ctx.set(trace_id)
        try:
            yield
        finally:
            _trace_id_ctx.reset(token)

    # ==================== ä¸šåŠ¡ä¸Šä¸‹æ–‡ç®¡ç† ====================

    def set_log_category(self, category: str) -> None:
        """
        è®¾ç½®æ—¥å¿—ç±»åˆ«

        Args:
            category: æ—¥å¿—ç±»åˆ« ("system" æˆ– "backtest")

        Example:
            >>> GLOG.set_log_category("backtest")
            >>> GLOG.INFO("Backtest started")  # æ—¥å¿—å°†åŒ…å« log_category="backtest"
        """
        _log_category_ctx.set(category)

    def bind_context(self, **kwargs) -> None:
        """
        ç»‘å®šä¸šåŠ¡ä¸Šä¸‹æ–‡ï¼ˆä¼šè‡ªåŠ¨æ·»åŠ åˆ°æ‰€æœ‰åŽç»­æ—¥å¿—ï¼‰

        Args:
            **kwargs: ä¸šåŠ¡ä¸Šä¸‹æ–‡å­—æ®µ
                - strategy_id: UUID
                - portfolio_id: UUID
                - event_type: str
                - symbol: str
                - direction: str
                - å…¶ä»–è‡ªå®šä¹‰å­—æ®µ

        Example:
            >>> GLOG.bind_context(
            ...     strategy_id=strategy.uuid,
            ...     portfolio_id=portfolio.uuid
            ... )
            >>> GLOG.INFO("Signal generated")  # è‡ªåŠ¨åŒ…å«ä¸Šè¿°å­—æ®µ
        """
        current_context = _business_context_ctx.get()
        if current_context is None:
            current_context = {}
        current_context.update(kwargs)
        _business_context_ctx.set(current_context)

    def unbind_context(self, *keys: str) -> None:
        """
        è§£ç»‘æŒ‡å®šçš„ä¸Šä¸‹æ–‡å­—æ®µ

        Args:
            *keys: è¦è§£ç»‘çš„å­—æ®µåç§°

        Example:
            >>> GLOG.unbind_context("strategy_id", "portfolio_id")
        """
        current_context = _business_context_ctx.get()
        if current_context:
            for key in keys:
                current_context.pop(key, None)
            _business_context_ctx.set(current_context)

    def clear_context(self) -> None:
        """
        æ¸…é™¤æ‰€æœ‰ä¸šåŠ¡ä¸Šä¸‹æ–‡

        Example:
            >>> GLOG.clear_context()
        """
        _business_context_ctx.set({})
        _log_category_ctx.set(None)
