"""
StrategyDataMixin - ç­–ç•¥æ•°æ®æ··å…¥ç±»

æä¾›ç­–ç•¥ä¸“ç”¨çš„æ•°æ®è®¿é—®åŠŸèƒ½ï¼ŒåŸºäºç°æœ‰çš„data_feederæœºåˆ¶ï¼Œ
æä¾›ç®€å•çš„ç¼“å­˜å’Œpandasåºåˆ—è½¬æ¢åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. åŸºäºdata_feederçš„ç¼“å­˜æ•°æ®è®¿é—®
2. ä»·æ ¼åºåˆ—è½¬æ¢ä¸ºpandas Series
3. ç®€å•çš„ç¼“å­˜ç®¡ç†å’Œç»Ÿè®¡
4. å½“å‰ä»·æ ¼å¿«é€Ÿè·å–

ä½¿ç”¨ç¤ºä¾‹ï¼š
    class MyStrategy(BaseStrategy, StrategyDataMixin):
        def cal(self, portfolio_info, event):
            # è·å–ç¼“å­˜çš„Kçº¿æ•°æ®
            bars = self.get_bars_cached(event.symbol, count=50)

            # è½¬æ¢ä¸ºpandasåºåˆ—ä¾¿äºè®¡ç®—
            close_prices = self.get_price_series(event.symbol, count=50)

            # ç­–ç•¥è‡ªå·±è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            ma20 = close_prices.rolling(20).mean()
            ma5 = close_prices.rolling(5).mean()

            # ç­–ç•¥é€»è¾‘...
            return signals
"""

from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import pandas as pd
from ginkgo.libs import GLOG


class StrategyDataMixin:
    """ç­–ç•¥æ•°æ®æ··å…¥ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®æ··å…¥åŠŸèƒ½"""
        if not hasattr(self, '_strategy_data_initialized'):
            self._strategy_data_initialized = True
            self._init_strategy_data()

    def _init_strategy_data(self):
        """åˆå§‹åŒ–æ•°æ®åŠŸèƒ½å†…éƒ¨çŠ¶æ€"""
        # æ•°æ®ç¼“å­˜
        self._data_cache: Dict[str, Any] = {}
        self._cache_timestamps: Dict[str, datetime] = {}
        self._cache_ttl: timedelta = timedelta(minutes=5)

        # æ•°æ®ç»Ÿè®¡
        self._data_stats: Dict[str, Any] = {
            'cache_hits': 0,
            'cache_misses': 0,
            'data_errors': 0
        }

    def get_bars_cached(self, symbol: str, count: int = 100, frequency: str = '1d',
                       start_date: Optional[datetime] = None, end_date: Optional[datetime] = None,
                       use_cache: bool = True) -> List:
        """
        è·å–ç¼“å­˜çš„Kçº¿æ•°æ® (Get Cached Bar Data)

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            count: æ•°æ®æ¡æ•°
            frequency: æ•°æ®é¢‘ç‡
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            List: Kçº¿æ•°æ®åˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å›ç©ºåˆ—è¡¨
        """
        # è®¡ç®—æ—¶é—´èŒƒå›´
        if end_date is None:
            # ä½¿ç”¨ä¸šåŠ¡æ—¶é—´ï¼ˆå›æµ‹æ—¶ç”±data_feeder.time_controlleræä¾›ï¼‰
            if hasattr(self, 'data_feeder') and self.data_feeder:
                # ä¼˜å…ˆä½¿ç”¨ time_controller.now()ï¼ˆå›æµ‹æ—¶çš„ä¸šåŠ¡æ—¶é—´ï¼Œéœ€è¦è°ƒç”¨ï¼‰
                if hasattr(self.data_feeder, 'time_controller') and self.data_feeder.time_controller:
                    end_date = self.data_feeder.time_controller.now()
                    print(f"[DATA_MIXIN] ä½¿ç”¨ time_controller.now(): {end_date}")
                # ç„¶åå°è¯• data_feeder.nowï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                elif hasattr(self.data_feeder, 'now'):
                    end_date = self.data_feeder.now
                    print(f"[DATA_MIXIN] ä½¿ç”¨ data_feeder.now: {end_date}")
                else:
                    end_date = datetime.now()
                    print(f"[DATA_MIXIN] ä½¿ç”¨ datetime.now: {end_date}")
            else:
                end_date = datetime.now()
                print(f"[DATA_MIXIN] data_feeder ä¸å­˜åœ¨ï¼Œä½¿ç”¨ datetime.now: {end_date}")

        if start_date is None:
            # æ ¹æ®countå’Œfrequencyæ¨ç®—start_date
            if frequency == '1d':
                delta = timedelta(days=count + 10)
            elif frequency == '1h':
                delta = timedelta(hours=count + 10)
            elif frequency == '1m':
                delta = timedelta(minutes=count + 10)
            else:
                delta = timedelta(days=count + 10)
            start_date = end_date - delta

        cache_key = f"bars_{symbol}_{start_date.date()}_{end_date.date()}"

        # æ£€æŸ¥ç¼“å­˜
        if use_cache and self._is_cache_valid(cache_key):
            self._data_stats['cache_hits'] += 1
            return self._data_cache[cache_key]

        # ä»data_feederè·å–æ•°æ®
        try:
            # æ£€æŸ¥ data_feeder æ˜¯å¦å­˜åœ¨
            has_feeder = hasattr(self, 'data_feeder')
            feeder_value = getattr(self, 'data_feeder', None) if has_feeder else None
            has_bar_service = hasattr(feeder_value, 'bar_service') if feeder_value else False

            if not has_feeder:
                print(f"[DATA_MIXIN] æ²¡æœ‰ data_feeder å±æ€§")
                return []
            if not feeder_value:
                print(f"[DATA_MIXIN] data_feeder ä¸º None")
                return []
            if not has_bar_service:
                print(f"[DATA_MIXIN] data_feeder æ²¡æœ‰ bar_service å±æ€§")
                return []

            # ğŸ” è°ƒè¯•æ—¥å¿—
            print(f"[DATA_MIXIN] æŸ¥è¯¢æ•°æ® {symbol}, æ—¶é—´èŒƒå›´: {start_date.date()} ~ {end_date.date()}")

            # ç›´æ¥ä½¿ç”¨ bar_service è·å–æ•°æ®
            result = self.data_feeder.bar_service.get(
                code=symbol,
                start_date=start_date.date(),
                end_date=end_date.date()
            )

            if not result.success or not result.data:
                print(f"[DATA_MIXIN] æŸ¥è¯¢å¤±è´¥æˆ–æ— æ•°æ®, success={result.success}, data={result.data}")
                self._data_stats['cache_misses'] += 1
                return []

            # è½¬æ¢ä¸ºBarå®ä½“åˆ—è¡¨
            bars = result.data.to_entities()

            print(f"[DATA_MIXIN] æŸ¥è¯¢åˆ° {len(bars)} æ¡åŸå§‹æ•°æ®")

            # æŒ‰æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„countæ¡
            bars = sorted(bars, key=lambda x: x.timestamp, reverse=True)
            if len(bars) > count:
                bars = bars[:count]

            # æŒ‰æ—¶é—´å‡åºæ’åˆ—
            bars = list(reversed(bars))

            # ç¼“å­˜ç»“æœ
            if use_cache and bars:
                self._cache_data(cache_key, bars)

            self._data_stats['cache_misses'] += 1
            return bars

        except Exception as e:
            self._data_stats['data_errors'] += 1
            GLOG.error(f"{self._get_name()}: è·å–Kçº¿æ•°æ®å¤±è´¥ {symbol}: {e}")
            import traceback
            traceback.print_exc()
            return []

    def get_current_price(self, symbol: str) -> Optional[float]:
        """
        è·å–å½“å‰ä»·æ ¼ (Get Current Price)

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            Optional[float]: å½“å‰ä»·æ ¼ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            bars = self.get_bars_cached(symbol, count=1)
            if bars and hasattr(bars[0], 'close'):
                return bars[0].close
            return None
        except Exception as e:
            GLOG.error(f"{self._get_name()}: è·å–å½“å‰ä»·æ ¼å¤±è´¥ {symbol}: {e}")
            return None

    def get_price_series(self, symbol: str, count: int = 100, field: str = 'close',
                        frequency: str = '1d') -> pd.Series:
        """
        è·å–ä»·æ ¼åºåˆ— (Get Price Series)

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            count: æ•°æ®æ¡æ•°
            field: ä»·æ ¼å­—æ®µ ('open', 'high', 'low', 'close')
            frequency: æ•°æ®é¢‘ç‡

        Returns:
            pd.Series: ä»·æ ¼åºåˆ—ï¼Œå¤±è´¥æ—¶è¿”å›ç©ºSeries
        """
        try:
            bars = self.get_bars_cached(symbol, count=count, frequency=frequency)
            if not bars:
                return pd.Series()

            # æå–ä»·æ ¼æ•°æ®
            prices = []
            timestamps = []

            for bar in bars:
                if hasattr(bar, field):
                    prices.append(getattr(bar, field))
                    timestamps.append(bar.timestamp)

            if not prices:
                return pd.Series()

            # åˆ›å»ºpandas Series
            series = pd.Series(prices, index=pd.to_datetime(timestamps))
            series.index.name = 'timestamp'
            series.name = f'{symbol}_{field}'

            return series.sort_index()

        except Exception as e:
            GLOG.error(f"{self._get_name()}: è·å–ä»·æ ¼åºåˆ—å¤±è´¥ {symbol}: {e}")
            return pd.Series()

    def get_ohlcv_data(self, symbol: str, count: int = 100, frequency: str = '1d') -> pd.DataFrame:
        """
        è·å–OHLCVæ•°æ®æ¡† (Get OHLCV DataFrame)

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            count: æ•°æ®æ¡æ•°
            frequency: æ•°æ®é¢‘ç‡

        Returns:
            pd.DataFrame: OHLCVæ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å›ç©ºDataFrame
        """
        try:
            bars = self.get_bars_cached(symbol, count=count, frequency=frequency)
            if not bars:
                return pd.DataFrame()

            # è½¬æ¢ä¸ºDataFrame
            data = []
            for bar in bars:
                data.append({
                    'open': getattr(bar, 'open', 0),
                    'high': getattr(bar, 'high', 0),
                    'low': getattr(bar, 'low', 0),
                    'close': getattr(bar, 'close', 0),
                    'volume': getattr(bar, 'volume', 0),
                    'timestamp': bar.timestamp
                })

            df = pd.DataFrame(data)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df.set_index('timestamp', inplace=True)

            return df.sort_index()

        except Exception as e:
            GLOG.error(f"{self._get_name()}: è·å–OHLCVæ•°æ®å¤±è´¥ {symbol}: {e}")
            return pd.DataFrame()

    # ========== ç¼“å­˜ç®¡ç† ==========

    def _is_cache_valid(self, key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if key not in self._data_cache:
            return False
        if key not in self._cache_timestamps:
            return False
        age = datetime.now() - self._cache_timestamps[key]
        return age < self._cache_ttl

    def _cache_data(self, key: str, data: Any) -> None:
        """ç¼“å­˜æ•°æ®"""
        self._data_cache[key] = data
        self._cache_timestamps[key] = datetime.now()

    def clear_data_cache(self, pattern: Optional[str] = None) -> None:
        """
        æ¸…ç†æ•°æ®ç¼“å­˜ (Clear Data Cache)

        Args:
            pattern: ç¼“å­˜é”®æ¨¡å¼ï¼Œä¸ºNoneæ—¶æ¸…ç†æ‰€æœ‰
        """
        if pattern:
            keys_to_remove = [k for k in self._data_cache.keys() if pattern in k]
            for key in keys_to_remove:
                self._data_cache.pop(key, None)
                self._cache_timestamps.pop(key, None)
            GLOG.debug(f"{self._get_name()}: æ¸…ç†ç¼“å­˜æ¨¡å¼ '{pattern}': {len(keys_to_remove)}é¡¹")
        else:
            cache_count = len(self._data_cache)
            self._data_cache.clear()
            self._cache_timestamps.clear()
            GLOG.debug(f"{self._get_name()}: æ¸…ç†æ‰€æœ‰æ•°æ®ç¼“å­˜: {cache_count}é¡¹")

    def set_cache_ttl(self, minutes: int) -> None:
        """
        è®¾ç½®ç¼“å­˜TTL (Set Cache TTL)

        Args:
            minutes: ç¼“å­˜æœ‰æ•ˆæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
        """
        self._cache_ttl = timedelta(minutes=minutes)
        GLOG.debug(f"{self._get_name()}: ç¼“å­˜TTLè®¾ç½®ä¸º {minutes} åˆ†é’Ÿ")

    # ========== ç»Ÿè®¡å’Œå·¥å…·æ–¹æ³• ==========

    def get_data_statistics(self) -> Dict[str, Any]:
        """
        è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯ (Get Data Statistics)

        Returns:
            Dict[str, Any]: æ•°æ®ç»Ÿè®¡
        """
        total_requests = self._data_stats['cache_hits'] + self._data_stats['cache_misses']
        cache_hit_rate = self._data_stats['cache_hits'] / max(total_requests, 1)

        return {
            'cache_hit_rate': round(cache_hit_rate, 3),
            'total_requests': total_requests,
            'cache_hits': self._data_stats['cache_hits'],
            'cache_misses': self._data_stats['cache_misses'],
            'data_errors': self._data_stats['data_errors'],
            'cache_size': len(self._data_cache),
            'cache_ttl_minutes': int(self._cache_ttl.total_seconds() / 60)
        }

    def reset_data_statistics(self) -> None:
        """é‡ç½®æ•°æ®ç»Ÿè®¡"""
        self._data_stats = {
            'cache_hits': 0,
            'cache_misses': 0,
            'data_errors': 0
        }

    def _get_name(self) -> str:
        """è·å–ç»„ä»¶åç§°"""
        return getattr(self, 'name', self.__class__.__name__)