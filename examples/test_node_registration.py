"""
æµ‹è¯• ExecutionNode è‡ªæˆ‘æ³¨å†ŒåŠŸèƒ½

éªŒè¯ ExecutionNode å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨æ³¨å†Œåˆ° Redisï¼š
1. èŠ‚ç‚¹åŸºæœ¬ä¿¡æ¯ (node:info:{node_id})
2. èŠ‚ç‚¹èƒ½åŠ› (node:capabilities:{node_id})
3. å¿ƒè·³ä¿¡æ¯ (heartbeat:node:{node_id})
4. èŠ‚ç‚¹æŒ‡æ ‡ (node:metrics:{node_id})

è¿è¡Œæ–¹å¼ï¼š
    PYTHONPATH=/home/kaoru/Ginkgo/src python examples/test_node_registration.py
"""

import time
from datetime import datetime

print("=" * 70)
print("  ExecutionNode è‡ªæˆ‘æ³¨å†Œæµ‹è¯•")
print("=" * 70)

# ============================================================
# æµ‹è¯• 1: èŠ‚ç‚¹å¯åŠ¨æ—¶è‡ªåŠ¨æ³¨å†Œ
# ============================================================
print("\nğŸ“‹ æµ‹è¯• 1: èŠ‚ç‚¹å¯åŠ¨æ—¶è‡ªåŠ¨æ³¨å†Œ")
print("-" * 70)

try:
    from ginkgo.workers.execution_node.node import ExecutionNode
    from ginkgo.data.crud import RedisCRUD

    # æ¸…ç†æ—§æ•°æ®
    print("ğŸ§¹ æ¸…ç†æ—§æ•°æ®...")
    redis_crud = RedisCRUD()
    redis_client = redis_crud.redis
    test_node_id = "test_registration_node"

    keys_to_delete = [
        f"node:info:{test_node_id}",
        f"node:capabilities:{test_node_id}",
        f"heartbeat:node:{test_node_id}",
        f"node:metrics:{test_node_id}",
    ]
    for key in keys_to_delete:
        redis_client.delete(key)

    # åˆ›å»ºå¹¶å¯åŠ¨èŠ‚ç‚¹
    print("\nğŸ“¦ åˆ›å»ºå¹¶å¯åŠ¨ ExecutionNode...")
    node = ExecutionNode(node_id=test_node_id)

    print(f"   èŠ‚ç‚¹ ID: {node.node_id}")
    print(f"   æœ€å¤§ Portfolio æ•°: {node.max_portfolios}")
    print(f"   å·²æ³¨å†Œæ ‡å¿—: {node.registered}")

    print("\nğŸš€ å¯åŠ¨èŠ‚ç‚¹...")
    node.start()

    # éªŒè¯æ³¨å†Œç»“æœ
    print("\nğŸ” éªŒè¯ Redis ä¸­çš„æ³¨å†Œä¿¡æ¯...")

    # 1. æ£€æŸ¥èŠ‚ç‚¹åŸºæœ¬ä¿¡æ¯
    info_key = f"node:info:{test_node_id}"
    info_data = redis_client.hgetall(info_key)

    if info_data:
        print(f"\nâœ… èŠ‚ç‚¹åŸºæœ¬ä¿¡æ¯ (node:info:{test_node_id}):")
        for field, value in info_data.items():
            print(f"   â€¢ {field.decode('utf-8')}: {value.decode('utf-8')}")
        assert info_data.get(b'status') == b'running', "çŠ¶æ€åº”ä¸º running"
        assert info_data.get(b'max_portfolios') == b'5', "æœ€å¤§ Portfolio æ•°åº”ä¸º 5"
    else:
        print("âŒ æœªæ‰¾åˆ°èŠ‚ç‚¹åŸºæœ¬ä¿¡æ¯")
        raise AssertionError("Node registration failed")

    # 2. æ£€æŸ¥èŠ‚ç‚¹èƒ½åŠ›
    capabilities_key = f"node:capabilities:{test_node_id}"
    capabilities_data = redis_client.hgetall(capabilities_key)

    if capabilities_data:
        print(f"\nâœ… èŠ‚ç‚¹èƒ½åŠ› (node:capabilities:{test_node_id}):")
        for field, value in capabilities_data.items():
            print(f"   â€¢ {field.decode('utf-8')}: {value.decode('utf-8')}")
        assert capabilities_data.get(b'supports_migration') == b'true', "åº”æ”¯æŒè¿ç§»"
        assert capabilities_data.get(b'supports_reload') == b'true', "åº”æ”¯æŒé‡è½½"
    else:
        print("âŒ æœªæ‰¾åˆ°èŠ‚ç‚¹èƒ½åŠ›ä¿¡æ¯")
        raise AssertionError("Node capabilities registration failed")

    # 3. æ£€æŸ¥å¿ƒè·³ï¼ˆå¯åŠ¨åä¼šç«‹å³å‘é€ç¬¬ä¸€æ¬¡å¿ƒè·³ï¼‰
    heartbeat_key = f"heartbeat:node:{test_node_id}"
    heartbeat_value = redis_client.get(heartbeat_key)

    if heartbeat_value:
        print(f"\nâœ… å¿ƒè·³ä¿¡æ¯ (heartbeat:node:{test_node_id}):")
        print(f"   â€¢ å¿ƒè·³æ—¶é—´: {heartbeat_value.decode('utf-8')}")
        ttl = redis_client.ttl(heartbeat_key)
        print(f"   â€¢ TTL: {ttl} ç§’")
        assert ttl > 0 and ttl <= 30, "å¿ƒè·³ TTL åº”åœ¨ 30 ç§’å†…"
    else:
        print("âš ï¸  æœªæ‰¾åˆ°å¿ƒè·³ä¿¡æ¯ï¼ˆå¯èƒ½å¿ƒè·³çº¿ç¨‹å°šæœªå‘é€ï¼‰")

    # 4. æ£€æŸ¥èŠ‚ç‚¹æŒ‡æ ‡
    metrics_key = f"node:metrics:{test_node_id}"
    metrics_data = redis_client.hgetall(metrics_key)

    if metrics_data:
        print(f"\nâœ… èŠ‚ç‚¹æŒ‡æ ‡ (node:metrics:{test_node_id}):")
        for field, value in metrics_data.items():
            print(f"   â€¢ {field.decode('utf-8')}: {value.decode('utf-8')}")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°èŠ‚ç‚¹æŒ‡æ ‡ä¿¡æ¯ï¼ˆå¯èƒ½å¿ƒè·³çº¿ç¨‹å°šæœªæ›´æ–°ï¼‰")

    # 5. éªŒè¯å†…å­˜çŠ¶æ€
    print(f"\nğŸ” èŠ‚ç‚¹å†…å­˜çŠ¶æ€:")
    print(f"   â€¢ å·²æ³¨å†Œ: {node.registered}")
    print(f"   â€¢ å¯åŠ¨æ—¶é—´: {node.started_at}")
    print(f"   â€¢ è¿è¡Œä¸­: {node.is_running}")

    assert node.registered == True, "èŠ‚ç‚¹ registered æ ‡å¿—åº”ä¸º True"
    assert node.started_at is not None, "å¯åŠ¨æ—¶é—´åº”å·²è®¾ç½®"

    print("\nâœ… æµ‹è¯• 1 é€šè¿‡ï¼šèŠ‚ç‚¹è‡ªæˆ‘æ³¨å†ŒæˆåŠŸ")

except Exception as e:
    print(f"\nâŒ æµ‹è¯• 1 å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# ============================================================
# æµ‹è¯• 2: èŠ‚ç‚¹åœæ­¢æ—¶è‡ªåŠ¨æ³¨é”€
# ============================================================
print("\nğŸ“‹ æµ‹è¯• 2: èŠ‚ç‚¹åœæ­¢æ—¶è‡ªåŠ¨æ³¨é”€")
print("-" * 70)

try:
    print("ğŸ›‘ åœæ­¢èŠ‚ç‚¹...")
    node.stop()

    # éªŒè¯æ³¨é”€ç»“æœ
    print("\nğŸ” éªŒè¯ Redis ä¸­çš„æ³¨é”€ç»“æœ...")

    # æ£€æŸ¥æ‰€æœ‰é”®æ˜¯å¦å·²åˆ é™¤
    all_deleted = True
    for key in keys_to_delete:
        exists = redis_client.exists(key)
        if exists:
            print(f"   âŒ é”®ä»å­˜åœ¨: {key}")
            all_deleted = False
        else:
            print(f"   âœ… é”®å·²åˆ é™¤: {key}")

    if all_deleted:
        print("\nâœ… æ‰€æœ‰æ³¨å†Œä¿¡æ¯å·²ä» Redis åˆ é™¤")
    else:
        print("\nâš ï¸  éƒ¨åˆ†é”®ä»å­˜åœ¨")

    # éªŒè¯å†…å­˜çŠ¶æ€
    print(f"\nğŸ” èŠ‚ç‚¹å†…å­˜çŠ¶æ€:")
    print(f"   â€¢ å·²æ³¨å†Œ: {node.registered}")
    print(f"   â€¢ è¿è¡Œä¸­: {node.is_running}")

    assert node.registered == False, "èŠ‚ç‚¹ registered æ ‡å¿—åº”ä¸º False"
    assert node.is_running == False, "èŠ‚ç‚¹ is_running æ ‡å¿—åº”ä¸º False"

    print("\nâœ… æµ‹è¯• 2 é€šè¿‡ï¼šèŠ‚ç‚¹è‡ªæˆ‘æ³¨é”€æˆåŠŸ")

except Exception as e:
    print(f"\nâŒ æµ‹è¯• 2 å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# ============================================================
# æµ‹è¯• 3: Scheduler CLI èƒ½æ£€æµ‹åˆ°æ³¨å†Œçš„èŠ‚ç‚¹
# ============================================================
print("\nğŸ“‹ æµ‹è¯• 3: Scheduler CLI æ£€æµ‹æ³¨å†ŒèŠ‚ç‚¹")
print("-" * 70)

try:
    import subprocess

    # é‡æ–°å¯åŠ¨èŠ‚ç‚¹
    print("ğŸš€ é‡æ–°å¯åŠ¨èŠ‚ç‚¹...")
    node = ExecutionNode(node_id="test_cli_detection_node")
    node.start()

    # ç­‰å¾…å¿ƒè·³å‘é€
    print("â³ ç­‰å¾…å¿ƒè·³å‘é€ (5ç§’)...")
    time.sleep(5)

    # ä½¿ç”¨ CLI æ£€æŸ¥
    print("\nğŸ” ä½¿ç”¨ ginkgo scheduler nodes æ£€æŸ¥...")
    result = subprocess.run(
        ["ginkgo", "scheduler", "nodes"],
        capture_output=True,
        text=True
    )

    if "test_cli_detection_node" in result.stdout:
        print("âœ… Scheduler CLI æˆåŠŸæ£€æµ‹åˆ°æ³¨å†Œçš„èŠ‚ç‚¹")
        print("\n" + result.stdout)
    else:
        print("âš ï¸  Scheduler CLI è¾“å‡ºä¸­æœªæ‰¾åˆ°èŠ‚ç‚¹")
        print("\n" + result.stdout)

    # æ¸…ç†
    print("\nğŸ›‘ æ¸…ç†èŠ‚ç‚¹...")
    node.stop()

    print("\nâœ… æµ‹è¯• 3 é€šè¿‡ï¼šScheduler CLI æ£€æµ‹æˆåŠŸ")

except Exception as e:
    print(f"\nâŒ æµ‹è¯• 3 å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# ============================================================
# æ€»ç»“
# ============================================================
print("\n" + "=" * 70)
print("  âœ… ExecutionNode è‡ªæˆ‘æ³¨å†Œæµ‹è¯•å®Œæˆ")
print("=" * 70)

print("""
ğŸ“Š æµ‹è¯•æ€»ç»“ï¼š

âœ… æµ‹è¯• 1: èŠ‚ç‚¹å¯åŠ¨æ—¶è‡ªåŠ¨æ³¨å†Œ
   - èŠ‚ç‚¹åŸºæœ¬ä¿¡æ¯æ³¨å†ŒæˆåŠŸ (node:info:{node_id})
   - èŠ‚ç‚¹èƒ½åŠ›ä¿¡æ¯æ³¨å†ŒæˆåŠŸ (node:capabilities:{node_id})
   - å¿ƒè·³ä¿¡æ¯æ³¨å†ŒæˆåŠŸ (heartbeat:node:{node_id})
   - èŠ‚ç‚¹æŒ‡æ ‡ä¿¡æ¯æ³¨å†ŒæˆåŠŸ (node:metrics:{node_id})
   - å†…å­˜çŠ¶æ€æ›´æ–°æˆåŠŸ (registered=True, started_atè®¾ç½®)

âœ… æµ‹è¯• 2: èŠ‚ç‚¹åœæ­¢æ—¶è‡ªåŠ¨æ³¨é”€
   - æ‰€æœ‰ Redis é”®æˆåŠŸåˆ é™¤
   - å†…å­˜çŠ¶æ€æ¢å¤ (registered=False, is_running=False)

âœ… æµ‹è¯• 3: Scheduler CLI æ£€æµ‹
   - Scheduler nodes å‘½ä»¤æˆåŠŸæ£€æµ‹åˆ°æ³¨å†Œçš„èŠ‚ç‚¹
   - èŠ‚ç‚¹ä¿¡æ¯æ­£ç¡®æ˜¾ç¤º

ğŸ¯ è‡ªæˆ‘æ³¨å†ŒåŠŸèƒ½éªŒè¯å®Œæˆï¼š

ğŸ’¡ æ³¨å†Œçš„ Redis é”®ç»“æ„ï¼š
   node:info:{node_id} (Hash)
     - node_id: èŠ‚ç‚¹å”¯ä¸€æ ‡è¯†
     - started_at: å¯åŠ¨æ—¶é—´
     - max_portfolios: æœ€å¤§ Portfolio æ•°é‡
     - current_portfolios: å½“å‰ Portfolio æ•°é‡
     - status: è¿è¡ŒçŠ¶æ€ (running)
     - heartbeat_interval: å¿ƒè·³é—´éš”
     - heartbeat_ttl: å¿ƒè·³ TTL

   node:capabilities:{node_id} (Hash)
     - max_portfolios: æœ€å¤§å®¹é‡
     - supports_migration: æ”¯æŒè¿ç§» (true)
     - supports_reload: æ”¯æŒé‡è½½ (true)
     - supports_live_trading: æ”¯æŒå®ç›˜ (true)
     - supports_paper_trading: æ”¯æŒæ¨¡æ‹Ÿç›˜ (true)

   heartbeat:node:{node_id} (String with TTL)
     - Value: ISO 8601 æ—¶é—´æˆ³
     - TTL: 30 ç§’

   node:metrics:{node_id} (Hash)
     - portfolio_count: Portfolio æ•°é‡
     - queue_size: å¹³å‡é˜Ÿåˆ—å¤§å°
     - cpu_usage: CPU ä½¿ç”¨ç‡
     - memory_usage: å†…å­˜ä½¿ç”¨
     - total_events: æ€»äº‹ä»¶æ•°
     - backpressure_count: èƒŒå‹æ¬¡æ•°
     - dropped_events: ä¸¢å¼ƒäº‹ä»¶æ•°

ğŸ”§ ä½¿ç”¨åœºæ™¯ï¼š
   1. èŠ‚ç‚¹å¯åŠ¨ â†’ è‡ªåŠ¨æ³¨å†Œ â†’ Scheduler å¯è§
   2. å®šæœŸå¿ƒè·³ â†’ ä¿æŒåœ¨çº¿çŠ¶æ€
   3. èŠ‚ç‚¹åœæ­¢ â†’ è‡ªåŠ¨æ³¨é”€ â†’ Scheduler æ£€æµ‹åˆ°ç¦»çº¿

ğŸš€ Phase 5 è‡ªæˆ‘æ³¨å†ŒåŠŸèƒ½ï¼šå®Œæˆï¼
""")
