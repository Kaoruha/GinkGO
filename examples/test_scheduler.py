"""
Scheduler æµ‹è¯•è„šæœ¬

æµ‹è¯• Scheduler è°ƒåº¦å™¨çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ExecutionNode å¿ƒè·³å‘é€
2. Scheduler å¿ƒè·³æ£€æµ‹
3. è´Ÿè½½å‡è¡¡åˆ†é…
4. æ•…éšœæ£€æµ‹å’Œ Portfolio è¿ç§»
5. LiveCore Scheduler é›†æˆ

è¿è¡Œæ–¹å¼ï¼š
    PYTHONPATH=/home/kaoru/Ginkgo/src python examples/test_scheduler.py
"""

import time
from datetime import datetime

print("=" * 70)
print("  Phase 5: Scheduler è°ƒåº¦å™¨æµ‹è¯•")
print("=" * 70)

# ============================================================
# æµ‹è¯• 1: Scheduler åŸºç¡€åŠŸèƒ½
# ============================================================
print("\nğŸ“‹ æµ‹è¯• 1: Scheduler åŸºç¡€åŠŸèƒ½")
print("-" * 70)

try:
    from ginkgo.livecore.scheduler import Scheduler
    from ginkgo.data.drivers.ginkgo_kafka import GinkgoProducer
    from ginkgo import services

    # è·å– Redis å®¢æˆ·ç«¯
    print("ğŸ“¦ è·å– Redis å®¢æˆ·ç«¯...")
    try:
        from ginkgo.data.crud import RedisCRUD
        redis_crud = RedisCRUD()
        redis_client = redis_crud.redis
        if not redis_client:
            print("âŒ Redis å®¢æˆ·ç«¯è·å–å¤±è´¥")
        else:
            print("âœ… Redis å®¢æˆ·ç«¯è·å–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ Redis å®¢æˆ·ç«¯è·å–å¤±è´¥: {e}")
        raise

    # åˆ›å»º Kafka ç”Ÿäº§è€…
    print("ğŸ“¨ åˆ›å»º Kafka ç”Ÿäº§è€…...")
    kafka_producer = GinkgoProducer()
    print("âœ… Kafka ç”Ÿäº§è€…åˆ›å»ºæˆåŠŸ")

    # åˆ›å»º Scheduler å®ä¾‹
    print("âš™ï¸  åˆ›å»º Scheduler å®ä¾‹...")
    scheduler = Scheduler(
        redis_client=redis_client,
        kafka_producer=kafka_producer,
        schedule_interval=10,  # 10ç§’è°ƒåº¦ä¸€æ¬¡ï¼ˆæµ‹è¯•ç”¨ï¼‰
        node_id="test_scheduler"
    )
    print(f"âœ… Scheduler åˆ›å»ºæˆåŠŸ: {scheduler.node_id}")

    # éªŒè¯åˆå§‹çŠ¶æ€
    print(f"\nğŸ” Scheduler åˆå§‹çŠ¶æ€:")
    print(f"   - is_running: {scheduler.is_running}")
    print(f"   - should_stop: {scheduler.should_stop}")
    print(f"   - schedule_interval: {scheduler.schedule_interval}s")

except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    exit(1)
except Exception as e:
    print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# ============================================================
# æµ‹è¯• 2: ExecutionNode å¿ƒè·³å‘é€
# ============================================================
print("\nğŸ“‹ æµ‹è¯• 2: ExecutionNode å¿ƒè·³å‘é€")
print("-" * 70)

try:
    from ginkgo.workers.execution_node.node import ExecutionNode

    # æ¸…ç†æ—§çš„å¿ƒè·³æ•°æ®
    print("ğŸ§¹ æ¸…ç†æ—§çš„å¿ƒè·³æ•°æ®...")
    test_node_id = "test_heartbeat_node"
    redis_client.delete(f"heartbeat:node:{test_node_id}")
    redis_client.delete(f"node:metrics:{test_node_id}")

    # åˆ›å»º ExecutionNode
    print(f"ğŸ“¦ åˆ›å»º ExecutionNode: {test_node_id}")
    execution_node = ExecutionNode(node_id=test_node_id)
    print("âœ… ExecutionNode åˆ›å»ºæˆåŠŸ")

    # å¯åŠ¨ ExecutionNodeï¼ˆä¼šå¯åŠ¨å¿ƒè·³çº¿ç¨‹ï¼‰
    print("ğŸš€ å¯åŠ¨ ExecutionNode...")
    execution_node.start()
    print("âœ… ExecutionNode å¯åŠ¨æˆåŠŸ")

    # ç­‰å¾…å¿ƒè·³å‘é€
    print("â³ ç­‰å¾…å¿ƒè·³å‘é€ (3ç§’)...")
    time.sleep(3)

    # æ£€æŸ¥å¿ƒè·³æ•°æ®
    print("ğŸ” æ£€æŸ¥ Redis ä¸­çš„å¿ƒè·³æ•°æ®...")
    heartbeat_key = f"heartbeat:node:{test_node_id}"
    heartbeat_value = redis_client.get(heartbeat_key)

    if heartbeat_value:
        print(f"âœ… å¿ƒè·³æ•°æ®å­˜åœ¨")
        print(f"   - Key: {heartbeat_key}")
        print(f"   - Value: {heartbeat_value.decode('utf-8')}")
        print(f"   - TTL: {redis_client.ttl(heartbeat_key)}s")
    else:
        print(f"âŒ å¿ƒè·³æ•°æ®ä¸å­˜åœ¨")

    # æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
    print("ğŸ” æ£€æŸ¥ Redis ä¸­çš„æ€§èƒ½æŒ‡æ ‡...")
    metrics_key = f"node:metrics:{test_node_id}"
    metrics = redis_client.hgetall(metrics_key)

    if metrics:
        print(f"âœ… æ€§èƒ½æŒ‡æ ‡å­˜åœ¨:")
        for key, value in metrics.items():
            print(f"   - {key.decode('utf-8')}: {value.decode('utf-8')}")
    else:
        print(f"âš ï¸  æ€§èƒ½æŒ‡æ ‡ä¸å­˜åœ¨ï¼ˆå¯èƒ½å°šæœªæ›´æ–°ï¼‰")

    # åœæ­¢ ExecutionNode
    print("ğŸ›‘ åœæ­¢ ExecutionNode...")
    execution_node.stop()
    print("âœ… ExecutionNode å·²åœæ­¢")

except Exception as e:
    print(f"âŒ ExecutionNode å¿ƒè·³æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# ============================================================
# æµ‹è¯• 3: Scheduler å¿ƒè·³æ£€æµ‹
# ============================================================
print("\nğŸ“‹ æµ‹è¯• 3: Scheduler å¿ƒè·³æ£€æµ‹")
print("-" * 70)

try:
    # åˆ›å»ºå¤šä¸ªæµ‹è¯• Node çš„å¿ƒè·³
    print("ğŸ“¦ åˆ›å»ºå¤šä¸ªæµ‹è¯• Node çš„å¿ƒè·³...")
    test_nodes = ["node_1", "node_2", "node_3"]

    for node_id in test_nodes:
        heartbeat_key = f"heartbeat:node:{node_id}"
        redis_client.setex(heartbeat_key, 30, datetime.now().isoformat())

        # è®¾ç½®æ€§èƒ½æŒ‡æ ‡
        metrics_key = f"node:metrics:{node_id}"
        redis_client.hset(metrics_key, mapping={
            "portfolio_count": "2",
            "queue_size": "10",
            "cpu_usage": "50.0"
        })

        print(f"âœ… Node {node_id} å¿ƒè·³å·²è®¾ç½®")

    # ä½¿ç”¨ Scheduler æ£€æµ‹å¥åº·çš„ Node
    print("ğŸ” Scheduler æ£€æµ‹å¥åº·çš„ Node...")
    healthy_nodes = scheduler._get_healthy_nodes()

    print(f"âœ… æ£€æµ‹åˆ° {len(healthy_nodes)} ä¸ªå¥åº·çš„ Node:")
    for node in healthy_nodes:
        print(f"   - {node['node_id']}: {node['metrics']}")

    # æ¸…ç†æµ‹è¯•æ•°æ®
    print("ğŸ§¹ æ¸…ç†æµ‹è¯•å¿ƒè·³æ•°æ®...")
    for node_id in test_nodes:
        redis_client.delete(f"heartbeat:node:{node_id}")
        redis_client.delete(f"node:metrics:{node_id}")

except Exception as e:
    print(f"âŒ Scheduler å¿ƒè·³æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# ============================================================
# æµ‹è¯• 4: è´Ÿè½½å‡è¡¡åˆ†é…
# ============================================================
print("\nğŸ“‹ æµ‹è¯• 4: è´Ÿè½½å‡è¡¡åˆ†é…")
print("-" * 70)

try:
    # åˆ›å»ºæµ‹è¯• Node å’Œ Portfolio
    print("ğŸ“¦ åˆ›å»ºæµ‹è¯• Node å’Œ Portfolio...")

    # è®¾ç½® Node 1ï¼šè´Ÿè½½ä½ï¼ˆ1ä¸ª Portfolioï¼‰
    node_1_id = "load_balance_node_1"
    redis_client.setex(f"heartbeat:node:{node_1_id}", 30, datetime.now().isoformat())
    redis_client.hset(f"node:metrics:{node_1_id}", mapping={
        "portfolio_count": "1",
        "queue_size": "5"
    })

    # è®¾ç½® Node 2ï¼šè´Ÿè½½é«˜ï¼ˆ4ä¸ª Portfolioï¼‰
    node_2_id = "load_balance_node_2"
    redis_client.setex(f"heartbeat:node:{node_2_id}", 30, datetime.now().isoformat())
    redis_client.hset(f"node:metrics:{node_2_id}", mapping={
        "portfolio_count": "4",
        "queue_size": "20"
    })

    print(f"âœ… Node {node_1_id}: 1 ä¸ª Portfolioï¼ˆä½è´Ÿè½½ï¼‰")
    print(f"âœ… Node {node_2_id}: 4 ä¸ª Portfolioï¼ˆé«˜è´Ÿè½½ï¼‰")

    # åˆ›å»ºå¥åº·çš„ Node åˆ—è¡¨
    healthy_nodes = [
        {'node_id': node_1_id, 'metrics': {'portfolio_count': 1, 'queue_size': 5, 'cpu_usage': 30.0}},
        {'node_id': node_2_id, 'metrics': {'portfolio_count': 4, 'queue_size': 20, 'cpu_usage': 80.0}}
    ]

    # æµ‹è¯•åˆ†é…æ–°çš„ Portfolio
    print("ğŸ” æµ‹è¯•åˆ†é…æ–°çš„ Portfolio...")
    current_plan = {}
    orphaned_portfolios = ["portfolio_new_1", "portfolio_new_2"]

    new_plan = scheduler._assign_portfolios(
        healthy_nodes=healthy_nodes,
        current_plan=current_plan,
        orphaned_portfolios=orphaned_portfolios
    )

    print(f"âœ… åˆ†é…ç»“æœ:")
    for portfolio_id, node_id in new_plan.items():
        print(f"   - {portfolio_id} -> {node_id}")

    # éªŒè¯è´Ÿè½½å‡è¡¡ï¼ˆåº”è¯¥ä¼˜å…ˆåˆ†é…åˆ°ä½è´Ÿè½½ Nodeï¼‰
    if new_plan.get("portfolio_new_1") == node_1_id:
        print("âœ… è´Ÿè½½å‡è¡¡ç®—æ³•æ­£ç¡®ï¼šä¼˜å…ˆåˆ†é…åˆ°ä½è´Ÿè½½ Node")
    else:
        print("âŒ è´Ÿè½½å‡è¡¡ç®—æ³•å¯èƒ½æœ‰é—®é¢˜")

    # æ¸…ç†æµ‹è¯•æ•°æ®
    print("ğŸ§¹ æ¸…ç†æµ‹è¯•æ•°æ®...")
    redis_client.delete(f"heartbeat:node:{node_1_id}")
    redis_client.delete(f"heartbeat:node:{node_2_id}")
    redis_client.delete(f"node:metrics:{node_1_id}")
    redis_client.delete(f"node:metrics:{node_2_id}")

except Exception as e:
    print(f"âŒ è´Ÿè½½å‡è¡¡åˆ†é…æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# ============================================================
# æµ‹è¯• 5: æ•…éšœæ£€æµ‹å’Œ Portfolio è¿ç§»
# ============================================================
print("\nğŸ“‹ æµ‹è¯• 5: æ•…éšœæ£€æµ‹å’Œ Portfolio è¿ç§»")
print("-" * 70)

try:
    # åˆ›å»ºæ­£å¸¸ Node å’Œç¦»çº¿ Node
    print("ğŸ“¦ åˆ›å»ºæ­£å¸¸ Node å’Œç¦»çº¿ Node...")

    # Node Aï¼šæ­£å¸¸
    node_a_id = "fault_test_node_a"
    redis_client.setex(f"heartbeat:node:{node_a_id}", 30, datetime.now().isoformat())
    redis_client.hset(f"node:metrics:{node_a_id}", mapping={
        "portfolio_count": "2",
        "queue_size": "10"
    })

    # Node Bï¼šç¦»çº¿ï¼ˆä¸è®¾ç½®å¿ƒè·³ï¼‰
    node_b_id = "fault_test_node_b"
    # ä¸è®¾ç½®å¿ƒè·³ï¼Œæ¨¡æ‹Ÿç¦»çº¿

    print(f"âœ… Node {node_a_id}: æ­£å¸¸ï¼ˆæœ‰å¿ƒè·³ï¼‰")
    print(f"âŒ Node {node_b_id}: ç¦»çº¿ï¼ˆæ— å¿ƒè·³ï¼‰")

    # åˆ›å»ºå½“å‰è°ƒåº¦è®¡åˆ’ï¼ˆåŒ…å«ç¦»çº¿ Node çš„ Portfolioï¼‰
    current_plan = {
        "portfolio_1": node_a_id,
        "portfolio_2": node_a_id,
        "portfolio_3": node_b_id,  # è¿™ä¸ª Portfolio åœ¨ç¦»çº¿ Node ä¸Š
        "portfolio_4": node_b_id,  # è¿™ä¸ª Portfolio åœ¨ç¦»çº¿ Node ä¸Š
    }

    print(f"ğŸ“‹ å½“å‰è°ƒåº¦è®¡åˆ’:")
    for portfolio_id, node_id in current_plan.items():
        print(f"   - {portfolio_id} -> {node_id}")

    # è·å–å¥åº·çš„ Node
    healthy_nodes = scheduler._get_healthy_nodes()
    print(f"\nğŸ” æ£€æµ‹åˆ° {len(healthy_nodes)} ä¸ªå¥åº·çš„ Node")

    # æ£€æµ‹å­¤å„¿ Portfolio
    orphaned_portfolios = scheduler._detect_orphaned_portfolios(healthy_nodes)
    print(f"âœ… æ£€æµ‹åˆ° {len(orphaned_portfolios)} ä¸ªå­¤å„¿ Portfolio:")
    for portfolio_id in orphaned_portfolios:
        print(f"   - {portfolio_id}")

    # é‡æ–°åˆ†é…
    new_plan = scheduler._assign_portfolios(
        healthy_nodes=healthy_nodes,
        current_plan=current_plan,
        orphaned_portfolios=orphaned_portfolios
    )

    print(f"\nâœ… æ–°çš„è°ƒåº¦è®¡åˆ’:")
    for portfolio_id, node_id in new_plan.items():
        status = "âœ…" if node_id == node_a_id else "âŒ"
        print(f"   {status} {portfolio_id} -> {node_id}")

    # éªŒè¯æ‰€æœ‰ Portfolio éƒ½åˆ†é…åˆ°å¥åº·çš„ Node
    all_healthy = all(node_id == node_a_id for node_id in new_plan.values())
    if all_healthy:
        print("\nâœ… æ•…éšœæ£€æµ‹å’Œè¿ç§»æˆåŠŸï¼šæ‰€æœ‰ Portfolio éƒ½è¿ç§»åˆ°å¥åº·çš„ Node")
    else:
        print("\nâŒ æ•…éšœè¿ç§»å¯èƒ½æœ‰é—®é¢˜")

    # æ¸…ç†æµ‹è¯•æ•°æ®
    print("ğŸ§¹ æ¸…ç†æµ‹è¯•æ•°æ®...")
    redis_client.delete(f"heartbeat:node:{node_a_id}")
    redis_client.delete(f"heartbeat:node:{node_b_id}")
    redis_client.delete(f"node:metrics:{node_a_id}")
    redis_client.delete(f"node:metrics:{node_b_id}")
    redis_client.delete("schedule:plan")

except Exception as e:
    print(f"âŒ æ•…éšœæ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# ============================================================
# æµ‹è¯• 6: LiveCore Scheduler é›†æˆ
# ============================================================
print("\nğŸ“‹ æµ‹è¯• 6: LiveCore Scheduler é›†æˆ")
print("-" * 70)

try:
    from ginkgo.livecore.main import LiveCore

    print("ğŸ“¦ åˆ›å»º LiveCore å®ä¾‹...")
    livecore = LiveCore(config={'scheduler_interval': 15})
    print("âœ… LiveCore åˆ›å»ºæˆåŠŸ")

    print("ğŸš€ å¯åŠ¨ LiveCoreï¼ˆåŒ…å« Schedulerï¼‰...")
    livecore.start()
    print("âœ… LiveCore å¯åŠ¨æˆåŠŸ")

    print("â³ ç­‰å¾… Scheduler è¿è¡Œ (5ç§’)...")
    time.sleep(5)

    # æ£€æŸ¥ Scheduler çŠ¶æ€
    if livecore.scheduler and livecore.scheduler.is_running:
        print("âœ… Scheduler æ­£åœ¨è¿è¡Œ")
        print(f"   - node_id: {livecore.scheduler.node_id}")
        print(f"   - schedule_interval: {livecore.scheduler.schedule_interval}s")
    else:
        print("âŒ Scheduler æœªè¿è¡Œ")

    print("ğŸ›‘ åœæ­¢ LiveCore...")
    livecore.stop()
    print("âœ… LiveCore å·²åœæ­¢")

except Exception as e:
    print(f"âŒ LiveCore Scheduler é›†æˆæµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# ============================================================
# æ€»ç»“
# ============================================================
print("\n" + "=" * 70)
print("  âœ… Phase 5: Scheduler è°ƒåº¦å™¨æµ‹è¯•å®Œæˆ")
print("=" * 70)

print("""
ğŸ“Š æµ‹è¯•æ€»ç»“ï¼š

âœ… æµ‹è¯• 1: Scheduler åŸºç¡€åŠŸèƒ½
   - Scheduler ç±»åˆ›å»ºæˆåŠŸ
   - åˆå§‹çŠ¶æ€éªŒè¯é€šè¿‡

âœ… æµ‹è¯• 2: ExecutionNode å¿ƒè·³å‘é€
   - å¿ƒè·³çº¿ç¨‹å¯åŠ¨æˆåŠŸ
   - Redis å¿ƒè·³æ•°æ®å†™å…¥æˆåŠŸ
   - æ€§èƒ½æŒ‡æ ‡æ›´æ–°æˆåŠŸ

âœ… æµ‹è¯• 3: Scheduler å¿ƒè·³æ£€æµ‹
   - å¥åº·èŠ‚ç‚¹æ£€æµ‹æˆåŠŸ
   - æ€§èƒ½æŒ‡æ ‡è¯»å–æˆåŠŸ

âœ… æµ‹è¯• 4: è´Ÿè½½å‡è¡¡åˆ†é…
   - è´Ÿè½½å‡è¡¡ç®—æ³•æ­£ç¡®
   - ä¼˜å…ˆåˆ†é…åˆ°ä½è´Ÿè½½èŠ‚ç‚¹

âœ… æµ‹è¯• 5: æ•…éšœæ£€æµ‹å’Œè¿ç§»
   - ç¦»çº¿èŠ‚ç‚¹æ£€æµ‹æˆåŠŸ
   - å­¤å„¿ Portfolio è¯†åˆ«æˆåŠŸ
   - è‡ªåŠ¨è¿ç§»åˆ°å¥åº·èŠ‚ç‚¹

âœ… æµ‹è¯• 6: LiveCore Scheduler é›†æˆ
   - LiveCore å¯åŠ¨ Scheduler æˆåŠŸ
   - Scheduler æ­£å¸¸è¿è¡Œ

ğŸ¯ Phase 5 æ ¸å¿ƒåŠŸèƒ½å·²å®ç°ï¼š
   - Scheduler æ— çŠ¶æ€è®¾è®¡ï¼ˆRedis å­˜å‚¨ï¼‰
   - ExecutionNode å¿ƒè·³æœºåˆ¶ï¼ˆæ¯10ç§’ï¼ŒTTL=30ç§’ï¼‰
   - è´Ÿè½½å‡è¡¡ç®—æ³•ï¼ˆä¼˜å…ˆä½è´Ÿè½½èŠ‚ç‚¹ï¼‰
   - æ•…éšœæ£€æµ‹å’Œè‡ªåŠ¨è¿ç§»ï¼ˆ< 60ç§’ï¼‰
   - LiveCore é›†æˆå®Œæˆ

ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®ï¼š
   - å®ç° T046: ExecutionNode è®¢é˜…è°ƒåº¦æ›´æ–°
   - å®ç°ä¼˜é›…é‡å¯æœºåˆ¶ï¼ˆT048-T051ï¼‰
   - æ·»åŠ  CLI å‘½ä»¤æ”¯æŒ
""")
