# ExecutionNode å¯åŠ¨é€»è¾‘è¯¦è§£

## æ¦‚è¿°

ExecutionNode æ˜¯ Portfolio çš„è¿è¡Œå®¹å™¨ï¼Œè´Ÿè´£è¿è¡Œå¤šä¸ª Portfolio å®ä¾‹å¹¶å¤„ç†æ¥è‡ª Kafka çš„äº‹ä»¶ã€‚

---

## å¯åŠ¨æµç¨‹

### 1. åˆå§‹åŒ–é˜¶æ®µï¼ˆ`__init__`ï¼‰

```python
ExecutionNode(node_id: str)
```

**æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ–**ï¼š

```python
# Portfolio ç®¡ç†
self.portfolios: Dict[str, PortfolioProcessor] = {}          # {portfolio_id: PortfolioProcessor}
self.portfolio_lock = Lock()                                  # çº¿ç¨‹å®‰å…¨é”
self._portfolio_instances: Dict[str, PortfolioLive] = {}     # Portfolio å®ä¾‹æŒæœ‰

# è·¯ç”±ä¼˜åŒ–ï¼ˆPhase 4ï¼‰
self.interest_map: InterestMap = InterestMap()               # è‚¡ç¥¨ä»£ç  â†’ Portfolio ID åˆ—è¡¨

# Kafka è¿æ¥
self.market_data_consumer: Optional[GinkgoConsumer] = None   # å¸‚åœºæ•°æ®æ¶ˆè´¹è€…
self.order_feedback_consumer: Optional[GinkgoConsumer] = None # è®¢å•åé¦ˆæ¶ˆè´¹è€…
self.schedule_updates_consumer: Optional[GinkgoConsumer] = None  # è°ƒåº¦æ›´æ–°æ¶ˆè´¹è€…ï¼ˆPhase 5ï¼‰
self.order_producer = GinkgoProducer()                       # è®¢å•ç”Ÿäº§è€…

# çº¿ç¨‹ç®¡ç†
self.market_data_thread: Optional[Thread] = None
self.order_feedback_thread: Optional[Thread] = None
self.schedule_updates_thread: Optional[Thread] = None       # è°ƒåº¦æ›´æ–°çº¿ç¨‹ï¼ˆPhase 5ï¼‰
self.heartbeat_thread: Optional[Thread] = None              # å¿ƒè·³çº¿ç¨‹ï¼ˆPhase 5ï¼‰

# è¿è¡ŒçŠ¶æ€
self.is_running = False

# å¿ƒè·³é…ç½®ï¼ˆPhase 5ï¼‰
self.heartbeat_interval = 10   # 10ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
self.heartbeat_ttl = 30        # å¿ƒè·³ TTL 30ç§’

# èƒŒå‹ç»Ÿè®¡
self.backpressure_count = 0
self.dropped_event_count = 0
self.total_event_count = 0
```

**å…³é”®ç‚¹**ï¼š
- âœ… åˆå§‹åŒ–é˜¶æ®µ**ä¸å¯åŠ¨ä»»ä½•çº¿ç¨‹**
- âœ… åˆå§‹åŒ–é˜¶æ®µ**ä¸è¿æ¥ Kafka**
- âœ… åªå‡†å¤‡æ•°æ®ç»“æ„å’Œé…ç½®

---

### 2. å¯åŠ¨é˜¶æ®µï¼ˆ`start()`ï¼‰

```python
def start(self):
    """å¯åŠ¨ExecutionNode"""
```

**å¯åŠ¨æµç¨‹**ï¼š

```python
# 1. çŠ¶æ€æ£€æŸ¥
if self.is_running:
    print(f"[WARNING] ExecutionNode {self.node_id} is already running")
    return

# 2. è®¾ç½®è¿è¡Œæ ‡å¿—
self.is_running = True
print(f"Starting ExecutionNode {self.node_id}")

# 3. å¯åŠ¨å¿ƒè·³ä¸ŠæŠ¥çº¿ç¨‹ï¼ˆPhase 5ï¼‰
self._start_heartbeat_thread()

# 4. å¯åŠ¨è°ƒåº¦æ›´æ–°è®¢é˜…çº¿ç¨‹ï¼ˆPhase 5ï¼‰
self._start_schedule_updates_thread()

# 5. TODO: å¯åŠ¨Kafkaæ¶ˆè´¹çº¿ç¨‹ï¼ˆPhase 4å®ç°ï¼‰
# TODO: è®¢é˜…market.dataå’Œorders.feedback topics
```

**å…³é”®ç‚¹**ï¼š
- âœ… å¯åŠ¨**å¿ƒè·³çº¿ç¨‹**ï¼ˆPhase 5ï¼‰
- âœ… å¯åŠ¨**è°ƒåº¦æ›´æ–°è®¢é˜…çº¿ç¨‹**ï¼ˆPhase 5ï¼‰
- â³ **å¾…å®ç°**ï¼šå¯åŠ¨å¸‚åœºæ•°æ®å’Œè®¢å•åé¦ˆæ¶ˆè´¹çº¿ç¨‹ï¼ˆPhase 4ï¼‰

---

### 3. å¿ƒè·³çº¿ç¨‹ï¼ˆPhase 5ï¼‰

#### å¯åŠ¨å¿ƒè·³çº¿ç¨‹

```python
def _start_heartbeat_thread(self):
    """å¯åŠ¨å¿ƒè·³ä¸ŠæŠ¥çº¿ç¨‹"""
    self.heartbeat_thread = Thread(
        target=self._heartbeat_loop,
        daemon=True,                      # å®ˆæŠ¤çº¿ç¨‹ï¼Œä¸»çº¿ç¨‹é€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸ
        name=f"heartbeat_{self.node_id}"
    )
    self.heartbeat_thread.start()
```

#### å¿ƒè·³å¾ªç¯

```python
def _heartbeat_loop(self):
    """å¿ƒè·³ä¸ŠæŠ¥å¾ªç¯ï¼ˆæ¯10ç§’å‘é€ä¸€æ¬¡ï¼‰"""
    while self.is_running:
        try:
            # 1. å‘é€å¿ƒè·³åˆ° Redis
            self._send_heartbeat()

            # 2. æ›´æ–°æ€§èƒ½æŒ‡æ ‡åˆ° Redis
            self._update_node_metrics()

        except Exception as e:
            logger.error(f"Heartbeat error: {e}")

        # 3. ç­‰å¾…ä¸‹ä¸€æ¬¡å¿ƒè·³
        time.sleep(self.heartbeat_interval)  # 10ç§’
```

#### å‘é€å¿ƒè·³

```python
def _send_heartbeat(self):
    """å‘é€å¿ƒè·³åˆ° Redis"""
    redis_client = self._get_redis_client()

    # Redis Key: heartbeat:node:{node_id}
    heartbeat_key = f"heartbeat:node:{self.node_id}"
    heartbeat_value = datetime.now().isoformat()

    # è®¾ç½®å¿ƒè·³å¹¶é™„å¸¦ TTLï¼ˆ30ç§’ï¼‰
    redis_client.setex(
        heartbeat_key,
        self.heartbeat_ttl,        # TTL = 30ç§’
        heartbeat_value
    )
```

**å¿ƒè·³æœºåˆ¶**ï¼š
- ğŸ“¡ æ¯ **10 ç§’**å‘é€ä¸€æ¬¡å¿ƒè·³
- â° TTL **30 ç§’**ï¼ˆè¶…è¿‡ 30 ç§’æ— å¿ƒè·³è®¤ä¸ºèŠ‚ç‚¹ç¦»çº¿ï¼‰
- ğŸ’¾ å­˜å‚¨åˆ° Redis Key: `heartbeat:node:{node_id}`
- ğŸ” Scheduler é€šè¿‡æ£€æŸ¥ TTL åˆ¤æ–­èŠ‚ç‚¹å¥åº·çŠ¶æ€

#### æ›´æ–°èŠ‚ç‚¹æŒ‡æ ‡

```python
def _update_node_metrics(self):
    """æ›´æ–°èŠ‚ç‚¹æ€§èƒ½æŒ‡æ ‡åˆ° Redis"""
    metrics = {
        "portfolio_count": str(len(self.portfolios)),
        "queue_size": str(self._get_average_queue_size()),
        "cpu_usage": "0.0",                    # é¢„ç•™
        "memory_usage": "0",                   # é¢„ç•™
        "total_events": str(self.total_event_count),
        "backpressure_count": str(self.backpressure_count),
        "dropped_events": str(self.dropped_event_count)
    }

    # Redis Key: node:metrics:{node_id} (Hash)
    metrics_key = f"node:metrics:{self.node_id}"
    redis_client.hset(metrics_key, mapping=metrics)
```

**æ€§èƒ½æŒ‡æ ‡**ï¼š
- ğŸ“Š Portfolio æ•°é‡
- ğŸ“ˆ å¹³å‡é˜Ÿåˆ—å¤§å°
- ğŸ”¢ æ€»äº‹ä»¶æ•°
- âš ï¸ èƒŒå‹æ¬¡æ•°
- âŒ ä¸¢å¼ƒäº‹ä»¶æ•°

---

### 4. è°ƒåº¦æ›´æ–°è®¢é˜…çº¿ç¨‹ï¼ˆPhase 5ï¼‰

#### å¯åŠ¨è°ƒåº¦æ›´æ–°çº¿ç¨‹

```python
def _start_schedule_updates_thread(self):
    """å¯åŠ¨è°ƒåº¦æ›´æ–°è®¢é˜…çº¿ç¨‹"""
    self.schedule_updates_thread = Thread(
        target=self._schedule_updates_loop,
        daemon=True,
        name=f"schedule_updates_{self.node_id}"
    )
    self.schedule_updates_thread.start()
```

#### è°ƒåº¦æ›´æ–°å¾ªç¯

```python
def _schedule_updates_loop(self):
    """è°ƒåº¦æ›´æ–°æ¶ˆè´¹å¾ªç¯"""
    # åˆ›å»º Kafka æ¶ˆè´¹è€…
    topic = "schedule.updates"
    self.schedule_updates_consumer = GinkgoConsumer(
        topic=topic,
        group_id=f"execution_node_{self.node_id}",
        offset="latest"                    # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹æ¶ˆè´¹
    )

    logger.info(f"Subscribed to {topic} for node {self.node_id}")

    # æ¶ˆè´¹å¾ªç¯
    while self.is_running:
        try:
            # ä» Kafka æ‹‰å–æ¶ˆæ¯
            messages = self.schedule_updates_consumer.consumer.poll(timeout_ms=1000)

            for tp, records in messages.items():
                for msg in records:
                    # å¤„ç†è°ƒåº¦å‘½ä»¤
                    self._handle_schedule_update(msg)

        except Exception as e:
            logger.error(f"Schedule updates loop error: {e}")

    # æ¸…ç†
    if self.schedule_updates_consumer:
        self.schedule_updates_consumer.close()
        logger.info("Schedule updates consumer closed")
```

**è®¢é˜…æœºåˆ¶**ï¼š
- ğŸ“¡ è®¢é˜… Kafka Topic: `schedule.updates`
- ğŸ‘¥ Group ID: `execution_node_{node_id}`
- ğŸ†• `offset="latest"`ï¼šåªæ¶ˆè´¹æ–°æ¶ˆæ¯ï¼ˆå¯åŠ¨åçš„å‘½ä»¤ï¼‰

#### å¤„ç†è°ƒåº¦å‘½ä»¤

```python
def _handle_schedule_update(self, msg):
    """å¤„ç†è°ƒåº¦æ›´æ–°å‘½ä»¤"""
    command_data = msg.value  # GinkgoConsumer å·²ååºåˆ—åŒ–
    command = command_data.get("command")
    portfolio_id = command_data.get("portfolio_id")

    # è·¯ç”±åˆ°å…·ä½“å¤„ç†å™¨
    if command == "portfolio.reload":
        self._handle_portfolio_reload(portfolio_id, command_data)

    elif command == "portfolio.migrate":
        self._handle_portfolio_migrate(portfolio_id, command_data)

    elif command == "node.shutdown":
        self._handle_node_shutdown(command_data)

    else:
        logger.warning(f"Unknown command: {command}")
```

**æ”¯æŒçš„å‘½ä»¤**ï¼š
- ğŸ”„ `portfolio.reload`ï¼šé‡è½½ Portfolio é…ç½®
- ğŸ“¦ `portfolio.migrate`ï¼šè¿ç§» Portfolio åˆ°å…¶ä»–èŠ‚ç‚¹
- ğŸ›‘ `node.shutdown`ï¼šå…³é—­èŠ‚ç‚¹

---

## åœæ­¢æµç¨‹

```python
def stop(self):
    """åœæ­¢ExecutionNode"""
    if not self.is_running:
        return

    print(f"Stopping ExecutionNode {self.node_id}")
    self.is_running = False

    # 1. åœæ­¢å¿ƒè·³çº¿ç¨‹
    if self.heartbeat_thread and self.heartbeat_thread.is_alive():
        logger.info("Stopping heartbeat thread...")
        self.heartbeat_thread.join(timeout=5)

    # 2. åœæ­¢æ‰€æœ‰ PortfolioProcessor
    with self.portfolio_lock:
        processors_to_stop = list(self.portfolios.values())

    for processor in processors_to_stop:
        processor.stop()

    # 3. ç­‰å¾…æ¶ˆè´¹çº¿ç¨‹ç»“æŸ
    if self.schedule_updates_thread and self.schedule_updates_thread.is_alive():
        self.schedule_updates_thread.join(timeout=5)

    # 4. å…³é—­ Kafka è¿æ¥
    if self.schedule_updates_consumer:
        self.schedule_updates_consumer.close()

    logger.info(f"ExecutionNode {self.node_id} stopped")
```

**åœæ­¢é¡ºåº**ï¼š
1. è®¾ç½® `is_running = False`ï¼ˆæ‰€æœ‰å¾ªç¯çº¿ç¨‹æ£€æµ‹åˆ°åé€€å‡ºï¼‰
2. ç­‰å¾…å¿ƒè·³çº¿ç¨‹ç»“æŸ
3. åœæ­¢æ‰€æœ‰ PortfolioProcessor
4. ç­‰å¾…æ¶ˆè´¹çº¿ç¨‹ç»“æŸ
5. å…³é—­ Kafka è¿æ¥

---

## çº¿ç¨‹æ¶æ„

```
ExecutionNode ä¸»çº¿ç¨‹
    â”‚
    â”œâ”€ å¿ƒè·³çº¿ç¨‹ï¼ˆheartbeat_threadï¼‰
    â”‚   â””â”€ _heartbeat_loop()
    â”‚       â”œâ”€ _send_heartbeat()        [æ¯ 10 ç§’]
    â”‚       â””â”€ _update_node_metrics()    [æ¯ 10 ç§’]
    â”‚
    â”œâ”€ è°ƒåº¦æ›´æ–°çº¿ç¨‹ï¼ˆschedule_updates_threadï¼‰
    â”‚   â””â”€ _schedule_updates_loop()
    â”‚       â”œâ”€ Kafka poll()
    â”‚       â””â”€ _handle_schedule_update()
    â”‚
    â”œâ”€ å¸‚åœºæ•°æ®æ¶ˆè´¹çº¿ç¨‹ï¼ˆmarket_data_threadï¼‰[TODO]
    â”‚   â””â”€ _market_data_loop()
    â”‚
    â””â”€ è®¢å•åé¦ˆæ¶ˆè´¹çº¿ç¨‹ï¼ˆorder_feedback_threadï¼‰[TODO]
        â””â”€ _order_feedback_loop()
```

**çº¿ç¨‹ç‰¹æ€§**ï¼š
- ğŸ”’ çº¿ç¨‹å®‰å…¨ï¼šä½¿ç”¨ `Lock` ä¿æŠ¤å…±äº«æ•°æ®
- ğŸ‘» å®ˆæŠ¤çº¿ç¨‹ï¼š`daemon=True`ï¼Œä¸»çº¿ç¨‹é€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸ
- ğŸ›‘ ä¼˜é›…åœæ­¢ï¼šé€šè¿‡ `is_running` æ ‡å¿—æ§åˆ¶

---

## å¯åŠ¨æ—¶æœº

### æ‰‹åŠ¨å¯åŠ¨

```python
from ginkgo.workers.execution_node.node import ExecutionNode

# åˆ›å»ºèŠ‚ç‚¹
node = ExecutionNode(node_id="my_node")

# å¯åŠ¨èŠ‚ç‚¹
node.start()
```

### LiveCore å¯åŠ¨ï¼ˆé›†æˆï¼‰

```python
# LiveCore å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨å¯åŠ¨ ExecutionNode
from ginkgo.livecore.main import LiveCore

livecore = LiveCore()
livecore.start()  # ä¼šå¯åŠ¨ ExecutionNode å’Œ Scheduler
```

---

## å…³é”®é…ç½®

| é…ç½®é¡¹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `heartbeat_interval` | 10 ç§’ | å¿ƒè·³å‘é€é—´éš” |
| `heartbeat_ttl` | 30 ç§’ | å¿ƒè·³è¿‡æœŸæ—¶é—´ï¼ˆTTLï¼‰ |
| `is_running` | `False` | è¿è¡Œæ ‡å¿— |
| `daemon_threads` | `True` | å®ˆæŠ¤çº¿ç¨‹ |

---

## æ€»ç»“

### ExecutionNode å¯åŠ¨é€»è¾‘æ ¸å¿ƒè¦ç‚¹ï¼š

1. **å»¶è¿Ÿå¯åŠ¨**ï¼šåˆå§‹åŒ–å’Œå¯åŠ¨åˆ†ç¦»ï¼Œ`__init__` åªå‡†å¤‡æ•°æ®ç»“æ„
2. **çº¿ç¨‹åˆ†ç¦»**ï¼šå¿ƒè·³ã€è°ƒåº¦æ›´æ–°ã€å¸‚åœºæ•°æ®ã€è®¢å•åé¦ˆå„ç‹¬ç«‹çº¿ç¨‹
3. **å¿ƒè·³æœºåˆ¶**ï¼šæ¯ 10 ç§’ä¸ŠæŠ¥ï¼ŒTTL 30 ç§’ï¼Œæ”¯æŒæ•…éšœæ£€æµ‹
4. **è°ƒåº¦è®¢é˜…**ï¼šä» Kafka æ¥æ”¶è°ƒåº¦å‘½ä»¤ï¼ˆreload/migrate/shutdownï¼‰
5. **ä¼˜é›…åœæ­¢**ï¼šé€šè¿‡ `is_running` æ ‡å¿—æ§åˆ¶æ‰€æœ‰çº¿ç¨‹é€€å‡º
6. **çº¿ç¨‹å®‰å…¨**ï¼šä½¿ç”¨ `Lock` ä¿æŠ¤ Portfolio åˆ—è¡¨ç­‰å…±äº«æ•°æ®

### å¯åŠ¨åè‡ªåŠ¨æ‰§è¡Œçš„ä»»åŠ¡ï¼š

âœ… **å¿ƒè·³ä¸ŠæŠ¥**ï¼ˆæ¯ 10 ç§’ï¼‰
- Redis: `heartbeat:node:{node_id}` (TTL=30s)
- Redis: `node:metrics:{node_id}` (Hash)

âœ… **è°ƒåº¦æ›´æ–°ç›‘å¬**ï¼ˆæŒç»­æ¶ˆè´¹ï¼‰
- Kafka: `schedule.updates` topic
- å¤„ç† reload/migrate/shutdown å‘½ä»¤

â³ **å¸‚åœºæ•°æ®æ¶ˆè´¹**ï¼ˆå¾…å®ç° Phase 4ï¼‰
- Kafka: `market.data` topic

â³ **è®¢å•åé¦ˆæ¶ˆè´¹**ï¼ˆå¾…å®ç° Phase 4ï¼‰
- Kafka: `orders.feedback` topic
