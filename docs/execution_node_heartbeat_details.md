# ExecutionNode å¿ƒè·³ä¸ŠæŠ¥ä¿¡æ¯è¯¦è§£

## æ¦‚è¿°

ExecutionNode æ¯ 10 ç§’å‘é€ä¸€æ¬¡å¿ƒè·³ï¼Œå‘ Redis ä¸ŠæŠ¥ä¸¤ç±»ä¿¡æ¯ï¼š
1. **å¿ƒè·³ä¿¡æ¯** (`heartbeat:node:{node_id}`) - è¯æ˜èŠ‚ç‚¹å­˜æ´»
2. **æ€§èƒ½æŒ‡æ ‡** (`node:metrics:{node_id}`) - èŠ‚ç‚¹è¿è¡ŒçŠ¶æ€

---

## å¿ƒè·³å‘é€æµç¨‹

```python
# å¿ƒè·³çº¿ç¨‹æ¯10ç§’æ‰§è¡Œä¸€æ¬¡
def _heartbeat_loop(self):
    while self.is_running:
        self._send_heartbeat()        # å‘é€å¿ƒè·³
        self._update_node_metrics()    # æ›´æ–°æŒ‡æ ‡
        time.sleep(10)                # ç­‰å¾…10ç§’
```

---

## 1. å¿ƒè·³ä¿¡æ¯ (heartbeat:node:{node_id})

### Redis é”®ç»“æ„

```
Key:   heartbeat:node:{node_id}
Type:  String
TTL:   30ç§’ï¼ˆè‡ªåŠ¨è¿‡æœŸï¼‰
Value: ISO 8601 æ—¶é—´æˆ³
```

### ç¤ºä¾‹

```python
redis_client.setex(
    "heartbeat:node:my_node_1",
    30,  # TTL 30ç§’
    "2026-01-06T12:30:45.123456"  # å½“å‰æ—¶é—´
)
```

### Redis CLI æŸ¥çœ‹

```bash
# æŸ¥çœ‹å¿ƒè·³å€¼
127.0.0.1:6379> GET heartbeat:node:my_node_1
"2026-01-06T12:30:45.123456"

# æŸ¥çœ‹å¿ƒè·³TTL
127.0.0.1:6379> TTL heartbeat:node:my_node_1
(integer) 25  # è¿˜å‰©25ç§’è¿‡æœŸ

# æ£€æŸ¥å¿ƒè·³æ˜¯å¦å­˜åœ¨
127.0.0.1:6379> EXISTS heartbeat:node:my_node_1
(integer) 1  # å­˜åœ¨ = èŠ‚ç‚¹åœ¨çº¿
```

### ç”¨é€”

- âœ… **å­˜æ´»è¯æ˜**ï¼šé”®å­˜åœ¨ = èŠ‚ç‚¹åœ¨çº¿
- âœ… **ç¦»çº¿æ£€æµ‹**ï¼šé”®ä¸å­˜åœ¨æˆ–TTLè¿‡æœŸ = èŠ‚ç‚¹ç¦»çº¿
- âœ… **æ—¶é—´æˆ³**ï¼šæœ€åä¸€æ¬¡å¿ƒè·³æ—¶é—´

---

## 2. æ€§èƒ½æŒ‡æ ‡ (node:metrics:{node_id})

### Redis é”®ç»“æ„

```
Key:   node:metrics:{node_id}
Type:  Hash
TTL:   æ— ï¼ˆæ‰‹åŠ¨åˆ é™¤æˆ–èŠ‚ç‚¹åœæ­¢æ—¶æ¸…ç†ï¼‰
Fields: 7ä¸ªæŒ‡æ ‡å­—æ®µ
```

### æŒ‡æ ‡è¯¦æƒ…

| å­—æ®µ | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹å€¼ |
|------|------|------|--------|
| `portfolio_count` | String | å½“å‰è¿è¡Œçš„ Portfolio æ•°é‡ | `"3"` |
| `queue_size` | String | æ‰€æœ‰ Portfolio çš„å¹³å‡é˜Ÿåˆ—å¤§å° | `"15"` |
| `cpu_usage` | String | CPU ä½¿ç”¨ç‡ï¼ˆé¢„ç•™ï¼‰ | `"0.0"` |
| `memory_usage` | String | å†…å­˜ä½¿ç”¨ï¼ˆé¢„ç•™ï¼‰ | `"0"` |
| `total_events` | String | æ€»å¤„ç†äº‹ä»¶æ•° | `"15000"` |
| `backpressure_count` | String | èƒŒå‹å‘ç”Ÿæ¬¡æ•° | `"5"` |
| `dropped_events` | String | ä¸¢å¼ƒäº‹ä»¶æ•° | `"2"` |

### ä»£ç å®ç°

```python
metrics = {
    "portfolio_count": str(len(self.portfolios)),
    "queue_size": str(self._get_average_queue_size()),
    "cpu_usage": "0.0",                      # é¢„ç•™
    "memory_usage": "0",                     # é¢„ç•™
    "total_events": str(self.total_event_count),
    "backpressure_count": str(self.backpressure_count),
    "dropped_events": str(self.dropped_event_count)
}

redis_client.hset(f"node:metrics:{self.node_id}", mapping=metrics)
```

### Redis CLI æŸ¥çœ‹

```bash
# æŸ¥çœ‹æ‰€æœ‰æŒ‡æ ‡
127.0.0.1:6379> HGETALL node:metrics:my_node_1
{
  "portfolio_count": "3",
  "queue_size": "15",
  "cpu_usage": "0.0",
  "memory_usage": "0",
  "total_events": "15000",
  "backpressure_count": "5",
  "dropped_events": "2"
}

# æŸ¥çœ‹å•ä¸ªæŒ‡æ ‡
127.0.0.1:6379> HGET node:metrics:my_node_1 portfolio_count
"3"

# æŸ¥çœ‹æ‰€æœ‰æŒ‡æ ‡é”®
127.0.0.1:6379> KEYS node:metrics:*
1) "node:metrics:node_1"
2) "node:metrics:node_2"
3) "node:metrics:node_3"
```

---

## æŒ‡æ ‡è¯¦ç»†è¯´æ˜

### portfolio_count
```python
"portfolio_count": str(len(self.portfolios))
```
- **å«ä¹‰**ï¼šå½“å‰åŠ è½½çš„ Portfolio æ•°é‡
- **ç”¨é€”**ï¼šScheduler ç”¨äºè´Ÿè½½å‡è¡¡å†³ç­–
- **èŒƒå›´**ï¼š0 ~ max_portfoliosï¼ˆé»˜è®¤5ï¼‰

### queue_size
```python
"queue_size": str(self._get_average_queue_size())
```
- **å«ä¹‰**ï¼šæ‰€æœ‰ Portfolio çš„å¹³å‡é˜Ÿåˆ—å¤§å°
- **ç”¨é€”**ï¼šæ£€æµ‹èŠ‚ç‚¹è´Ÿè½½ï¼ŒèƒŒå‹é¢„è­¦
- **è®¡ç®—**ï¼šæ‰€æœ‰ Portfolio é˜Ÿåˆ—å¤§å°ä¹‹å’Œ / Portfolio æ•°é‡

### cpu_usage
```python
"cpu_usage": "0.0"  # é¢„ç•™
```
- **å«ä¹‰**ï¼šCPU ä½¿ç”¨ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
- **çŠ¶æ€**ï¼šâ³ é¢„ç•™ï¼Œæœªæ¥å®ç°
- **è®¡åˆ’**ï¼šä½¿ç”¨ psutil åº“è·å–å®é™… CPU ä½¿ç”¨ç‡

### memory_usage
```python
"memory_usage": "0"  # é¢„ç•™
```
- **å«ä¹‰**ï¼šå†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰
- **çŠ¶æ€**ï¼šâ³ é¢„ç•™ï¼Œæœªæ¥å®ç°
- **è®¡åˆ’**ï¼šä½¿ç”¨ psutil åº“è·å–å®é™…å†…å­˜ä½¿ç”¨

### total_events
```python
"total_events": str(self.total_event_count)
```
- **å«ä¹‰**ï¼šè‡ªå¯åŠ¨ä»¥æ¥å¤„ç†çš„ç´¯è®¡äº‹ä»¶æ•°
- **æ›´æ–°**ï¼šæ¯æ¬¡å¤„ç†äº‹ä»¶æ—¶é€’å¢
- **ç”¨é€”**ï¼šç›‘æ§èŠ‚ç‚¹å·¥ä½œé‡

### backpressure_count
```python
"backpressure_count": str(self.backpressure_count)
```
- **å«ä¹‰**ï¼šèƒŒå‹å‘ç”Ÿçš„ç´¯è®¡æ¬¡æ•°
- **è§¦å‘**ï¼šå½“é˜Ÿåˆ—æ»¡æ—¶è§¦å‘èƒŒå‹
- **ç”¨é€”**ï¼šè¯„ä¼°èŠ‚ç‚¹æ€§èƒ½ç“¶é¢ˆ

### dropped_events
```python
"dropped_events": str(self.dropped_event_count)
```
- **å«ä¹‰**ï¼šä¸¢å¼ƒäº‹ä»¶çš„ç´¯è®¡æ•°é‡
- **è§¦å‘**ï¼šèƒŒå‹æ— æ³•ç¼“è§£æ—¶ä¸¢å¼ƒäº‹ä»¶
- **ç”¨é€”**ï¼šç›‘æ§æ•°æ®ä¸¢å¤±æƒ…å†µ

---

## ä½¿ç”¨åœºæ™¯

### Scheduler å‘ç°èŠ‚ç‚¹

```python
# Scheduler æ‰«ææ‰€æœ‰å¿ƒè·³é”®
heartbeat_keys = redis_client.keys("heartbeat:node:*")

for key in heartbeat_keys:
    node_id = key.replace("heartbeat:node:", "")

    # æ£€æŸ¥ TTLï¼ˆå¿ƒè·³æ–°é²œåº¦ï¼‰
    ttl = redis_client.ttl(key)
    if ttl > 0:
        # èŠ‚ç‚¹åœ¨çº¿
        metrics = redis_client.hgetall(f"node:metrics:{node_id}")
        portfolio_count = metrics.get(b'portfolio_count', b'0')
        print(f"èŠ‚ç‚¹ {node_id}: åœ¨çº¿, Portfolioæ•°={portfolio_count}")
```

### CLI æ˜¾ç¤ºèŠ‚ç‚¹çŠ¶æ€

```bash
$ ginkgo scheduler nodes

                            ğŸ–¥ ExecutionNode Status
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Node ID               â”ƒ Portfolios â”ƒ Queue Size â”ƒ CPU Usage â”ƒ Last Heartbeat â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ test_node_1           â”‚          3 â”‚         15 â”‚      0.0% â”‚ 25s ago        â”‚
â”‚ test_node_2           â”‚          2 â”‚         10 â”‚      0.0% â”‚ 18s ago        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è´Ÿè½½å‡è¡¡å†³ç­–

```python
# Scheduler æ ¹æ®æŒ‡æ ‡é€‰æ‹©èŠ‚ç‚¹

def select_node_for_portfolio(healthy_nodes):
    # é€‰æ‹© portfolio_count æœ€å°‘çš„èŠ‚ç‚¹
    min_count = float('inf')
    selected_node = None

    for node in healthy_nodes:
        count = int(node['metrics']['portfolio_count'])
        if count < min_count:
            min_count = count
            selected_node = node['node_id']

    return selected_node
```

---

## å¿ƒè·³æ—¶é—´çº¿

```
T=0s:   ExecutionNode å¯åŠ¨
        â†“
        ç«‹å³å‘é€ç¬¬1æ¬¡å¿ƒè·³
        heartbeat:node:xxx = "2026-01-06T12:00:00" (TTL=30)

T=10s:  å¿ƒè·³çº¿ç¨‹ç¬¬1æ¬¡å¾ªç¯
        â†“
        å‘é€ç¬¬2æ¬¡å¿ƒè·³
        heartbeat:node:xxx = "2026-01-06T12:00:10" (TTL=30)

T=20s:  å¿ƒè·³çº¿ç¨‹ç¬¬2æ¬¡å¾ªç¯
        â†“
        å‘é€ç¬¬3æ¬¡å¿ƒè·³
        heartbeat:node:xxx = "2026-01-06T12:00:20" (TTL=30)

T=30s:  å¿ƒè·³çº¿ç¨‹ç¬¬3æ¬¡å¾ªç¯
        â†“
        å‘é€ç¬¬4æ¬¡å¿ƒè·³
        heartbeat:node:xxx = "2026-01-06T12:00:30" (TTL=30)

...

å¦‚æœèŠ‚ç‚¹åœæ­¢ï¼š
        ä¸å†å‘é€å¿ƒè·³
        â†“
T=X+30s: TTL è¿‡æœŸï¼Œé”®è‡ªåŠ¨åˆ é™¤
        â†“
        Scheduler æ£€æµ‹åˆ°ç¦»çº¿
```

---

## è°ƒè¯•å’Œç›‘æ§

### æŸ¥çœ‹æ‰€æœ‰å¿ƒè·³

```bash
# æŸ¥çœ‹æ‰€æœ‰å¿ƒè·³é”®
redis-cli KEYS "heartbeat:node:*"

# æŸ¥çœ‹æ‰€æœ‰èŠ‚ç‚¹çš„å¿ƒè·³æ—¶é—´
for key in $(redis-cli KEYS "heartbeat:node:*"); do
    echo "$key: $(redis-cli GET $key)"
done
```

### æŸ¥çœ‹æ‰€æœ‰æŒ‡æ ‡

```bash
# æŸ¥çœ‹æ‰€æœ‰æŒ‡æ ‡é”®
redis-cli KEYS "node:metrics:*"

# æŸ¥çœ‹ç‰¹å®šèŠ‚ç‚¹çš„æ‰€æœ‰æŒ‡æ ‡
redis-cli HGETALL "node:metrics:test_node_1"
```

### å®æ—¶ç›‘æ§è„šæœ¬

```python
import time
from ginkgo.data.crud import RedisCRUD

def monitor_nodes():
    redis_crud = RedisCRUD()
    redis_client = redis_crud.redis

    while True:
        print("\n" + "="*70)
        print("  ExecutionNode ç›‘æ§é¢æ¿")
        print("="*70)

        # è·å–æ‰€æœ‰å¿ƒè·³
        heartbeat_keys = redis_client.keys("heartbeat:node:*")

        if not heartbeat_keys:
            print("âš ï¸  æ²¡æœ‰åœ¨çº¿èŠ‚ç‚¹")
        else:
            for key in heartbeat_keys:
                node_id = key.decode('utf-8').replace("heartbeat:node:", "")

                # å¿ƒè·³æ—¶é—´
                heartbeat_value = redis_client.get(key).decode('utf-8')
                ttl = redis_client.ttl(key)

                # èŠ‚ç‚¹æŒ‡æ ‡
                metrics_key = f"node:metrics:{node_id}"
                metrics = redis_client.hgetall(metrics_key)

                if metrics:
                    portfolio_count = metrics.get(b'portfolio_count', b'0').decode('utf-8')
                    queue_size = metrics.get(b'queue_size', b'0').decode('utf-8')
                else:
                    portfolio_count = "0"
                    queue_size = "0"

                print(f"\nğŸ“Š èŠ‚ç‚¹: {node_id}")
                print(f"   ğŸ’“ å¿ƒè·³: {heartbeat_value} (TTL: {ttl}s)")
                print(f"   ğŸ“¦ Portfolio: {portfolio_count}")
                print(f"   ğŸ“‹ é˜Ÿåˆ—: {queue_size}")

        time.sleep(5)  # æ¯5ç§’åˆ·æ–°
```

---

## æ€»ç»“

### å¿ƒè·³ä¸ŠæŠ¥çš„ä¿¡æ¯

| ä¿¡æ¯ç±»å‹ | Redis é”® | æ•°æ®ç±»å‹ | é¢‘ç‡ | ç”¨é€” |
|---------|---------|---------|------|------|
| **å¿ƒè·³** | `heartbeat:node:{id}` | String + TTL | æ¯10ç§’ | å­˜æ´»è¯æ˜ |
| **æŒ‡æ ‡** | `node:metrics:{id}` | Hash | æ¯10ç§’ | æ€§èƒ½ç›‘æ§ |

### æ ¸å¿ƒæŒ‡æ ‡

```
âœ… å®æ—¶æŒ‡æ ‡ï¼ˆå½“å‰ä½¿ç”¨ï¼‰ï¼š
   - portfolio_count: Portfolio æ•°é‡
   - queue_size: é˜Ÿåˆ—å¤§å°
   - total_events: æ€»äº‹ä»¶æ•°
   - backpressure_count: èƒŒå‹æ¬¡æ•°
   - dropped_events: ä¸¢å¼ƒäº‹ä»¶æ•°

â³ é¢„ç•™æŒ‡æ ‡ï¼ˆæœªæ¥å®ç°ï¼‰ï¼š
   - cpu_usage: CPU ä½¿ç”¨ç‡
   - memory_usage: å†…å­˜ä½¿ç”¨
```

### ç‰¹ç‚¹

- âœ… **ç®€å•**ï¼šåªæœ‰2ä¸ªé”®ï¼Œ1ä¸ªå¿ƒè·³ + 1ä¸ªæŒ‡æ ‡
- âœ… **é«˜æ•ˆ**ï¼šæ¯10ç§’æ›´æ–°ä¸€æ¬¡
- âœ… **å¯é **ï¼šRedis TTL è‡ªåŠ¨å¤„ç†ç¦»çº¿
- âœ… **å®Œæ•´**ï¼šæ¶µç›–èŠ‚ç‚¹çŠ¶æ€çš„å…³é”®æŒ‡æ ‡
